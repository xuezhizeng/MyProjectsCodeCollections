{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !ls -hl|grep csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time, ctime\n",
    "from sklearn.metrics import accuracy_score, classification_report, classification, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, StratifiedShuffleSplit\n",
    "from helper import plot_confusion_matrix, plot_confusion_matrix2\n",
    "dim=lambda *x: [i.shape for i in x]\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49260, 748)\n",
      "CPU times: user 2.86 s, sys: 232 ms, total: 3.09 s\n",
      "Wall time: 3.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('./preprocessed.csv')\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49260, 746)\n",
      "(49260,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>fname.gender</th>\n",
       "      <th>username_split_predict</th>\n",
       "      <th>last</th>\n",
       "      <th>last_two</th>\n",
       "      <th>first</th>\n",
       "      <th>first2</th>\n",
       "      <th>nchar</th>\n",
       "      <th>vowels.pct</th>\n",
       "      <th>digits.pct</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_721</th>\n",
       "      <th>feature_722</th>\n",
       "      <th>feature_723</th>\n",
       "      <th>feature_724</th>\n",
       "      <th>feature_725</th>\n",
       "      <th>feature_726</th>\n",
       "      <th>feature_727</th>\n",
       "      <th>feature_728</th>\n",
       "      <th>feature_729</th>\n",
       "      <th>feature_730</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>billion</td>\n",
       "      <td>male</td>\n",
       "      <td>unknow</td>\n",
       "      <td>n</td>\n",
       "      <td>on</td>\n",
       "      <td>b</td>\n",
       "      <td>bi</td>\n",
       "      <td>7</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 748 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  username fname.gender username_split_predict last last_two first first2  \\\n",
       "0  billion         male                 unknow    n       on     b     bi   \n",
       "\n",
       "   nchar  vowels.pct  digits.pct     ...       feature_721  feature_722  \\\n",
       "0      7    0.428571         0.0     ...               0.0          0.0   \n",
       "\n",
       "   feature_723  feature_724  feature_725  feature_726  feature_727  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_728  feature_729  feature_730  \n",
       "0         13.0         14.0          7.0  \n",
       "\n",
       "[1 rows x 748 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,2:].values\n",
    "print X.shape\n",
    "y = df.iloc[:,1].map({'male':1,'female':0}).values\n",
    "print y.shape\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 144 ms, sys: 999 µs, total: 145 ms\n",
      "Wall time: 144 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Encoding the Independent Variable\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "for i in range(5):\n",
    "    i=str(i)\n",
    "    exec(\"labelencoder_X_{} = LabelEncoder()\".format(i))\n",
    "    exec(\"X[:, {}] = labelencoder_X_{}.fit_transform(X[:, {}])\".format(i,i,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49260, 746)\n",
      "(49260, 4505)\n",
      "CPU times: user 1.31 s, sys: 485 ms, total: 1.79 s\n",
      "Wall time: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print X.shape\n",
    "onehotencoder = OneHotEncoder(categorical_features = range(6))\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49260, 4505)\n",
      "CPU times: user 2.93 s, sys: 1.53 s, total: 4.46 s\n",
      "Wall time: 4.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "# fit on training set\n",
    "X = sc.fit_transform(X)\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier,\\\n",
    "ExtraTreesClassifier, GradientBoostingClassifier, VotingClassifier, RandomForestClassifier\n",
    "\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sat Nov 11 00:44:46 2017'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation:\n",
      "\n",
      "Accuracy: 0.8237 (+/- 0.0008) [AdaBoost]\n",
      "Accuracy: 0.8244 (+/- 0.0013) [Random Forest]\n",
      "Accuracy: 0.8298 (+/- 0.0019) [Xgboost]\n",
      "Accuracy: 0.8269 (+/- 0.0019) [Bagging]\n",
      "Accuracy: 0.8268 (+/- 0.0012) [ExtraTrees]\n"
     ]
    }
   ],
   "source": [
    "clf1 = AdaBoostClassifier()\n",
    "clf2 = RandomForestClassifier(random_state=1, n_estimators=320, min_samples_split=4, n_jobs=-1)\n",
    "clf3 = XGBClassifier(nthread=-1, max_depth=24,\n",
    "                        min_child_weight=0.9, colsample_bytree=0.9,\n",
    "                       scale_pos_weight= 0.9, reg_alpha=0.6)\n",
    "clf4 = BaggingClassifier(n_jobs=-1, n_estimators=50)\n",
    "clf5 = ExtraTreesClassifier(n_jobs=-1, bootstrap=True, n_estimators=100)\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs', n_jobs=-1)\n",
    "\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3, clf4, clf5], \n",
    "                          meta_classifier=lr)\n",
    "\n",
    "print('5-fold cross validation:\\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    stack1=[]\n",
    "    for clf, label in zip([clf1, clf2, clf3, clf4, clf5,  sclf], \n",
    "                          ['AdaBoost', \n",
    "                           'Random Forest', \n",
    "                           'Xgboost',\n",
    "                           'Bagging',\n",
    "                           'ExtraTrees',\n",
    "                           'Stacking']):\n",
    "\n",
    "        scores = model_selection.cross_val_score(clf, X, y, \n",
    "#                                                  n_jobs=-1,\n",
    "                                                  cv=5, scoring='accuracy')\n",
    "        stack1.append([label, scores, scores.mean(), scores.std()])\n",
    "        print(\"Accuracy: %0.4f (+/- %0.4f) [%s]\" \n",
    "              % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf1 = AdaBoostClassifier()\n",
    "clf2 = RandomForestClassifier(random_state=1, n_estimators=320, min_samples_split=4, n_jobs=-1)\n",
    "clf3 = XGBClassifier(nthread=-1, max_depth=24,\n",
    "                        min_child_weight=0.9, colsample_bytree=0.9,\n",
    "                       scale_pos_weight= 0.9, reg_alpha=0.6)\n",
    "clf4 = BaggingClassifier(n_jobs=-1, n_estimators=50)\n",
    "clf5 = ExtraTreesClassifier(n_jobs=-1, bootstrap=True, n_estimators=100)\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs', n_jobs=-1)\n",
    "\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3, clf4, clf5], \n",
    "                          meta_classifier=lr, \n",
    "                         use_probas=True,\n",
    "                          average_probas=False)\n",
    "\n",
    "print('5-fold cross validation:\\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    stack2 = []\n",
    "    for clf, label in zip([clf1, clf2, clf3, clf4, clf5,  sclf], \n",
    "                          ['AdaBoost', \n",
    "                           'Random Forest', \n",
    "                           'Xgboost',\n",
    "                           'Bagging',\n",
    "                           'ExtraTrees',\n",
    "                           'Stacking']):\n",
    "\n",
    "        scores = model_selection.cross_val_score(clf, X, y, \n",
    "#                                                  n_jobs=-1,\n",
    "                                                  cv=5, scoring='accuracy')\n",
    "        stack2.append([label, scores, scores.mean(), scores.std()])\n",
    "        print(\"Accuracy: %0.4f (+/- %0.4f) [%s]\" \n",
    "              % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['AdaBoost',\n",
       "  array([ 0.82330255,  0.82511165,  0.8226756 ,  0.82369062,  0.8234697 ]),\n",
       "  0.82365002369368789,\n",
       "  0.00080507980493064015],\n",
       " ['Random Forest',\n",
       "  array([ 0.82299807,  0.82592367,  0.82511165,  0.82521315,  0.82275911]),\n",
       "  0.82440113197399723,\n",
       "  0.0012764916941748496],\n",
       " ['Xgboost',\n",
       "  array([ 0.82989952,  0.8317093 ,  0.8316078 ,  0.82917174,  0.82661659]),\n",
       "  0.82980098897816001,\n",
       "  0.001868275523513574],\n",
       " ['Bagging',\n",
       "  array([ 0.82604283,  0.82998376,  0.82805522,  0.82531466,  0.8250939 ]),\n",
       "  0.8268980724943058,\n",
       "  0.0018630156210343507],\n",
       " ['ExtraTrees',\n",
       "  array([ 0.82685477,  0.82835972,  0.82754771,  0.82643118,  0.82489087]),\n",
       "  0.82681685010371453,\n",
       "  0.0011639735131901646],\n",
       " ['Stacking',\n",
       "  array([ 0.82746372,  0.82785221,  0.82846123,  0.82582217,  0.82570297]),\n",
       "  0.82706045958704189,\n",
       "  0.001107047276820309]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['AdaBoost',\n",
       "  array([ 0.82330255,  0.82511165,  0.8226756 ,  0.82369062,  0.8234697 ]),\n",
       "  0.82365002369368789,\n",
       "  0.00080507980493064015],\n",
       " ['Random Forest',\n",
       "  array([ 0.82299807,  0.82592367,  0.82511165,  0.82521315,  0.82275911]),\n",
       "  0.82440113197399723,\n",
       "  0.0012764916941748496],\n",
       " ['Xgboost',\n",
       "  array([ 0.82989952,  0.8317093 ,  0.8316078 ,  0.82917174,  0.82661659]),\n",
       "  0.82980098897816001,\n",
       "  0.001868275523513574],\n",
       " ['Bagging',\n",
       "  array([ 0.82523089,  0.82825822,  0.82886724,  0.82470564,  0.82377424]),\n",
       "  0.8261672461092564,\n",
       "  0.0020199828324036695],\n",
       " ['ExtraTrees',\n",
       "  array([ 0.82726073,  0.82754771,  0.82825822,  0.8271417 ,  0.82560146]),\n",
       "  0.82716196388000418,\n",
       "  0.00087131062491349154],\n",
       " ['Stacking',\n",
       "  array([ 0.83203085,  0.83353634,  0.83038977,  0.8271417 ,  0.8275302 ]),\n",
       "  0.83012577140370336,\n",
       "  0.002488882720539454]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
