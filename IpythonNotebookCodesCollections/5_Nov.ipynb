{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "print 'start'\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf8')\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from time import time, ctime\n",
    "\n",
    "import concurrent.futures\n",
    "\n",
    "from lxml import etree\n",
    "import json\n",
    "import re\n",
    "\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of files: 68229\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "# path='technosystem.html'\n",
    "\n",
    "folder='bidder_pages/'\n",
    "cont = os.listdir(folder)\n",
    "cont = [i for i in cont if i[-4:]=='html']\n",
    "\n",
    "print 'No. of files:',len(cont)\n",
    "# In[11]:\n",
    "\n",
    "def flatten_dict(data, layers=1, drop_deeper=False):\n",
    "\n",
    "        for _ in range(layers):\n",
    "            data = [(k, v) if not isinstance(v, dict) else [(k + '.' + k2, v2) for k2, v2 in v.items()] for k, v in\n",
    "                    data.items()]\n",
    "            data = [item for sublist in data for item in sublist if isinstance(sublist, list)] + [y for y in data if\n",
    "                                                                                                  not isinstance(y,\n",
    "                                                                                                                 list)]\n",
    "            data = dict(data)\n",
    "\n",
    "        if drop_deeper:\n",
    "            data = {k: v for k, v in data.items() if not isinstance(v, dict) or isinstance(v, list)}\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "from collections import defaultdict\n",
    "iniDict = defaultdict(lambda: None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_columns(path):\n",
    "    from time import ctime\n",
    "    global failed_names, collect, n\n",
    "    \n",
    "    n+=1\n",
    "    if n%5000==0 or n==1:\n",
    "        print ctime(), ': processed', n, 'and failed: ',len(failed_names)\n",
    "    get=[]\n",
    "    \n",
    "    with open(folder+path,'r') as fl:\n",
    "        text=fl.read()\n",
    "#         tree=etree.HTML(text)\n",
    "    try:\n",
    "#         script = tree.xpath('//script')[-2]\n",
    "        data = re.search(r\"__export\\('profileServerData',(.*?)\\n\", text)        \n",
    "        jsondata=data.group(1)[:-2]\n",
    "        \n",
    "        json_dict = json.loads(jsondata)\n",
    "        flat = flatten_dict(json_dict, layers=1)\n",
    "        for i in flat:\n",
    "            iniDict[i]=str(flat[i])\n",
    "        collect.append(pd.DataFrame(iniDict, index=[path]))\n",
    "            \n",
    "#         return pd.DataFrame(iniDict, index=[0])\n",
    "#         names = flat.keys()\n",
    "#         return flat\n",
    "    except Exception as e:\n",
    "        # print 'X',\n",
    "        failed_names.append(path)\n",
    "        collect.append(pd.DataFrame(index=[path]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch(allnames):\n",
    "    global collect\n",
    "    start=time()\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=12) as executor:\n",
    "        executor.map(get_columns, allnames)\n",
    "    past='{:.2f}'.format(time()-start)\n",
    "    now=ctime()[4:]\n",
    "\n",
    "    print 'profiles ',len(allnames),'  used ',past,'s', now\n",
    "    return past\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  5 18:18:40 2017 : processed 1 and failed:  0\n",
      "profiles  3200   used  16.91 s Nov  5 18:18:57 2017\n",
      "concat dataframe\n",
      "Sun Nov  5 18:18:57 2017\n",
      "16.91\n"
     ]
    }
   ],
   "source": [
    "# ### multi starts\n",
    "\n",
    "# initialize\n",
    "n=0\n",
    "initial = pd.DataFrame()\n",
    "collect=[]\n",
    "failed_names=[]\n",
    "\n",
    "\n",
    "# start\n",
    "eclipse = batch(cont[:3200])\n",
    "\n",
    "print 'concat dataframe'\n",
    "print ctime()\n",
    "print eclipse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(collect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 8.11 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# qq = pd.concat(collect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial.equals(pd.concat(collect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list count 3200\n",
      "CPU times: user 24.8 s, sys: 0 ns, total: 24.8 s\n",
      "Wall time: 24.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n=0\n",
    "print 'list count',len(collect)\n",
    "for i  in collect:\n",
    "    initial=initial.append(i)\n",
    "#     n+=1\n",
    "#     print n\n",
    "#     print ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done df, copying\n",
      "Sun Nov  5 18:21:41 2017\n",
      "done copy\n",
      "Sun Nov  5 18:21:41 2017\n",
      "(9600, 73)\n",
      "start making df\n",
      "Sun Nov  5 18:21:41 2017\n",
      "35\n",
      "save df\n",
      "Sun Nov  5 18:21:42 2017\n",
      "(9600, 38)\n",
      "Sun Nov  5 18:21:42 2017\n",
      "write to txt\n",
      "batch saving\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "Sun Nov  5 18:21:42 2017\n",
      "saving complete\n",
      "Sun Nov  5 18:21:42 2017\n",
      "done\n",
      "Sun Nov  5 18:21:42 2017\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In[53]:\n",
    "\n",
    "print 'done df, copying'\n",
    "print ctime()\n",
    "start=initial.copy()\n",
    "print 'done copy'\n",
    "print ctime()\n",
    "\n",
    "\n",
    "# In[55]:\n",
    "\n",
    "print start.shape\n",
    "\n",
    "# In[72]:\n",
    "print 'start making df'\n",
    "print ctime()\n",
    "delete=[]\n",
    "for i in start:\n",
    "#     print i\n",
    "#     print start[i].value_counts().head(5)\n",
    "#     print \n",
    "#     print \n",
    "    try:\n",
    "        if start[i].value_counts(dropna=False).iloc[:2].sum()==start.shape[0]:\n",
    "            delete.append(i)\n",
    "    except:\n",
    "        print i\n",
    "#         print i\n",
    "print len(delete)\n",
    "    \n",
    "\n",
    "\n",
    "# In[76]:\n",
    "print 'save df'\n",
    "print ctime()\n",
    "start = start.drop(delete, axis=1)\n",
    "start = start.reset_index(drop=True)\n",
    "print start.shape\n",
    "print ctime()\n",
    "\n",
    "\n",
    "print 'write to txt'\n",
    "#start.to_csv('bidder1_JSON.csv',index=False,chucksize=100,mode='w')\n",
    "\n",
    "#with open('result.txt','w') as fl:\n",
    "#\tfor i in range(start.shape[0]):\n",
    "#\t\tfor i in start.iloc[i,:]:\n",
    "#\t\t\tfl.write(str(i))\n",
    "#\t\t\tfl.write(',')\n",
    "#\t\tfl.write('\\n')\n",
    "\n",
    "def saving(df):\t\t\n",
    "\tflag=True\n",
    "\twhile df.shape[0]!=0:\n",
    "\t    tmp=df.iloc[:100,:]\n",
    "\t    df=df.iloc[100:,:]\n",
    "\t    if flag:\n",
    "\t        tmp.to_csv('goden.csv', index=False, mode='a')\n",
    "\t        flag=False\n",
    "\t\tprint ctime()\n",
    "\t    else:\n",
    "\t        tmp.to_csv('goden.csv', index=False,header=None, mode='a')\n",
    "\t\tprint ctime()\n",
    "\tprint 'saving complete'\n",
    "\tprint ctime()\n",
    "print 'batch saving'\n",
    "print ctime()\n",
    "saving(start)\n",
    "\n",
    "# In[77]:\n",
    "\n",
    "print 'done'\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "from time import ctime\n",
    "\n",
    "\n",
    "\n",
    "print ctime()\n",
    "\n",
    "exit()\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9600, 38)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('goden.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
