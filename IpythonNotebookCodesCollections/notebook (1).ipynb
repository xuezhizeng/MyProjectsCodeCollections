{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5b986c3f-64a6-4d45-948a-ec114abf9a26",
    "_uuid": "5b4cd66934364f7ed43dba5a2fe792edd2f232fc",
    "collapsed": true
   },
   "source": [
    "# Description\n",
    "\n",
    "This is an associated model using RNN and Ridge to solve Mercari Price Suggestion Challenge competition.\n",
    "\n",
    "You can find description of the competition here https://www.kaggle.com/c/mercari-price-suggestion-challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b3ac57a4-fbde-48c0-ba83-4e6281defc1d",
    "_uuid": "dd786f0add7f6e630dacbfce2c9e83ca4d911a09"
   },
   "source": [
    "## Import packages\n",
    "\n",
    "Import all needed packages for constructing models and solving the competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "adb99d41-c151-4dc7-80d9-405ec3d45a18",
    "_uuid": "ef91ec21ad7dbb55a77b760091e35ea8bdbb9a91",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dropout, Dense, concatenate, GRU, Embedding, Flatten, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "da0c86f0-897b-42e6-8bf4-792d7a8bdc3d",
    "_uuid": "2fe904526a603d8f0ff4a9b1c8f6cef40f0702ea"
   },
   "source": [
    "## Define RMSL Error Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b84221d8-2ced-43db-90c8-94ef5ee9e707",
    "_uuid": "3b4290b96e65b16b80a7f171b44f546f3b2ea493",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle(Y, Y_pred):\n",
    "    # Y and Y_red have already been in log scale.\n",
    "    assert Y.shape == Y_pred.shape\n",
    "    return np.sqrt(np.mean(np.square(Y_pred - Y )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "883b408d-686f-4c54-93e6-5632a21f2220",
    "_uuid": "22e7509badd537bbc17d9a1d823915889b4a6933"
   },
   "source": [
    "## Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "949a8eb5-a530-46ae-8874-859a785967f8",
    "_uuid": "ed0effa8967da098941de9ea8521de8bb4544da3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_df = pd.read_table('../input/train.tsv')\n",
    "test_df = pd.read_table('../input/test.tsv')\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3d6235a8-2b92-43c7-a1f4-f1dbe105c88b",
    "_uuid": "091d0eb8a2caee61aa7650fa85b9228972270d23"
   },
   "source": [
    "## Prepare data for processing by RNN and Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0777a728-5597-4192-965d-e493a1ed965b",
    "_uuid": "7c72bb19ef74bf23dcff5501361ccbe801f7ee97",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Handle missing data.\n",
    "def fill_missing_values(df):\n",
    "    df.category_name.fillna(value=\"Other\", inplace=True)\n",
    "    df.brand_name.fillna(value=\"missing\", inplace=True)\n",
    "    df.item_description.fillna(value=\"None\", inplace=True)\n",
    "    return df\n",
    "\n",
    "train_df = fill_missing_values(train_df)\n",
    "test_df = fill_missing_values(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ed6bc20a-1674-454e-9a88-c7a7fa05dcae",
    "_uuid": "cd3fe6e0c98aa258ac9747b58bfb865451df1016",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scale target variable to log.\n",
    "train_df[\"target\"] = np.log1p(train_df.price)\n",
    "\n",
    "# Split training examples into train/dev examples.\n",
    "train_df, dev_df = train_test_split(train_df, random_state=347, train_size=0.99)\n",
    "\n",
    "Y_train = train_df.target.values.reshape(-11, 1)\n",
    "Y_dev = dev_df.target.values.reshape(-1, 1)\n",
    "\n",
    "# Calculate number of train/dev/test examples.\n",
    "n_trains = train_df.shape[0]\n",
    "n_devs = dev_df.shape[0]\n",
    "n_tests = test_df.shape[0]\n",
    "print(\"Training on\", n_trains, \"examples\")\n",
    "print(\"Validating on\", n_devs, \"examples\")\n",
    "print(\"Testing on\", n_tests, \"examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "34572b8c-63cc-4524-8acc-1cd7d5c515cc",
    "_uuid": "7d562df976dc974844db6995ceca669b9a145e31"
   },
   "source": [
    "# RNN Model\n",
    "\n",
    "This section will use RNN Model to solve the competition with following steps:\n",
    "\n",
    "1. Preprocessing data\n",
    "1. Define RNN model\n",
    "1. Fitting RNN model on training examples\n",
    "1. Evaluating RNN model on dev examples\n",
    "1. Make prediction for test data using RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "92abc87d-6fb1-4000-b0ae-c21f364694d3",
    "_uuid": "46d9a48d339dd0255ba8750ca6c2a24b4c8fa786",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate train - dev - test data for easy to handle\n",
    "full_df = pd.concat([train_df, dev_df, test_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8203fba3-991d-4d53-b4ee-ef731782ddd7",
    "_uuid": "bbf287ccc320ff94ccac70d44d8cdbc70b03d154"
   },
   "source": [
    "## Process categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c092125b-dfeb-4621-bc47-d3ef28880b5d",
    "_uuid": "e18af15196678765a108ace4020f4ad89f6a5e55",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Processing categorical data...\")\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(full_df.category_name)\n",
    "full_df.category_name = le.transform(full_df.category_name)\n",
    "\n",
    "le.fit(full_df.brand_name)\n",
    "full_df.brand_name = le.transform(full_df.brand_name)\n",
    "\n",
    "del le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "84c7cc19-0784-4653-906c-4ec87f6fd6c2",
    "_uuid": "48418acfaa734e761cadf5976ab4befff08ac8bb"
   },
   "source": [
    "## Process text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4967bb28-577c-4d15-b956-6f66787dd7bf",
    "_uuid": "dddf4d1490a92501c893c29a02e6f9b67546d984",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Transforming text data to sequences...\")\n",
    "raw_text = np.hstack([full_df.item_description.str.lower(), full_df.name.str.lower()])\n",
    "\n",
    "print(\"   Fitting tokenizer...\")\n",
    "tok_raw = Tokenizer()\n",
    "tok_raw.fit_on_texts(raw_text)\n",
    "\n",
    "print(\"   Transforming text to sequences...\")\n",
    "full_df['seq_item_description'] = tok_raw.texts_to_sequences(full_df.item_description.str.lower())\n",
    "full_df['seq_name'] = tok_raw.texts_to_sequences(full_df.name.str.lower())\n",
    "\n",
    "del tok_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bdad0de1-2288-4a0e-ab61-e115284ac70f",
    "_uuid": "db44552705681d6b48938a4a102ce002a92e2850",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define constants to use when define RNN model\n",
    "MAX_NAME_SEQ = 10\n",
    "MAX_ITEM_DESC_SEQ = 75\n",
    "MAX_TEXT = np.max([\n",
    "    np.max(full_df.seq_name.max()),\n",
    "    np.max(full_df.seq_item_description.max()),\n",
    "]) + 4\n",
    "MAX_CATEGORY = np.max(full_df.category_name.max()) + 1\n",
    "MAX_BRAND = np.max(full_df.brand_name.max()) + 1\n",
    "MAX_CONDITION = np.max(full_df.item_condition_id.max()) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "eacd3e58-9c02-4cee-b526-7f7a7e9f2dcf",
    "_uuid": "c199135fa649b0fe03e4817ca7313cfb5fbd57db"
   },
   "source": [
    "## Get data for RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "52c34eb2-9039-4c63-81b2-4662d69c1137",
    "_uuid": "e930d4cb31f6cc233e5144be04650b89afc5bc4f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def get_keras_data(df):\n",
    "    X = {\n",
    "        'name': pad_sequences(df.seq_name, maxlen=MAX_NAME_SEQ),\n",
    "        'item_desc': pad_sequences(df.seq_item_description, maxlen=MAX_ITEM_DESC_SEQ),\n",
    "        'brand_name': np.array(df.brand_name),\n",
    "        'category_name': np.array(df.category_name),\n",
    "        'item_condition': np.array(df.item_condition_id),\n",
    "        'num_vars': np.array(df[[\"shipping\"]]),\n",
    "    }\n",
    "    return X\n",
    "\n",
    "train = full_df[:n_trains]\n",
    "dev = full_df[n_trains:n_trains+n_devs]\n",
    "test = full_df[n_trains+n_devs:]\n",
    "\n",
    "X_train = get_keras_data(train)\n",
    "X_dev = get_keras_data(dev)\n",
    "X_test = get_keras_data(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7c6a54f1-81ce-49c7-b2e2-e38eced7a958",
    "_uuid": "a6b6da051c3ab6d278e1986de9244e7f06628cee"
   },
   "source": [
    "## Define RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5e681e7b-ce3c-41cd-b182-b2a9fbe3f214",
    "_uuid": "314ef9524f32da1a031389025dd4848d56b0752f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_rnn_model(lr=0.001, decay=0.0):    \n",
    "    # Inputs\n",
    "    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n",
    "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n",
    "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
    "    category_name = Input(shape=[1], name=\"category_name\")\n",
    "    item_condition = Input(shape=[1], name=\"item_condition\")\n",
    "    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n",
    "\n",
    "    # Embeddings layers\n",
    "    emb_name = Embedding(MAX_TEXT, 20)(name)\n",
    "    emb_item_desc = Embedding(MAX_TEXT, 60)(item_desc)\n",
    "    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n",
    "    emb_category_name = Embedding(MAX_CATEGORY, 10)(category_name)\n",
    "    emb_item_condition = Embedding(MAX_CONDITION, 5)(item_condition)\n",
    "\n",
    "    # rnn layers\n",
    "    rnn_layer1 = GRU(16) (emb_item_desc)\n",
    "    rnn_layer2 = GRU(8) (emb_name)\n",
    "\n",
    "    # main layers\n",
    "    main_l = concatenate([\n",
    "        Flatten() (emb_brand_name)\n",
    "        , Flatten() (emb_category_name)\n",
    "        , Flatten() (emb_item_condition)\n",
    "        , rnn_layer1\n",
    "        , rnn_layer2\n",
    "        , num_vars\n",
    "    ])\n",
    "\n",
    "    main_l = Dense(256)(main_l)\n",
    "    main_l = Activation('elu')(main_l)\n",
    "\n",
    "    main_l = Dense(128)(main_l)\n",
    "    main_l = Activation('elu')(main_l)\n",
    "\n",
    "    main_l = Dense(64)(main_l)\n",
    "    main_l = Activation('elu')(main_l)\n",
    "\n",
    "    # the output layer.\n",
    "    output = Dense(1, activation=\"linear\") (main_l)\n",
    "\n",
    "    model = Model([name, item_desc, brand_name , category_name, item_condition, num_vars], output)\n",
    "\n",
    "    optimizer = Adam(lr=lr, decay=decay)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = new_rnn_model()\n",
    "model.summary()\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e26a8a7b-f946-49ca-baf3-bd05fbd62ea8",
    "_uuid": "b5b91c2ed4c45d859624c512a15e53d829e7c8df"
   },
   "source": [
    "## Fit RNN model to train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0fe2e204-3df1-4d42-b85c-2963bc1f168f",
    "_uuid": "6c6b35398cab7ab1e88ccc532d9abdf798fb67c4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set hyper parameters for the model.\n",
    "BATCH_SIZE = 1024\n",
    "epochs = 2\n",
    "\n",
    "# Calculate learning rate decay.\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "steps = int(n_trains / BATCH_SIZE) * epochs\n",
    "lr_init, lr_fin = 0.007, 0.0005\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "\n",
    "rnn_model = new_rnn_model(lr=lr_init, decay=lr_decay)\n",
    "\n",
    "print(\"Fitting RNN model to training examples...\")\n",
    "rnn_model.fit(\n",
    "        X_train, Y_train, epochs=epochs, batch_size=BATCH_SIZE,\n",
    "        validation_data=(X_dev, Y_dev), verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5c71f814-7f4c-42a3-8030-9e869df6cb5d",
    "_uuid": "e172a260b930d63a679cb21f084342755d60a8b4"
   },
   "source": [
    "## Evaluate RNN model on dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b48221eb-ac00-4bd3-bc4e-6465b40a87fc",
    "_uuid": "0e671e64429d2eca87bf0cacabb307d67da3e6c7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Evaluating the model on validation data...\")\n",
    "Y_dev_preds_rnn = rnn_model.predict(X_dev, batch_size=BATCH_SIZE)\n",
    "print(\" RMSLE error:\", rmsle(Y_dev, Y_dev_preds_rnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "106ddfdc-ac33-432d-8b6a-db656680480d",
    "_uuid": "9ccfd39ff8da963f36fa45c1e0511f3f5683033a"
   },
   "source": [
    "## Make prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f0356339-126f-491c-9d22-c9c128546168",
    "_uuid": "35c4ed5d85952ec34f0059535e753cd537faab53",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn_preds = rnn_model.predict(X_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "rnn_preds = np.expm1(rnn_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3ce824f3-dcbd-453b-92ba-e490e4cd9d84",
    "_uuid": "74cbbf48ca09e2f487ca6f6a7e170c2f58c32291"
   },
   "source": [
    "# Ridge Model\n",
    "\n",
    "This section will solve the competition using Ridge model with following steps:\n",
    "\n",
    "1. Preprocessing data\n",
    "1. Fitting Ridge model on training examples\n",
    "1. Evaluating Ridge model on dev examples\n",
    "1. Make prediction for test data using Ridge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "34c19c19-e90e-4a3e-b4a7-eb55ca00848c",
    "_uuid": "d234a8ac2c9aa67c7e173fcab684f4856ed82752",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate train - dev - test data for easy to handle\n",
    "full_df = pd.concat([train_df, dev_df, test_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "950a555e-fc91-45db-b969-fbe141af9aea",
    "_uuid": "02fe1644a1da61d0e4e6d88f13e03fb60f09d43a"
   },
   "source": [
    "## Convert data type to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8835e22b-d064-4bc6-acb4-567c44d4428f",
    "_uuid": "7cc69ef79fecd5dc042599f3ec04d0207668d287",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Convert data type to string\n",
    "full_df['shipping'] = full_df['shipping'].astype(str)\n",
    "full_df['item_condition_id'] = full_df['item_condition_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "185c6a6d-5d2a-4fd7-a7f2-747c680fab8e",
    "_uuid": "51dabf318564e7521af76ac161d2086d8d0ff599"
   },
   "source": [
    "## Extract features from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "04a35027-7b04-4e7c-a432-d0178fcbecac",
    "_uuid": "575135f0c3eede733bfdf704853204905580207e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Vectorizing data...\")\n",
    "default_preprocessor = CountVectorizer().build_preprocessor()\n",
    "def build_preprocessor(field):\n",
    "    field_idx = list(full_df.columns).index(field)\n",
    "    return lambda x: default_preprocessor(x[field_idx])\n",
    "\n",
    "vectorizer = FeatureUnion([\n",
    "    ('name', CountVectorizer(\n",
    "        ngram_range=(1, 2),\n",
    "        max_features=50000,\n",
    "        preprocessor=build_preprocessor('name'))),\n",
    "    ('category_name', CountVectorizer(\n",
    "        token_pattern='.+',\n",
    "        preprocessor=build_preprocessor('category_name'))),\n",
    "    ('brand_name', CountVectorizer(\n",
    "        token_pattern='.+',\n",
    "        preprocessor=build_preprocessor('brand_name'))),\n",
    "    ('shipping', CountVectorizer(\n",
    "        token_pattern='\\d+',\n",
    "        preprocessor=build_preprocessor('shipping'))),\n",
    "    ('item_condition_id', CountVectorizer(\n",
    "        token_pattern='\\d+',\n",
    "        preprocessor=build_preprocessor('item_condition_id'))),\n",
    "    ('item_description', TfidfVectorizer(\n",
    "        ngram_range=(1, 3),\n",
    "        max_features=100000,\n",
    "        preprocessor=build_preprocessor('item_description'))),\n",
    "])\n",
    "\n",
    "X = vectorizer.fit_transform(full_df.values)\n",
    "\n",
    "X_train = X[:n_trains]\n",
    "X_dev = X[n_trains:n_trains+n_devs]\n",
    "X_test = X[n_trains+n_devs:]\n",
    "\n",
    "print(X.shape, X_train.shape, X_dev.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0f34eca4-762c-480e-a269-8ed327b9b21f",
    "_uuid": "403ef92d6982787c5f5a46bb5a0710d475046259"
   },
   "source": [
    "## Fitting Ridge model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ef1a3b85-f68e-4ddd-94e4-4c7765dd0cf5",
    "_uuid": "af45b7a71173895c06eb876b1c9c7e1d0c55b4c1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Fitting Ridge model on training examples...\")\n",
    "ridge_model = Ridge(\n",
    "    solver='auto', fit_intercept=True, alpha=0.5,\n",
    "    max_iter=100, normalize=False, tol=0.05,\n",
    ")\n",
    "ridge_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1cf25071-13be-43e9-be20-6b1200332fd4",
    "_uuid": "75ca7fe30319238f8a6c5697d5ac5782de9caf93"
   },
   "source": [
    "## Evaluating Ridge model on dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d56220b1-8fb0-444d-b1f2-80c6d866146c",
    "_uuid": "7722eb4220fe38f6c5676f1f68cf417f741ed014",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_dev_preds_ridge = ridge_model.predict(X_dev)\n",
    "Y_dev_preds_ridge = Y_dev_preds_ridge.reshape(-1, 1)\n",
    "print(\"RMSL error on dev set:\", rmsle(Y_dev, Y_dev_preds_ridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d0cdcc08-ceb7-4121-bfc4-e32e1866f66a",
    "_uuid": "685838b5e39b6cfcce7f87dd1f79fc90f85730fe"
   },
   "source": [
    "## Make prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "84bc9193-99da-494d-a669-93041e111aae",
    "_uuid": "750620b691ad0e208c3c4b9122c3c689fa3a8ba5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ridge_preds = ridge_model.predict(X_test)\n",
    "ridge_preds = np.expm1(ridge_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a23fffab-ceb6-4703-b8fe-c290312a780f",
    "_uuid": "5a6e8228e853d9a71b70fff4cfe3e8797709e6ac"
   },
   "source": [
    "# Evaluating for associated model on dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9b9062a6-dbc8-482a-8ca1-7ed867d291d8",
    "_uuid": "d99a43dbd9d5c8949a576cfd5ddb2a5163d0384e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregate_predicts(Y1, Y2):\n",
    "    assert Y1.shape == Y2.shape\n",
    "    ratio = 0.63\n",
    "    return Y1 * ratio + Y2 * (1.0 - ratio)\n",
    "\n",
    "Y_dev_preds = aggregate_predicts(Y_dev_preds_rnn, Y_dev_preds_ridge)\n",
    "print(\"RMSL error for RNN + Ridge on dev set:\", rmsle(Y_dev, Y_dev_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a81edb6f-fb2d-48d3-9afc-3c3f954aa558",
    "_uuid": "081b38c1e45242943159d8e44fca976b14f169a2"
   },
   "source": [
    "# Creating Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "864a2906-4ff6-4f3b-92a3-7a007f92f503",
    "_uuid": "e60ac502c9d977de54bbfdc91701229b5ad3b14e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = aggregate_predicts(rnn_preds, ridge_preds)\n",
    "submission = pd.DataFrame({\n",
    "        \"test_id\": test_df.test_id,\n",
    "        \"price\": preds.reshape(-1),\n",
    "})\n",
    "submission.to_csv(\"./rnn_ridge_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "31eb19bd-abff-4a51-a0fc-a7119767bdca",
    "_uuid": "6c2cbc5f33ae9df64c1a76916126465e5ae26bcf"
   },
   "source": [
    "# Something can be tried to improve the model\n",
    "\n",
    "- Change aggregation ratio for aggregate_predicts\n",
    "- Change learning rate and learning rate decay RNN model\n",
    "- Descrease the batch size for RNN model\n",
    "- Increase the embedding output dimension for RNN model\n",
    "-  Add more Dense layers for RNN model\n",
    "- Add Batch Normalization layers for RNN model\n",
    "- Try LSTM, Bidirectional RNN, stack RNN for RNN model\n",
    "- Using other optimizer for RNN model\n",
    "- Change parameters for Ridge model\n",
    "- Something else that can help to improve the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2ae17cee-26d3-4a98-ab0a-8b6ee47ffadc",
    "_uuid": "f30b94f118190d2da1e5aefaa6e52ff9aabee8bf"
   },
   "source": [
    "# References\n",
    "\n",
    "1. https://www.kaggle.com/knowledgegrappler/a-simple-nn-solution-with-keras-0-48611-pl\n",
    "1. https://www.kaggle.com/isaienkov/rnn-gru-with-keras-512-64-relu-0-43758\n",
    "1. https://www.kaggle.com/lopuhin/eli5-for-mercari"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
