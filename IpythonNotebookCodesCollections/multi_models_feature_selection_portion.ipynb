{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !ls -hl|grep csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time, ctime\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, classification, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, StratifiedShuffleSplit\n",
    "\n",
    "from helper import plot_confusion_matrix, plot_confusion_matrix2\n",
    "dim=lambda *x: [i.shape for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49260, 748)\n",
      "CPU times: user 3.07 s, sys: 256 ms, total: 3.33 s\n",
      "Wall time: 3.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('./preprocessed.csv')\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>fname.gender</th>\n",
       "      <th>username_split_predict</th>\n",
       "      <th>last</th>\n",
       "      <th>last_two</th>\n",
       "      <th>first</th>\n",
       "      <th>first2</th>\n",
       "      <th>nchar</th>\n",
       "      <th>vowels.pct</th>\n",
       "      <th>digits.pct</th>\n",
       "      <th>last_is_vowel</th>\n",
       "      <th>first_is_vowel</th>\n",
       "      <th>last_is_digit</th>\n",
       "      <th>first_is_digit</th>\n",
       "      <th>digits.num</th>\n",
       "      <th>upper.pct</th>\n",
       "      <th>first_is_upper</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "      <th>feature_25</th>\n",
       "      <th>feature_26</th>\n",
       "      <th>feature_27</th>\n",
       "      <th>feature_28</th>\n",
       "      <th>feature_29</th>\n",
       "      <th>feature_30</th>\n",
       "      <th>feature_31</th>\n",
       "      <th>feature_32</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_681</th>\n",
       "      <th>feature_682</th>\n",
       "      <th>feature_683</th>\n",
       "      <th>feature_684</th>\n",
       "      <th>feature_685</th>\n",
       "      <th>feature_686</th>\n",
       "      <th>feature_687</th>\n",
       "      <th>feature_688</th>\n",
       "      <th>feature_689</th>\n",
       "      <th>feature_690</th>\n",
       "      <th>feature_691</th>\n",
       "      <th>feature_692</th>\n",
       "      <th>feature_693</th>\n",
       "      <th>feature_694</th>\n",
       "      <th>feature_695</th>\n",
       "      <th>feature_696</th>\n",
       "      <th>feature_697</th>\n",
       "      <th>feature_698</th>\n",
       "      <th>feature_699</th>\n",
       "      <th>feature_700</th>\n",
       "      <th>feature_701</th>\n",
       "      <th>feature_702</th>\n",
       "      <th>feature_703</th>\n",
       "      <th>feature_704</th>\n",
       "      <th>feature_705</th>\n",
       "      <th>feature_706</th>\n",
       "      <th>feature_707</th>\n",
       "      <th>feature_708</th>\n",
       "      <th>feature_709</th>\n",
       "      <th>feature_710</th>\n",
       "      <th>feature_711</th>\n",
       "      <th>feature_712</th>\n",
       "      <th>feature_713</th>\n",
       "      <th>feature_714</th>\n",
       "      <th>feature_715</th>\n",
       "      <th>feature_716</th>\n",
       "      <th>feature_717</th>\n",
       "      <th>feature_718</th>\n",
       "      <th>feature_719</th>\n",
       "      <th>feature_720</th>\n",
       "      <th>feature_721</th>\n",
       "      <th>feature_722</th>\n",
       "      <th>feature_723</th>\n",
       "      <th>feature_724</th>\n",
       "      <th>feature_725</th>\n",
       "      <th>feature_726</th>\n",
       "      <th>feature_727</th>\n",
       "      <th>feature_728</th>\n",
       "      <th>feature_729</th>\n",
       "      <th>feature_730</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>billion</td>\n",
       "      <td>male</td>\n",
       "      <td>unknow</td>\n",
       "      <td>n</td>\n",
       "      <td>on</td>\n",
       "      <td>b</td>\n",
       "      <td>bi</td>\n",
       "      <td>7</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ArmenSoft</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>t</td>\n",
       "      <td>ft</td>\n",
       "      <td>A</td>\n",
       "      <td>Ar</td>\n",
       "      <td>9</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>okbookman</td>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>n</td>\n",
       "      <td>an</td>\n",
       "      <td>o</td>\n",
       "      <td>ok</td>\n",
       "      <td>9</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 748 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    username fname.gender username_split_predict last last_two first first2  \\\n",
       "0    billion         male                 unknow    n       on     b     bi   \n",
       "1  ArmenSoft         male                   male    t       ft     A     Ar   \n",
       "2  okbookman         male                 female    n       an     o     ok   \n",
       "\n",
       "   nchar  vowels.pct  digits.pct  last_is_vowel  first_is_vowel  \\\n",
       "0      7    0.428571         0.0          False           False   \n",
       "1      9    0.222222         0.0          False           False   \n",
       "2      9    0.444444         0.0          False            True   \n",
       "\n",
       "   last_is_digit  first_is_digit  digits.num  upper.pct  first_is_upper  \\\n",
       "0          False           False           0          0           False   \n",
       "1          False           False           0          2            True   \n",
       "2          False           False           0          0           False   \n",
       "\n",
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0        0.0        1.0        0.0        0.0        0.0        0.0   \n",
       "1        1.0        0.0        0.0        0.0        1.0        1.0   \n",
       "2        1.0        1.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  feature_10  feature_11  \\\n",
       "0        0.0        0.0        2.0        0.0         0.0         2.0   \n",
       "1        0.0        0.0        0.0        0.0         0.0         0.0   \n",
       "2        0.0        0.0        0.0        0.0         2.0         0.0   \n",
       "\n",
       "   feature_12  feature_13  feature_14  feature_15  feature_16  feature_17  \\\n",
       "0         0.0         1.0         1.0         0.0         0.0         0.0   \n",
       "1         1.0         1.0         1.0         0.0         0.0         1.0   \n",
       "2         1.0         1.0         3.0         0.0         0.0         0.0   \n",
       "\n",
       "   feature_18  feature_19  feature_20  feature_21  feature_22  feature_23  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         1.0         1.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   feature_24  feature_25  feature_26  feature_27  feature_28  feature_29  \\\n",
       "0         0.0         0.0         0.0         1.0         0.0         0.0   \n",
       "1         0.0         0.0         1.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         8.0         3.0         0.0         0.0   \n",
       "\n",
       "   feature_30  feature_31  feature_32     ...       feature_681  feature_682  \\\n",
       "0         0.0         0.0         0.0     ...               0.0          0.0   \n",
       "1         4.0         8.0         0.0     ...               0.0          0.0   \n",
       "2         0.0         0.0         0.0     ...               0.0          0.0   \n",
       "\n",
       "   feature_683  feature_684  feature_685  feature_686  feature_687  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_688  feature_689  feature_690  feature_691  feature_692  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_693  feature_694  feature_695  feature_696  feature_697  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_698  feature_699  feature_700  feature_701  feature_702  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_703  feature_704  feature_705  feature_706  feature_707  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_708  feature_709  feature_710  feature_711  feature_712  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_713  feature_714  feature_715  feature_716  feature_717  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_718  feature_719  feature_720  feature_721  feature_722  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_723  feature_724  feature_725  feature_726  feature_727  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_728  feature_729  feature_730  \n",
       "0         13.0         14.0          7.0  \n",
       "1         19.0          5.0          9.0  \n",
       "2         13.0          0.0          9.0  \n",
       "\n",
       "[3 rows x 748 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns=100\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49260, 746)\n",
      "(49260,)\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:,2:].values\n",
    "print X.shape\n",
    "y = df.iloc[:,1].map({'male':1,'female':0}).values\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 714 ms, sys: 42 ms, total: 756 ms\n",
      "Wall time: 755 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Encoding the Independent Variable\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "for i in range(5):\n",
    "    i=str(i)\n",
    "    exec(\"labelencoder_X_{} = LabelEncoder()\".format(i))\n",
    "    exec(\"X[:, {}] = labelencoder_X_{}.fit_transform(X[:, {}])\".format(i,i,i))\n",
    "\n",
    "XX=X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49260, 746)\n",
      "(49260, 4505)\n",
      "CPU times: user 1.3 s, sys: 484 ms, total: 1.79 s\n",
      "Wall time: 1.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print X.shape\n",
    "onehotencoder = OneHotEncoder(categorical_features = range(6))\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(34482, 4505), (14778, 4505), (34482,), (14778,)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                   random_state=7)\n",
    "dim(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(34482, 4505), (14778, 4505), (34482,), (14778,)]\n",
      "CPU times: user 2.42 s, sys: 1.28 s, total: 3.7 s\n",
      "Wall time: 3.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "# fit on training set\n",
    "X_train = sc.fit_transform(X_train)\n",
    "# only transform on test set\n",
    "X_test = sc.transform(X_test)\n",
    "print dim(X_train,X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impliment(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    print accuracy_score(y_test, pred)\n",
    "    plot_confusion_matrix(confusion_matrix(y_test,pred), ['female','male'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shj16110/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier,RandomForestClassifier,\\\n",
    "ExtraTreesClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.834348355664\n",
    "# 0.835363377994  alpha =0.5\n",
    "# 0.835701718771 alpha =0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2252"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/feature-selection-in-python-with-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# model=RandomForestClassifier(random_state=1, n_estimators=50, min_samples_split=2, n_jobs=-1)\n",
    "# rfe = RFE(model, X_train.shape[1]*2/3)\n",
    "# rfe = rfe.fit(X_train, y_train)\n",
    "# # summarize the selection of the attributes\n",
    "# print(rfe.support_)\n",
    "# # print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# index2=rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RFE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier,\\\n",
    "ExtraTreesClassifier, GradientBoostingClassifier, VotingClassifier, RandomForestClassifier\n",
    "\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 5min 55s, sys: 5.02 s, total: 1h 6min\n",
      "Wall time: 4min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m1 = AdaBoostClassifier().fit(X_train, y_train)\n",
    "index1= pd.Series(m1.feature_importances_).sort_values(ascending=False)[:X_train.shape[1]/4*3].index\n",
    "\n",
    "m2 = RandomForestClassifier(random_state=1, n_estimators=50, min_samples_split=2, n_jobs=-1).fit(X_train, y_train)\n",
    "index2= pd.Series(m2.feature_importances_).sort_values(ascending=False)[:X_train.shape[1]/4*3].index\n",
    "\n",
    "m3 = XGBClassifier(nthread=-1, max_depth=24, min_child_weight=0.9, colsample_bytree=0.9,\n",
    "                       scale_pos_weight= 0.9, reg_alpha=0.6).fit(X_train, y_train)\n",
    "index3= pd.Series(m3.feature_importances_).sort_values(ascending=False)[:X_train.shape[1]/5*4].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 45s, sys: 7.31 s, total: 25min 53s\n",
      "Wall time: 5min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = AdaBoostClassifier()\n",
    "clf2 = RandomForestClassifier(random_state=1, n_estimators=50, min_samples_split=2, n_jobs=-1)\n",
    "clf3 = XGBClassifier(nthread=-1, max_depth=24,\n",
    "                        min_child_weight=0.9, colsample_bytree=0.9,\n",
    "                       scale_pos_weight= 0.9, reg_alpha=0.6)\n",
    "clf4 = BaggingClassifier(n_jobs=-1, n_estimators=50)\n",
    "clf5 = ExtraTreesClassifier(n_jobs=-1, bootstrap=True, n_estimators=100)\n",
    "lr = LogisticRegression(solver='lbfgs', n_jobs=-1)\n",
    "\n",
    "pipe1 = make_pipeline(ColumnSelector(cols=index1),\n",
    "                      clf1)\n",
    "pipe2 = make_pipeline(ColumnSelector(cols=index2),\n",
    "                      clf2)\n",
    "pipe3 = make_pipeline(ColumnSelector(cols=index3),\n",
    "                      clf3)\n",
    "pipe5 = make_pipeline(ColumnSelector(cols=index5),\n",
    "                      clf5)\n",
    "\n",
    "sclf = StackingClassifier(classifiers=[pipe1, pipe2, pipe3, clf4, pipe5], \n",
    "                          meta_classifier=lr,\n",
    "                          use_probas=True,\n",
    "                          average_probas=False)\n",
    "\n",
    "sclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ..., 1 1 1]\n",
      "CPU times: user 26.1 s, sys: 1.68 s, total: 27.8 s\n",
      "Wall time: 28.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred = sclf.predict(X_test)\n",
    "print pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83779943158749492"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[  512  2151]\n",
      " [  246 11869]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV8AAAEmCAYAAADFmJOIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ae7f6b4f3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_test, pred), classes=['female','male'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### skip back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation:\n",
      "\n",
      "Accuracy: 0.8295 (+/- 0.0013) [Xgboost]\n",
      "Accuracy: 0.8241 (+/- 0.0007) [AdaBoost]\n",
      "Accuracy: 0.8254 (+/- 0.0011) [Random Forest]\n",
      "Accuracy: 0.8254 (+/- 0.0021) [Bagging]\n",
      "Accuracy: 0.8275 (+/- 0.0012) [ExtraTrees]\n",
      "Accuracy: 0.8310 (+/- 0.0022) [Stacking]\n",
      "CPU times: user 8h 48min 54s, sys: 2min 5s, total: 8h 50min 59s\n",
      "Wall time: 1h 20min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = AdaBoostClassifier()\n",
    "clf2 = RandomForestClassifier(random_state=1, n_estimators=50, min_samples_split=2, n_jobs=-1)\n",
    "clf3 = XGBClassifier(nthread=-1, max_depth=24,\n",
    "                        min_child_weight=0.9, colsample_bytree=0.9,\n",
    "                       scale_pos_weight= 0.9, reg_alpha=0.6)\n",
    "clf4 = BaggingClassifier(n_jobs=-1, n_estimators=50)\n",
    "clf5 = ExtraTreesClassifier(n_jobs=-1, bootstrap=True, n_estimators=100)\n",
    "lr = LogisticRegression(solver='lbfgs', n_jobs=-1)\n",
    "\n",
    "pipe1 = make_pipeline(ColumnSelector(cols=index1), clf1)\n",
    "pipe2 = make_pipeline(ColumnSelector(cols=index2), clf2)\n",
    "pipe3 = make_pipeline(ColumnSelector(cols=index3), clf3)\n",
    "\n",
    "sclf = StackingClassifier(classifiers=[ pipe1, pipe2, pipe3, clf4, clf5], \n",
    "                          meta_classifier=lr,\n",
    "                          use_probas=True,\n",
    "                          average_probas=False)\n",
    "\n",
    "print('5-fold cross validation:\\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    stack3 = []\n",
    "    for clf, label in zip([pipe1, pipe2, pipe3,  clf4, pipe5,  sclf], \n",
    "                          ['AdaBoost', \n",
    "                           'Random Forest', \n",
    "                           'Xgboost',\n",
    "                           'Bagging',\n",
    "                           'ExtraTrees',\n",
    "                           'Stacking']):\n",
    "\n",
    "        scores = model_selection.cross_val_score(clf, X, y, \n",
    "#                                                  n_jobs=-1,\n",
    "                                                  cv=5, scoring='accuracy')\n",
    "        stack3.append([label, scores, scores.mean(), scores.std()])\n",
    "        print(\"Accuracy: %0.4f (+/- %0.4f) [%s]\" \n",
    "              % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "            ...\n",
       "            4460, 4461, 4462, 4463, 4464, 4465, 4466, 4468, 4502, 4504],\n",
       "           dtype='int64', length=3002)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index1.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ada</th>\n",
       "      <th>forest</th>\n",
       "      <th>xgb</th>\n",
       "      <th>extraTree</th>\n",
       "      <th>ada_sort</th>\n",
       "      <th>forest_sort</th>\n",
       "      <th>xgb_sort</th>\n",
       "      <th>extraTree_sort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3765</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3947</td>\n",
       "      <td>3765</td>\n",
       "      <td>4503</td>\n",
       "      <td>3765</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3772</td>\n",
       "      <td>4504</td>\n",
       "      <td>4502</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3553</td>\n",
       "      <td>4502</td>\n",
       "      <td>3800</td>\n",
       "      <td>4504</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3944</td>\n",
       "      <td>4503</td>\n",
       "      <td>3804</td>\n",
       "      <td>4503</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4052</td>\n",
       "      <td>3804</td>\n",
       "      <td>4504</td>\n",
       "      <td>3800</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3086</td>\n",
       "      <td>3800</td>\n",
       "      <td>3817</td>\n",
       "      <td>4502</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4177</td>\n",
       "      <td>3817</td>\n",
       "      <td>3813</td>\n",
       "      <td>3804</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3792</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3774</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1585</td>\n",
       "      <td>3818</td>\n",
       "      <td>3818</td>\n",
       "      <td>3808</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3029</td>\n",
       "      <td>3813</td>\n",
       "      <td>3814</td>\n",
       "      <td>3817</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4164</td>\n",
       "      <td>3819</td>\n",
       "      <td>3811</td>\n",
       "      <td>3778</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4162</td>\n",
       "      <td>3814</td>\n",
       "      <td>3819</td>\n",
       "      <td>3813</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4038</td>\n",
       "      <td>3811</td>\n",
       "      <td>3766</td>\n",
       "      <td>3818</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3802</td>\n",
       "      <td>3766</td>\n",
       "      <td>3774</td>\n",
       "      <td>3814</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3241</td>\n",
       "      <td>3802</td>\n",
       "      <td>3772</td>\n",
       "      <td>3819</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3941</td>\n",
       "      <td>3774</td>\n",
       "      <td>3812</td>\n",
       "      <td>3792</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3560</td>\n",
       "      <td>3812</td>\n",
       "      <td>3802</td>\n",
       "      <td>3791</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>75</td>\n",
       "      <td>3778</td>\n",
       "      <td>3803</td>\n",
       "      <td>3787</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2709</td>\n",
       "      <td>3771</td>\n",
       "      <td>3778</td>\n",
       "      <td>3788</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3845</td>\n",
       "      <td>3792</td>\n",
       "      <td>3807</td>\n",
       "      <td>3782</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3769</td>\n",
       "      <td>3803</td>\n",
       "      <td>3791</td>\n",
       "      <td>3793</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1221</td>\n",
       "      <td>1</td>\n",
       "      <td>3787</td>\n",
       "      <td>3811</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3995</td>\n",
       "      <td>3807</td>\n",
       "      <td>3785</td>\n",
       "      <td>3771</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3824</td>\n",
       "      <td>3787</td>\n",
       "      <td>3782</td>\n",
       "      <td>3766</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3827</td>\n",
       "      <td>3791</td>\n",
       "      <td>3792</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4415</td>\n",
       "      <td>3793</td>\n",
       "      <td>3820</td>\n",
       "      <td>3785</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4122</td>\n",
       "      <td>3801</td>\n",
       "      <td>3801</td>\n",
       "      <td>3812</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3527</td>\n",
       "      <td>2</td>\n",
       "      <td>3788</td>\n",
       "      <td>3802</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4095</td>\n",
       "      <td>3820</td>\n",
       "      <td>3810</td>\n",
       "      <td>3786</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>4459</td>\n",
       "      <td>2847</td>\n",
       "      <td>2876</td>\n",
       "      <td>1246</td>\n",
       "      <td>4440</td>\n",
       "      <td>4473</td>\n",
       "      <td>4454</td>\n",
       "      <td>4474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>4453</td>\n",
       "      <td>1682</td>\n",
       "      <td>2875</td>\n",
       "      <td>2453</td>\n",
       "      <td>4441</td>\n",
       "      <td>4474</td>\n",
       "      <td>4455</td>\n",
       "      <td>4475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>4454</td>\n",
       "      <td>1596</td>\n",
       "      <td>2874</td>\n",
       "      <td>2173</td>\n",
       "      <td>4442</td>\n",
       "      <td>4475</td>\n",
       "      <td>4456</td>\n",
       "      <td>4476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>4455</td>\n",
       "      <td>2870</td>\n",
       "      <td>2873</td>\n",
       "      <td>847</td>\n",
       "      <td>4443</td>\n",
       "      <td>4476</td>\n",
       "      <td>4458</td>\n",
       "      <td>4477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>4456</td>\n",
       "      <td>1102</td>\n",
       "      <td>2872</td>\n",
       "      <td>2476</td>\n",
       "      <td>4444</td>\n",
       "      <td>4477</td>\n",
       "      <td>4460</td>\n",
       "      <td>4478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2977</th>\n",
       "      <td>4457</td>\n",
       "      <td>1600</td>\n",
       "      <td>2871</td>\n",
       "      <td>3460</td>\n",
       "      <td>4445</td>\n",
       "      <td>4478</td>\n",
       "      <td>4461</td>\n",
       "      <td>4479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>4458</td>\n",
       "      <td>529</td>\n",
       "      <td>2870</td>\n",
       "      <td>4256</td>\n",
       "      <td>4446</td>\n",
       "      <td>4479</td>\n",
       "      <td>4462</td>\n",
       "      <td>4480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>4460</td>\n",
       "      <td>3548</td>\n",
       "      <td>2869</td>\n",
       "      <td>1012</td>\n",
       "      <td>4447</td>\n",
       "      <td>4480</td>\n",
       "      <td>4463</td>\n",
       "      <td>4481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>4468</td>\n",
       "      <td>1313</td>\n",
       "      <td>2868</td>\n",
       "      <td>2212</td>\n",
       "      <td>4448</td>\n",
       "      <td>4481</td>\n",
       "      <td>4464</td>\n",
       "      <td>4482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>4461</td>\n",
       "      <td>2645</td>\n",
       "      <td>2867</td>\n",
       "      <td>3744</td>\n",
       "      <td>4449</td>\n",
       "      <td>4482</td>\n",
       "      <td>4465</td>\n",
       "      <td>4483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>4462</td>\n",
       "      <td>507</td>\n",
       "      <td>2866</td>\n",
       "      <td>2879</td>\n",
       "      <td>4450</td>\n",
       "      <td>4483</td>\n",
       "      <td>4467</td>\n",
       "      <td>4484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>4463</td>\n",
       "      <td>3400</td>\n",
       "      <td>2865</td>\n",
       "      <td>2227</td>\n",
       "      <td>4451</td>\n",
       "      <td>4484</td>\n",
       "      <td>4468</td>\n",
       "      <td>4485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>4464</td>\n",
       "      <td>3072</td>\n",
       "      <td>2864</td>\n",
       "      <td>2474</td>\n",
       "      <td>4452</td>\n",
       "      <td>4486</td>\n",
       "      <td>4469</td>\n",
       "      <td>4486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>4465</td>\n",
       "      <td>3440</td>\n",
       "      <td>2863</td>\n",
       "      <td>3317</td>\n",
       "      <td>4453</td>\n",
       "      <td>4487</td>\n",
       "      <td>4472</td>\n",
       "      <td>4487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>4466</td>\n",
       "      <td>780</td>\n",
       "      <td>2862</td>\n",
       "      <td>1107</td>\n",
       "      <td>4454</td>\n",
       "      <td>4488</td>\n",
       "      <td>4473</td>\n",
       "      <td>4488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>4452</td>\n",
       "      <td>2683</td>\n",
       "      <td>2861</td>\n",
       "      <td>2232</td>\n",
       "      <td>4455</td>\n",
       "      <td>4489</td>\n",
       "      <td>4474</td>\n",
       "      <td>4489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>4451</td>\n",
       "      <td>2682</td>\n",
       "      <td>2860</td>\n",
       "      <td>3176</td>\n",
       "      <td>4456</td>\n",
       "      <td>4490</td>\n",
       "      <td>4476</td>\n",
       "      <td>4490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>4450</td>\n",
       "      <td>2074</td>\n",
       "      <td>2859</td>\n",
       "      <td>3670</td>\n",
       "      <td>4457</td>\n",
       "      <td>4491</td>\n",
       "      <td>4480</td>\n",
       "      <td>4491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>4449</td>\n",
       "      <td>3436</td>\n",
       "      <td>2858</td>\n",
       "      <td>2900</td>\n",
       "      <td>4458</td>\n",
       "      <td>4493</td>\n",
       "      <td>4484</td>\n",
       "      <td>4493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>4448</td>\n",
       "      <td>1761</td>\n",
       "      <td>2856</td>\n",
       "      <td>2528</td>\n",
       "      <td>4459</td>\n",
       "      <td>4494</td>\n",
       "      <td>4489</td>\n",
       "      <td>4494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>4447</td>\n",
       "      <td>1795</td>\n",
       "      <td>2855</td>\n",
       "      <td>402</td>\n",
       "      <td>4460</td>\n",
       "      <td>4495</td>\n",
       "      <td>4490</td>\n",
       "      <td>4495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>4446</td>\n",
       "      <td>4259</td>\n",
       "      <td>2854</td>\n",
       "      <td>2594</td>\n",
       "      <td>4461</td>\n",
       "      <td>4496</td>\n",
       "      <td>4493</td>\n",
       "      <td>4496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>4445</td>\n",
       "      <td>3691</td>\n",
       "      <td>2853</td>\n",
       "      <td>2526</td>\n",
       "      <td>4462</td>\n",
       "      <td>4497</td>\n",
       "      <td>4495</td>\n",
       "      <td>4497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>4444</td>\n",
       "      <td>1086</td>\n",
       "      <td>2852</td>\n",
       "      <td>370</td>\n",
       "      <td>4463</td>\n",
       "      <td>4498</td>\n",
       "      <td>4496</td>\n",
       "      <td>4498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>4443</td>\n",
       "      <td>3352</td>\n",
       "      <td>2878</td>\n",
       "      <td>171</td>\n",
       "      <td>4464</td>\n",
       "      <td>4499</td>\n",
       "      <td>4498</td>\n",
       "      <td>4499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>4442</td>\n",
       "      <td>2259</td>\n",
       "      <td>2879</td>\n",
       "      <td>514</td>\n",
       "      <td>4465</td>\n",
       "      <td>4500</td>\n",
       "      <td>4500</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>4441</td>\n",
       "      <td>2618</td>\n",
       "      <td>2880</td>\n",
       "      <td>1280</td>\n",
       "      <td>4466</td>\n",
       "      <td>4501</td>\n",
       "      <td>4501</td>\n",
       "      <td>4501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>4440</td>\n",
       "      <td>1320</td>\n",
       "      <td>2894</td>\n",
       "      <td>2819</td>\n",
       "      <td>4468</td>\n",
       "      <td>4502</td>\n",
       "      <td>4502</td>\n",
       "      <td>4502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>4439</td>\n",
       "      <td>827</td>\n",
       "      <td>2905</td>\n",
       "      <td>2242</td>\n",
       "      <td>4502</td>\n",
       "      <td>4503</td>\n",
       "      <td>4503</td>\n",
       "      <td>4503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>4438</td>\n",
       "      <td>1456</td>\n",
       "      <td>2904</td>\n",
       "      <td>3332</td>\n",
       "      <td>4504</td>\n",
       "      <td>4504</td>\n",
       "      <td>4504</td>\n",
       "      <td>4504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3002 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ada  forest   xgb  extraTree  ada_sort  forest_sort  xgb_sort  \\\n",
       "0        0       0  3765          0         0            0         0   \n",
       "1     3947    3765  4503       3765         1            1         1   \n",
       "2     3772    4504  4502          1         2            2         2   \n",
       "3     3553    4502  3800       4504         3            4         3   \n",
       "4     3944    4503  3804       4503         4            5         4   \n",
       "5     4052    3804  4504       3800         5            6         5   \n",
       "6     3086    3800  3817       4502         6            7         6   \n",
       "7     4177    3817  3813       3804         7            8         7   \n",
       "8     3792    3808  3808       3774         8            9         8   \n",
       "9     1585    3818  3818       3808         9           10         9   \n",
       "10    3029    3813  3814       3817        10           11        10   \n",
       "11    4164    3819  3811       3778        11           12        11   \n",
       "12    4162    3814  3819       3813        12           13        12   \n",
       "13    4038    3811  3766       3818        13           14        13   \n",
       "14    3802    3766  3774       3814        14           15        14   \n",
       "15    3241    3802  3772       3819        15           16        15   \n",
       "16    3941    3774  3812       3792        16           17        16   \n",
       "17    3560    3812  3802       3791        17           18        17   \n",
       "18      75    3778  3803       3787        18           19        18   \n",
       "19    2709    3771  3778       3788        19           20        19   \n",
       "20    3845    3792  3807       3782        20           21        20   \n",
       "21    3769    3803  3791       3793        21           22        21   \n",
       "22    1221       1  3787       3811        22           23        22   \n",
       "23    3995    3807  3785       3771        23           24        23   \n",
       "24    3824    3787  3782       3766        24           25        24   \n",
       "25    3827    3791  3792          2        25           26        25   \n",
       "26    4415    3793  3820       3785        26           27        26   \n",
       "27    4122    3801  3801       3812        27           28        27   \n",
       "28    3527       2  3788       3802        28           29        28   \n",
       "29    4095    3820  3810       3786        29           30        29   \n",
       "...    ...     ...   ...        ...       ...          ...       ...   \n",
       "2972  4459    2847  2876       1246      4440         4473      4454   \n",
       "2973  4453    1682  2875       2453      4441         4474      4455   \n",
       "2974  4454    1596  2874       2173      4442         4475      4456   \n",
       "2975  4455    2870  2873        847      4443         4476      4458   \n",
       "2976  4456    1102  2872       2476      4444         4477      4460   \n",
       "2977  4457    1600  2871       3460      4445         4478      4461   \n",
       "2978  4458     529  2870       4256      4446         4479      4462   \n",
       "2979  4460    3548  2869       1012      4447         4480      4463   \n",
       "2980  4468    1313  2868       2212      4448         4481      4464   \n",
       "2981  4461    2645  2867       3744      4449         4482      4465   \n",
       "2982  4462     507  2866       2879      4450         4483      4467   \n",
       "2983  4463    3400  2865       2227      4451         4484      4468   \n",
       "2984  4464    3072  2864       2474      4452         4486      4469   \n",
       "2985  4465    3440  2863       3317      4453         4487      4472   \n",
       "2986  4466     780  2862       1107      4454         4488      4473   \n",
       "2987  4452    2683  2861       2232      4455         4489      4474   \n",
       "2988  4451    2682  2860       3176      4456         4490      4476   \n",
       "2989  4450    2074  2859       3670      4457         4491      4480   \n",
       "2990  4449    3436  2858       2900      4458         4493      4484   \n",
       "2991  4448    1761  2856       2528      4459         4494      4489   \n",
       "2992  4447    1795  2855        402      4460         4495      4490   \n",
       "2993  4446    4259  2854       2594      4461         4496      4493   \n",
       "2994  4445    3691  2853       2526      4462         4497      4495   \n",
       "2995  4444    1086  2852        370      4463         4498      4496   \n",
       "2996  4443    3352  2878        171      4464         4499      4498   \n",
       "2997  4442    2259  2879        514      4465         4500      4500   \n",
       "2998  4441    2618  2880       1280      4466         4501      4501   \n",
       "2999  4440    1320  2894       2819      4468         4502      4502   \n",
       "3000  4439     827  2905       2242      4502         4503      4503   \n",
       "3001  4438    1456  2904       3332      4504         4504      4504   \n",
       "\n",
       "      extraTree_sort  \n",
       "0                  0  \n",
       "1                  1  \n",
       "2                  2  \n",
       "3                  4  \n",
       "4                  5  \n",
       "5                  6  \n",
       "6                  7  \n",
       "7                  8  \n",
       "8                  9  \n",
       "9                 10  \n",
       "10                11  \n",
       "11                12  \n",
       "12                13  \n",
       "13                14  \n",
       "14                15  \n",
       "15                16  \n",
       "16                17  \n",
       "17                18  \n",
       "18                19  \n",
       "19                20  \n",
       "20                21  \n",
       "21                22  \n",
       "22                23  \n",
       "23                24  \n",
       "24                25  \n",
       "25                26  \n",
       "26                27  \n",
       "27                28  \n",
       "28                29  \n",
       "29                30  \n",
       "...              ...  \n",
       "2972            4474  \n",
       "2973            4475  \n",
       "2974            4476  \n",
       "2975            4477  \n",
       "2976            4478  \n",
       "2977            4479  \n",
       "2978            4480  \n",
       "2979            4481  \n",
       "2980            4482  \n",
       "2981            4483  \n",
       "2982            4484  \n",
       "2983            4485  \n",
       "2984            4486  \n",
       "2985            4487  \n",
       "2986            4488  \n",
       "2987            4489  \n",
       "2988            4490  \n",
       "2989            4491  \n",
       "2990            4493  \n",
       "2991            4494  \n",
       "2992            4495  \n",
       "2993            4496  \n",
       "2994            4497  \n",
       "2995            4498  \n",
       "2996            4499  \n",
       "2997            4500  \n",
       "2998            4501  \n",
       "2999            4502  \n",
       "3000            4503  \n",
       "3001            4504  \n",
       "\n",
       "[3002 rows x 8 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = pd.DataFrame([index1, index2, index3, index5, \n",
    "                    index1.sort_values(), index2.sort_values(), index3.sort_values(), index5.sort_values()]).transpose()\n",
    "imp.columns=[['ada','forest','xgb','extraTree', 'ada_sort','forest_sort','xgb_sort','extraTree_sort']]\n",
    "imp.to_csv('feature_importance_2D3.csv', index=False)\n",
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
