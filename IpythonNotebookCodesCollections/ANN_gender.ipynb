{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !ls -hl|grep csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time, ctime\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, classification, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, StratifiedShuffleSplit\n",
    "\n",
    "from helper import plot_confusion_matrix, plot_confusion_matrix2\n",
    "dim=lambda *x: [i.shape for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=24, \n",
    "                        inter_op_parallelism_threads=24,\n",
    "                        allow_soft_placement=True, \n",
    "                        device_count = {'CPU': 1})\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49260, 748)\n",
      "CPU times: user 2.98 s, sys: 201 ms, total: 3.18 s\n",
      "Wall time: 3.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('./preprocessed.csv')\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>fname.gender</th>\n",
       "      <th>username_split_predict</th>\n",
       "      <th>last</th>\n",
       "      <th>last_two</th>\n",
       "      <th>first</th>\n",
       "      <th>first2</th>\n",
       "      <th>nchar</th>\n",
       "      <th>vowels.pct</th>\n",
       "      <th>digits.pct</th>\n",
       "      <th>last_is_vowel</th>\n",
       "      <th>first_is_vowel</th>\n",
       "      <th>last_is_digit</th>\n",
       "      <th>first_is_digit</th>\n",
       "      <th>digits.num</th>\n",
       "      <th>upper.pct</th>\n",
       "      <th>first_is_upper</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "      <th>feature_25</th>\n",
       "      <th>feature_26</th>\n",
       "      <th>feature_27</th>\n",
       "      <th>feature_28</th>\n",
       "      <th>feature_29</th>\n",
       "      <th>feature_30</th>\n",
       "      <th>feature_31</th>\n",
       "      <th>feature_32</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_681</th>\n",
       "      <th>feature_682</th>\n",
       "      <th>feature_683</th>\n",
       "      <th>feature_684</th>\n",
       "      <th>feature_685</th>\n",
       "      <th>feature_686</th>\n",
       "      <th>feature_687</th>\n",
       "      <th>feature_688</th>\n",
       "      <th>feature_689</th>\n",
       "      <th>feature_690</th>\n",
       "      <th>feature_691</th>\n",
       "      <th>feature_692</th>\n",
       "      <th>feature_693</th>\n",
       "      <th>feature_694</th>\n",
       "      <th>feature_695</th>\n",
       "      <th>feature_696</th>\n",
       "      <th>feature_697</th>\n",
       "      <th>feature_698</th>\n",
       "      <th>feature_699</th>\n",
       "      <th>feature_700</th>\n",
       "      <th>feature_701</th>\n",
       "      <th>feature_702</th>\n",
       "      <th>feature_703</th>\n",
       "      <th>feature_704</th>\n",
       "      <th>feature_705</th>\n",
       "      <th>feature_706</th>\n",
       "      <th>feature_707</th>\n",
       "      <th>feature_708</th>\n",
       "      <th>feature_709</th>\n",
       "      <th>feature_710</th>\n",
       "      <th>feature_711</th>\n",
       "      <th>feature_712</th>\n",
       "      <th>feature_713</th>\n",
       "      <th>feature_714</th>\n",
       "      <th>feature_715</th>\n",
       "      <th>feature_716</th>\n",
       "      <th>feature_717</th>\n",
       "      <th>feature_718</th>\n",
       "      <th>feature_719</th>\n",
       "      <th>feature_720</th>\n",
       "      <th>feature_721</th>\n",
       "      <th>feature_722</th>\n",
       "      <th>feature_723</th>\n",
       "      <th>feature_724</th>\n",
       "      <th>feature_725</th>\n",
       "      <th>feature_726</th>\n",
       "      <th>feature_727</th>\n",
       "      <th>feature_728</th>\n",
       "      <th>feature_729</th>\n",
       "      <th>feature_730</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>billion</td>\n",
       "      <td>male</td>\n",
       "      <td>unknow</td>\n",
       "      <td>n</td>\n",
       "      <td>on</td>\n",
       "      <td>b</td>\n",
       "      <td>bi</td>\n",
       "      <td>7</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ArmenSoft</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>t</td>\n",
       "      <td>ft</td>\n",
       "      <td>A</td>\n",
       "      <td>Ar</td>\n",
       "      <td>9</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>okbookman</td>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>n</td>\n",
       "      <td>an</td>\n",
       "      <td>o</td>\n",
       "      <td>ok</td>\n",
       "      <td>9</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 748 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    username fname.gender username_split_predict last last_two first first2  \\\n",
       "0    billion         male                 unknow    n       on     b     bi   \n",
       "1  ArmenSoft         male                   male    t       ft     A     Ar   \n",
       "2  okbookman         male                 female    n       an     o     ok   \n",
       "\n",
       "   nchar  vowels.pct  digits.pct  last_is_vowel  first_is_vowel  \\\n",
       "0      7    0.428571         0.0          False           False   \n",
       "1      9    0.222222         0.0          False           False   \n",
       "2      9    0.444444         0.0          False            True   \n",
       "\n",
       "   last_is_digit  first_is_digit  digits.num  upper.pct  first_is_upper  \\\n",
       "0          False           False           0          0           False   \n",
       "1          False           False           0          2            True   \n",
       "2          False           False           0          0           False   \n",
       "\n",
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0        0.0        1.0        0.0        0.0        0.0        0.0   \n",
       "1        1.0        0.0        0.0        0.0        1.0        1.0   \n",
       "2        1.0        1.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  feature_10  feature_11  \\\n",
       "0        0.0        0.0        2.0        0.0         0.0         2.0   \n",
       "1        0.0        0.0        0.0        0.0         0.0         0.0   \n",
       "2        0.0        0.0        0.0        0.0         2.0         0.0   \n",
       "\n",
       "   feature_12  feature_13  feature_14  feature_15  feature_16  feature_17  \\\n",
       "0         0.0         1.0         1.0         0.0         0.0         0.0   \n",
       "1         1.0         1.0         1.0         0.0         0.0         1.0   \n",
       "2         1.0         1.0         3.0         0.0         0.0         0.0   \n",
       "\n",
       "   feature_18  feature_19  feature_20  feature_21  feature_22  feature_23  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         1.0         1.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   feature_24  feature_25  feature_26  feature_27  feature_28  feature_29  \\\n",
       "0         0.0         0.0         0.0         1.0         0.0         0.0   \n",
       "1         0.0         0.0         1.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         8.0         3.0         0.0         0.0   \n",
       "\n",
       "   feature_30  feature_31  feature_32     ...       feature_681  feature_682  \\\n",
       "0         0.0         0.0         0.0     ...               0.0          0.0   \n",
       "1         4.0         8.0         0.0     ...               0.0          0.0   \n",
       "2         0.0         0.0         0.0     ...               0.0          0.0   \n",
       "\n",
       "   feature_683  feature_684  feature_685  feature_686  feature_687  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_688  feature_689  feature_690  feature_691  feature_692  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_693  feature_694  feature_695  feature_696  feature_697  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_698  feature_699  feature_700  feature_701  feature_702  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_703  feature_704  feature_705  feature_706  feature_707  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_708  feature_709  feature_710  feature_711  feature_712  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_713  feature_714  feature_715  feature_716  feature_717  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_718  feature_719  feature_720  feature_721  feature_722  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_723  feature_724  feature_725  feature_726  feature_727  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_728  feature_729  feature_730  \n",
       "0         13.0         14.0          7.0  \n",
       "1         19.0          5.0          9.0  \n",
       "2         13.0          0.0          9.0  \n",
       "\n",
       "[3 rows x 748 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns=100\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# print df.columns.values[2:9]\n",
    "# def label_encode(df, columns):\n",
    "#     for col in columns:\n",
    "#         le = LabelEncoder()\n",
    "#         col_values_unique = list(df[col].unique())\n",
    "#         le_fitted = le.fit(col_values_unique)\n",
    " \n",
    "#         col_values = list(df[col].values)\n",
    "#         le.classes_\n",
    "#         col_values_transformed = le.transform(col_values)\n",
    "#         df[col] = col_values_transformed\n",
    " \n",
    "# to_be_encoded_cols = df.columns.values[2:9]\n",
    "# label_encode(df, to_be_encoded_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>fname.gender</th>\n",
       "      <th>username_split_predict</th>\n",
       "      <th>last</th>\n",
       "      <th>last_two</th>\n",
       "      <th>first</th>\n",
       "      <th>first2</th>\n",
       "      <th>nchar</th>\n",
       "      <th>vowels.pct</th>\n",
       "      <th>digits.pct</th>\n",
       "      <th>last_is_vowel</th>\n",
       "      <th>first_is_vowel</th>\n",
       "      <th>last_is_digit</th>\n",
       "      <th>first_is_digit</th>\n",
       "      <th>digits.num</th>\n",
       "      <th>upper.pct</th>\n",
       "      <th>first_is_upper</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "      <th>feature_25</th>\n",
       "      <th>feature_26</th>\n",
       "      <th>feature_27</th>\n",
       "      <th>feature_28</th>\n",
       "      <th>feature_29</th>\n",
       "      <th>feature_30</th>\n",
       "      <th>feature_31</th>\n",
       "      <th>feature_32</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_681</th>\n",
       "      <th>feature_682</th>\n",
       "      <th>feature_683</th>\n",
       "      <th>feature_684</th>\n",
       "      <th>feature_685</th>\n",
       "      <th>feature_686</th>\n",
       "      <th>feature_687</th>\n",
       "      <th>feature_688</th>\n",
       "      <th>feature_689</th>\n",
       "      <th>feature_690</th>\n",
       "      <th>feature_691</th>\n",
       "      <th>feature_692</th>\n",
       "      <th>feature_693</th>\n",
       "      <th>feature_694</th>\n",
       "      <th>feature_695</th>\n",
       "      <th>feature_696</th>\n",
       "      <th>feature_697</th>\n",
       "      <th>feature_698</th>\n",
       "      <th>feature_699</th>\n",
       "      <th>feature_700</th>\n",
       "      <th>feature_701</th>\n",
       "      <th>feature_702</th>\n",
       "      <th>feature_703</th>\n",
       "      <th>feature_704</th>\n",
       "      <th>feature_705</th>\n",
       "      <th>feature_706</th>\n",
       "      <th>feature_707</th>\n",
       "      <th>feature_708</th>\n",
       "      <th>feature_709</th>\n",
       "      <th>feature_710</th>\n",
       "      <th>feature_711</th>\n",
       "      <th>feature_712</th>\n",
       "      <th>feature_713</th>\n",
       "      <th>feature_714</th>\n",
       "      <th>feature_715</th>\n",
       "      <th>feature_716</th>\n",
       "      <th>feature_717</th>\n",
       "      <th>feature_718</th>\n",
       "      <th>feature_719</th>\n",
       "      <th>feature_720</th>\n",
       "      <th>feature_721</th>\n",
       "      <th>feature_722</th>\n",
       "      <th>feature_723</th>\n",
       "      <th>feature_724</th>\n",
       "      <th>feature_725</th>\n",
       "      <th>feature_726</th>\n",
       "      <th>feature_727</th>\n",
       "      <th>feature_728</th>\n",
       "      <th>feature_729</th>\n",
       "      <th>feature_730</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>billion</td>\n",
       "      <td>male</td>\n",
       "      <td>unknow</td>\n",
       "      <td>n</td>\n",
       "      <td>on</td>\n",
       "      <td>b</td>\n",
       "      <td>bi</td>\n",
       "      <td>7</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ArmenSoft</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>t</td>\n",
       "      <td>ft</td>\n",
       "      <td>A</td>\n",
       "      <td>Ar</td>\n",
       "      <td>9</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>okbookman</td>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>n</td>\n",
       "      <td>an</td>\n",
       "      <td>o</td>\n",
       "      <td>ok</td>\n",
       "      <td>9</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 748 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    username fname.gender username_split_predict last last_two first first2  \\\n",
       "0    billion         male                 unknow    n       on     b     bi   \n",
       "1  ArmenSoft         male                   male    t       ft     A     Ar   \n",
       "2  okbookman         male                 female    n       an     o     ok   \n",
       "\n",
       "   nchar  vowels.pct  digits.pct  last_is_vowel  first_is_vowel  \\\n",
       "0      7    0.428571         0.0          False           False   \n",
       "1      9    0.222222         0.0          False           False   \n",
       "2      9    0.444444         0.0          False            True   \n",
       "\n",
       "   last_is_digit  first_is_digit  digits.num  upper.pct  first_is_upper  \\\n",
       "0          False           False           0          0           False   \n",
       "1          False           False           0          2            True   \n",
       "2          False           False           0          0           False   \n",
       "\n",
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0        0.0        1.0        0.0        0.0        0.0        0.0   \n",
       "1        1.0        0.0        0.0        0.0        1.0        1.0   \n",
       "2        1.0        1.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  feature_10  feature_11  \\\n",
       "0        0.0        0.0        2.0        0.0         0.0         2.0   \n",
       "1        0.0        0.0        0.0        0.0         0.0         0.0   \n",
       "2        0.0        0.0        0.0        0.0         2.0         0.0   \n",
       "\n",
       "   feature_12  feature_13  feature_14  feature_15  feature_16  feature_17  \\\n",
       "0         0.0         1.0         1.0         0.0         0.0         0.0   \n",
       "1         1.0         1.0         1.0         0.0         0.0         1.0   \n",
       "2         1.0         1.0         3.0         0.0         0.0         0.0   \n",
       "\n",
       "   feature_18  feature_19  feature_20  feature_21  feature_22  feature_23  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         1.0         1.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   feature_24  feature_25  feature_26  feature_27  feature_28  feature_29  \\\n",
       "0         0.0         0.0         0.0         1.0         0.0         0.0   \n",
       "1         0.0         0.0         1.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         8.0         3.0         0.0         0.0   \n",
       "\n",
       "   feature_30  feature_31  feature_32     ...       feature_681  feature_682  \\\n",
       "0         0.0         0.0         0.0     ...               0.0          0.0   \n",
       "1         4.0         8.0         0.0     ...               0.0          0.0   \n",
       "2         0.0         0.0         0.0     ...               0.0          0.0   \n",
       "\n",
       "   feature_683  feature_684  feature_685  feature_686  feature_687  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_688  feature_689  feature_690  feature_691  feature_692  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_693  feature_694  feature_695  feature_696  feature_697  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_698  feature_699  feature_700  feature_701  feature_702  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_703  feature_704  feature_705  feature_706  feature_707  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_708  feature_709  feature_710  feature_711  feature_712  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_713  feature_714  feature_715  feature_716  feature_717  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_718  feature_719  feature_720  feature_721  feature_722  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_723  feature_724  feature_725  feature_726  feature_727  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_728  feature_729  feature_730  \n",
       "0         13.0         14.0          7.0  \n",
       "1         19.0          5.0          9.0  \n",
       "2         13.0          0.0          9.0  \n",
       "\n",
       "[3 rows x 748 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17179171194680952400\n",
      "]\n",
      "CPU times: user 0 ns, sys: 1e+03 µs, total: 1e+03 µs\n",
      "Wall time: 467 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test =train_test_split(pre0.iloc[:,2:], pre0.iloc[:,1], test_size=.3, stratify =pre0.iloc[:,1], \n",
    "#                                                   random_state=7)\n",
    "# print dim(X_train, y_train, X_test, y_test )\n",
    "# X_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49260, 746)\n",
      "(49260,)\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:,2:].values\n",
    "print X.shape\n",
    "y = df.iloc[:,1].map({'male':1,'female':0}).values\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.2 s, sys: 41 ms, total: 1.24 s\n",
      "Wall time: 1.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Encoding the Independent Variable\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 0] = labelencoder_X_1.fit_transform(X[:, 0])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_2.fit_transform(X[:, 1])\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_1.fit_transform(X[:, 2])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 3] = labelencoder_X_2.fit_transform(X[:, 3])\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 4] = labelencoder_X_1.fit_transform(X[:, 4])\n",
    "XX=X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# print X.shape\n",
    "# onehotencoder = OneHotEncoder(categorical_features = range(6))\n",
    "# X = onehotencoder.fit_transform(X).toarray()\n",
    "# print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # remove one dummy variable to avoid dummy variable trap\n",
    "# print X.shape\n",
    "# X = X[:, 1:]\n",
    "# print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(34482, 746), (14778, 746), (34482,), (14778,)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                   random_state=7)\n",
    "dim(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shj16110/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(34482, 746), (14778, 746), (34482,), (14778,)]\n",
      "CPU times: user 6.17 s, sys: 171 ms, total: 6.34 s\n",
      "Wall time: 6.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "# fit on training set\n",
    "X_train = sc.fit_transform(X_train)\n",
    "# only transform on test set\n",
    "X_test = sc.transform(X_test)\n",
    "print dim(X_train,X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_103 (Dense)            (None, 96)                71712     \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 64)                6208      \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 48)                3120      \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 24)                792       \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 16)                400       \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 87,089\n",
      "Trainable params: 87,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "# first hidden layer\n",
    "classifier.add(Dense(units = 128, \n",
    "#                      input_dim=4504, \n",
    "                     input_dim=746,\n",
    "                     kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.3))\n",
    "# second hidden layer\n",
    "classifier.add(Dense(units = 96,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.2))\n",
    "# second hidden layer\n",
    "classifier.add(Dense(units = 64,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "# thrid hidden layer\n",
    "classifier.add(Dense(units = 48,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "# thrid hidden layer\n",
    "classifier.add(Dense(units = 32,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "# thrid hidden layer\n",
    "classifier.add(Dense(units = 24,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "# thrid hidden layer\n",
    "classifier.add(Dense(units = 24,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "# thrid hidden layer\n",
    "classifier.add(Dense(units = 24,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "# thrid hidden layer\n",
    "classifier.add(Dense(units = 24,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "# thrid hidden layer\n",
    "classifier.add(Dense(units = 24,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "# thrid hidden layer\n",
    "classifier.add(Dense(units = 24,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "# thrid hidden layer\n",
    "classifier.add(Dense(units = 16,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "# thrid hidden layer\n",
    "classifier.add(Dense(units = 16,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "# # ouput layer\n",
    "classifier.add(Dense(units = 1,  kernel_initializer='uniform', activation='sigmoid'))\n",
    "# compiling the ANN\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics= ['accuracy'])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback, EarlyStopping\n",
    "class TestCallback(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "        \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=1)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopping = EarlyStopping(monitor='acc', min_delta=0,\n",
    "                              patience=6, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34482 samples, validate on 14778 samples\n",
      "Epoch 1/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.3722 - acc: 0.8200 - val_loss: 0.4885 - val_acc: 0.8198\n",
      "Epoch 2/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.3694 - acc: 0.8200 - val_loss: 0.4951 - val_acc: 0.8198\n",
      "Epoch 3/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.3586 - acc: 0.8401 - val_loss: 0.5123 - val_acc: 0.8118\n",
      "Epoch 4/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.3496 - acc: 0.8535 - val_loss: 0.4981 - val_acc: 0.8063\n",
      "Epoch 5/64\n",
      "34482/34482 [==============================] - 2s 65us/step - loss: 0.3434 - acc: 0.8564 - val_loss: 0.5441 - val_acc: 0.8037\n",
      "Epoch 6/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.3360 - acc: 0.8576 - val_loss: 0.6175 - val_acc: 0.8110\n",
      "Epoch 7/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.3305 - acc: 0.8630 - val_loss: 0.5177 - val_acc: 0.8079\n",
      "Epoch 8/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.3286 - acc: 0.8620 - val_loss: 0.5576 - val_acc: 0.8044\n",
      "Epoch 9/64\n",
      "34482/34482 [==============================] - 2s 65us/step - loss: 0.3226 - acc: 0.8671 - val_loss: 0.5557 - val_acc: 0.8071\n",
      "Epoch 10/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.3130 - acc: 0.8698 - val_loss: 0.5365 - val_acc: 0.8084\n",
      "Epoch 11/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.3090 - acc: 0.8747 - val_loss: 0.5684 - val_acc: 0.8153\n",
      "Epoch 12/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.3021 - acc: 0.8758 - val_loss: 0.5452 - val_acc: 0.8119\n",
      "Epoch 13/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2976 - acc: 0.8780 - val_loss: 0.5423 - val_acc: 0.8127\n",
      "Epoch 14/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2953 - acc: 0.8808 - val_loss: 0.5766 - val_acc: 0.8115\n",
      "Epoch 15/64\n",
      "34482/34482 [==============================] - 2s 65us/step - loss: 0.2869 - acc: 0.8834 - val_loss: 0.6099 - val_acc: 0.8098\n",
      "Epoch 16/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2861 - acc: 0.8840 - val_loss: 0.5587 - val_acc: 0.8086\n",
      "Epoch 17/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2802 - acc: 0.8872 - val_loss: 0.6055 - val_acc: 0.8060\n",
      "Epoch 18/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2782 - acc: 0.8864 - val_loss: 0.6068 - val_acc: 0.8117\n",
      "Epoch 19/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2777 - acc: 0.8855 - val_loss: 0.6366 - val_acc: 0.8025\n",
      "Epoch 20/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2711 - acc: 0.8885 - val_loss: 0.6106 - val_acc: 0.8017\n",
      "Epoch 21/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2687 - acc: 0.8910 - val_loss: 0.5645 - val_acc: 0.8003\n",
      "Epoch 22/64\n",
      "34482/34482 [==============================] - 2s 65us/step - loss: 0.2621 - acc: 0.8943 - val_loss: 0.6877 - val_acc: 0.7980\n",
      "Epoch 23/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2576 - acc: 0.8951 - val_loss: 0.7618 - val_acc: 0.8084\n",
      "Epoch 24/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2578 - acc: 0.8949 - val_loss: 0.6570 - val_acc: 0.8065\n",
      "Epoch 25/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2538 - acc: 0.8963 - val_loss: 0.6362 - val_acc: 0.8073\n",
      "Epoch 26/64\n",
      "34482/34482 [==============================] - 2s 65us/step - loss: 0.2491 - acc: 0.9015 - val_loss: 0.5406 - val_acc: 0.8135\n",
      "Epoch 27/64\n",
      "34482/34482 [==============================] - 2s 65us/step - loss: 0.2475 - acc: 0.9009 - val_loss: 0.5957 - val_acc: 0.7982\n",
      "Epoch 28/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2476 - acc: 0.9030 - val_loss: 0.7263 - val_acc: 0.8059\n",
      "Epoch 29/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2419 - acc: 0.9035 - val_loss: 0.7398 - val_acc: 0.8061\n",
      "Epoch 30/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2379 - acc: 0.9044 - val_loss: 0.6707 - val_acc: 0.7950\n",
      "Epoch 31/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2358 - acc: 0.9073 - val_loss: 0.7408 - val_acc: 0.8098\n",
      "Epoch 32/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2374 - acc: 0.9075 - val_loss: 0.5981 - val_acc: 0.8001\n",
      "Epoch 33/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2300 - acc: 0.9093 - val_loss: 0.7704 - val_acc: 0.8094\n",
      "Epoch 34/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2247 - acc: 0.9130 - val_loss: 0.6187 - val_acc: 0.8064\n",
      "Epoch 35/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2262 - acc: 0.9114 - val_loss: 0.6888 - val_acc: 0.7967\n",
      "Epoch 36/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2217 - acc: 0.9104 - val_loss: 0.7528 - val_acc: 0.8007\n",
      "Epoch 37/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2215 - acc: 0.9131 - val_loss: 0.7063 - val_acc: 0.7992\n",
      "Epoch 38/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2209 - acc: 0.9131 - val_loss: 0.6340 - val_acc: 0.7992\n",
      "Epoch 39/64\n",
      "34482/34482 [==============================] - 2s 65us/step - loss: 0.2174 - acc: 0.9156 - val_loss: 0.8587 - val_acc: 0.8123\n",
      "Epoch 40/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2153 - acc: 0.9170 - val_loss: 0.6753 - val_acc: 0.7878\n",
      "Epoch 41/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2140 - acc: 0.9155 - val_loss: 0.6303 - val_acc: 0.7936\n",
      "Epoch 42/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2117 - acc: 0.9177 - val_loss: 0.6712 - val_acc: 0.8037\n",
      "Epoch 43/64\n",
      "34482/34482 [==============================] - 2s 65us/step - loss: 0.2070 - acc: 0.9182 - val_loss: 0.7031 - val_acc: 0.8077\n",
      "Epoch 44/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2090 - acc: 0.9179 - val_loss: 0.6690 - val_acc: 0.8048\n",
      "Epoch 45/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2098 - acc: 0.9180 - val_loss: 0.6931 - val_acc: 0.7887\n",
      "Epoch 46/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2069 - acc: 0.9180 - val_loss: 0.7908 - val_acc: 0.8026\n",
      "Epoch 47/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2004 - acc: 0.9212 - val_loss: 0.6864 - val_acc: 0.7937\n",
      "Epoch 48/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.1994 - acc: 0.9221 - val_loss: 0.8505 - val_acc: 0.8011\n",
      "Epoch 49/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.2007 - acc: 0.9219 - val_loss: 0.7027 - val_acc: 0.7912\n",
      "Epoch 50/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.1949 - acc: 0.9223 - val_loss: 0.7502 - val_acc: 0.7839\n",
      "Epoch 51/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.1943 - acc: 0.9232 - val_loss: 0.7022 - val_acc: 0.8034\n",
      "Epoch 52/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.1966 - acc: 0.9240 - val_loss: 0.8215 - val_acc: 0.7949\n",
      "Epoch 53/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.1890 - acc: 0.9268 - val_loss: 0.7906 - val_acc: 0.7839\n",
      "Epoch 54/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.1926 - acc: 0.9270 - val_loss: 0.7137 - val_acc: 0.7955\n",
      "Epoch 55/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.1882 - acc: 0.9280 - val_loss: 0.8526 - val_acc: 0.7939\n",
      "Epoch 56/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.1890 - acc: 0.9270 - val_loss: 0.7365 - val_acc: 0.7921\n",
      "Epoch 57/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.1896 - acc: 0.9255 - val_loss: 0.9020 - val_acc: 0.8015\n",
      "Epoch 58/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.1860 - acc: 0.9292 - val_loss: 0.8042 - val_acc: 0.7978\n",
      "Epoch 59/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.1871 - acc: 0.9284 - val_loss: 0.7848 - val_acc: 0.7961\n",
      "Epoch 60/64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.1799 - acc: 0.9310 - val_loss: 0.8376 - val_acc: 0.7935\n",
      "Epoch 61/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.1807 - acc: 0.9302 - val_loss: 0.7333 - val_acc: 0.7913\n",
      "Epoch 62/64\n",
      "34482/34482 [==============================] - 2s 65us/step - loss: 0.1740 - acc: 0.9327 - val_loss: 0.7741 - val_acc: 0.7915\n",
      "Epoch 63/64\n",
      "34482/34482 [==============================] - 2s 64us/step - loss: 0.1785 - acc: 0.9301 - val_loss: 0.9402 - val_acc: 0.7952\n",
      "Epoch 64/64\n",
      "34482/34482 [==============================] - 2s 65us/step - loss: 0.1763 - acc: 0.9334 - val_loss: 0.7136 - val_acc: 0.7912\n",
      "CPU times: user 6min 9s, sys: 2min 53s, total: 9min 2s\n",
      "Wall time: 2min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b9e5cf2dad0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# fitting ANN with training set\n",
    "classifier.fit(X_train, y_train, \n",
    "               batch_size=64, epochs=64,\n",
    "               validation_data=(X_test, y_test),\n",
    "#           callbacks=[TestCallback((X_test, y_test))])\n",
    "          callbacks=[stopping])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79117607254\n",
      "Confusion matrix, without normalization\n",
      "[[  703  1960]\n",
      " [ 1126 10989]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV8AAAEmCAYAAADFmJOIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzKwIHHzNzIrAwdfMrAj+H2xgeoK+jicyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b9e64f10250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.08 s, sys: 377 ms, total: 1.46 s\n",
      "Wall time: 592 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred> 0.5)\n",
    "\n",
    "print accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plot_confusion_matrix(cm, ['female','male'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# k-fold cross validation\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
