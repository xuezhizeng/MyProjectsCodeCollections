{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !wget http://www.superdatascience.com/wp-content/uploads/2017/04/Convolutional_Neural_Networks.zip\n",
    "# !unzip Convolutional_Neural_Networks.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13545750763751998855\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5584994304\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 12762224606731568232\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 192)       5376      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 192)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 31, 31, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 128)       221312    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 595,649\n",
      "Trainable params: 595,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# initializing\n",
    "classifier = Sequential()\n",
    "# Step 1  - Convolution\n",
    "classifier.add(Convolution2D(192, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "# step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Dropout(rate= 0.03))\n",
    "\n",
    "# add another convolution layer\n",
    "classifier.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Dropout(rate= 0.02))\n",
    "\n",
    "# add another convolution layer\n",
    "classifier.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Dropout(rate= 0.01))\n",
    "\n",
    "# step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "# step 4 - full Connection\n",
    "classifier.add(Dense(128, activation='relu'))\n",
    "# step 5 - Output layer\n",
    "classifier.add(Dense(1, activation='sigmoid'))\n",
    "# compile\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image proprocessing & trainning, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1.0, 7.0, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !dir dataset\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "1, 1.,7., 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'dataset/training_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'dataset/test_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "500/500 [==============================] - 23s - loss: 0.6910 - acc: 0.5297 - val_loss: 0.6906 - val_acc: 0.5180\n",
      "Epoch 2/40\n",
      "500/500 [==============================] - 22s - loss: 0.6784 - acc: 0.5706 - val_loss: 0.6585 - val_acc: 0.6290\n",
      "Epoch 3/40\n",
      "500/500 [==============================] - 22s - loss: 0.6383 - acc: 0.6359 - val_loss: 0.6282 - val_acc: 0.6530\n",
      "Epoch 4/40\n",
      "500/500 [==============================] - 23s - loss: 0.5869 - acc: 0.6907 - val_loss: 0.5961 - val_acc: 0.7000\n",
      "Epoch 5/40\n",
      "500/500 [==============================] - 23s - loss: 0.5591 - acc: 0.7115 - val_loss: 0.5382 - val_acc: 0.7270\n",
      "Epoch 6/40\n",
      "500/500 [==============================] - 22s - loss: 0.5268 - acc: 0.7281 - val_loss: 0.5037 - val_acc: 0.7570\n",
      "Epoch 7/40\n",
      "500/500 [==============================] - 22s - loss: 0.4993 - acc: 0.7550 - val_loss: 0.4781 - val_acc: 0.7775\n",
      "Epoch 8/40\n",
      "500/500 [==============================] - 22s - loss: 0.4788 - acc: 0.7699 - val_loss: 0.4583 - val_acc: 0.7775\n",
      "Epoch 9/40\n",
      "500/500 [==============================] - 21s - loss: 0.4611 - acc: 0.7809 - val_loss: 0.4314 - val_acc: 0.8020\n",
      "Epoch 10/40\n",
      "500/500 [==============================] - 22s - loss: 0.4425 - acc: 0.7915 - val_loss: 0.4680 - val_acc: 0.7790\n",
      "Epoch 11/40\n",
      "500/500 [==============================] - 22s - loss: 0.4253 - acc: 0.8025 - val_loss: 0.4058 - val_acc: 0.8180\n",
      "Epoch 12/40\n",
      "500/500 [==============================] - 22s - loss: 0.4120 - acc: 0.8120 - val_loss: 0.4316 - val_acc: 0.8130\n",
      "Epoch 13/40\n",
      "500/500 [==============================] - 22s - loss: 0.4009 - acc: 0.8171 - val_loss: 0.3911 - val_acc: 0.8145\n",
      "Epoch 14/40\n",
      "500/500 [==============================] - 22s - loss: 0.3908 - acc: 0.8189 - val_loss: 0.3790 - val_acc: 0.8265\n",
      "Epoch 15/40\n",
      "500/500 [==============================] - 22s - loss: 0.3738 - acc: 0.8310 - val_loss: 0.4489 - val_acc: 0.7965\n",
      "Epoch 16/40\n",
      "500/500 [==============================] - 22s - loss: 0.3580 - acc: 0.8366 - val_loss: 0.3675 - val_acc: 0.8335\n",
      "Epoch 17/40\n",
      "500/500 [==============================] - 22s - loss: 0.3504 - acc: 0.8404 - val_loss: 0.3753 - val_acc: 0.8320\n",
      "Epoch 18/40\n",
      "500/500 [==============================] - 22s - loss: 0.3400 - acc: 0.8466 - val_loss: 0.3381 - val_acc: 0.8505\n",
      "Epoch 19/40\n",
      "500/500 [==============================] - 22s - loss: 0.3330 - acc: 0.8520 - val_loss: 0.3782 - val_acc: 0.8365\n",
      "Epoch 20/40\n",
      "500/500 [==============================] - 22s - loss: 0.3212 - acc: 0.8581 - val_loss: 0.3580 - val_acc: 0.8550\n",
      "Epoch 21/40\n",
      "500/500 [==============================] - 22s - loss: 0.3066 - acc: 0.8644 - val_loss: 0.3714 - val_acc: 0.8415\n",
      "Epoch 22/40\n",
      "500/500 [==============================] - 22s - loss: 0.3059 - acc: 0.8659 - val_loss: 0.3481 - val_acc: 0.8595\n",
      "Epoch 23/40\n",
      "500/500 [==============================] - 22s - loss: 0.2969 - acc: 0.8699 - val_loss: 0.3798 - val_acc: 0.8355\n",
      "Epoch 24/40\n",
      "500/500 [==============================] - 22s - loss: 0.2918 - acc: 0.8735 - val_loss: 0.3717 - val_acc: 0.8445\n",
      "Epoch 25/40\n",
      "500/500 [==============================] - 22s - loss: 0.2855 - acc: 0.8781 - val_loss: 0.3766 - val_acc: 0.8450\n",
      "Epoch 26/40\n",
      "500/500 [==============================] - 22s - loss: 0.2735 - acc: 0.8854 - val_loss: 0.3625 - val_acc: 0.8520\n",
      "Epoch 27/40\n",
      "500/500 [==============================] - 22s - loss: 0.2719 - acc: 0.8816 - val_loss: 0.3949 - val_acc: 0.8385\n",
      "Epoch 28/40\n",
      "500/500 [==============================] - 22s - loss: 0.2680 - acc: 0.8841 - val_loss: 0.3428 - val_acc: 0.8595\n",
      "Epoch 29/40\n",
      "500/500 [==============================] - 22s - loss: 0.2519 - acc: 0.8933 - val_loss: 0.3719 - val_acc: 0.8545\n",
      "Epoch 30/40\n",
      "500/500 [==============================] - 22s - loss: 0.2470 - acc: 0.8946 - val_loss: 0.3939 - val_acc: 0.8460\n",
      "Epoch 31/40\n",
      "500/500 [==============================] - 22s - loss: 0.2368 - acc: 0.8954 - val_loss: 0.3884 - val_acc: 0.8480\n",
      "Epoch 32/40\n",
      "500/500 [==============================] - 22s - loss: 0.2395 - acc: 0.8982 - val_loss: 0.4428 - val_acc: 0.8200\n",
      "Epoch 33/40\n",
      "500/500 [==============================] - 22s - loss: 0.2298 - acc: 0.9054 - val_loss: 0.3845 - val_acc: 0.8435\n",
      "Epoch 34/40\n",
      "500/500 [==============================] - 22s - loss: 0.2240 - acc: 0.9052 - val_loss: 0.3655 - val_acc: 0.8650\n",
      "Epoch 35/40\n",
      "500/500 [==============================] - 22s - loss: 0.2069 - acc: 0.9122 - val_loss: 0.3810 - val_acc: 0.8500\n",
      "Epoch 36/40\n",
      "500/500 [==============================] - 22s - loss: 0.2220 - acc: 0.9064 - val_loss: 0.3903 - val_acc: 0.8425\n",
      "Epoch 37/40\n",
      "500/500 [==============================] - 22s - loss: 0.2060 - acc: 0.9145 - val_loss: 0.4208 - val_acc: 0.8385\n",
      "Epoch 38/40\n",
      "500/500 [==============================] - 22s - loss: 0.1990 - acc: 0.9150 - val_loss: 0.3930 - val_acc: 0.8585\n",
      "Epoch 39/40\n",
      "500/500 [==============================] - 22s - loss: 0.2000 - acc: 0.9167 - val_loss: 0.4574 - val_acc: 0.8535\n",
      "Epoch 40/40\n",
      "500/500 [==============================] - 22s - loss: 0.1961 - acc: 0.9178 - val_loss: 0.3980 - val_acc: 0.8580\n",
      "used: 893.66 s\n"
     ]
    }
   ],
   "source": [
    "from time import time, ctime\n",
    "start = time()\n",
    "classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch= 8000/16,\n",
    "        epochs=40,\n",
    "        validation_data= test_set,\n",
    "        validation_steps= 2000/16)\n",
    "eclipse=time()-start\n",
    "print ('used: {:.2f} s'.format(eclipse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "893.6640000343323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Thu Oct 26 23:01:41 2017'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (eclipse)\n",
    "ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.894400000572205"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclipse/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classifier.predict_generator(\n",
    "#     test_datagen.flow_from_directory(\n",
    "#         'Convolutional_Neural_Networks/dataset/single_prediction/',\n",
    "#         target_size=(64, 64),\n",
    "#         batch_size=2,\n",
    "#         class_mode='binary'),  steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classifier.predict_generator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
