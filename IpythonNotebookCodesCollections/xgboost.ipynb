{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# import sys\n",
    "# # sys.setdefaultencoding() does not exist, here!\n",
    "# reload(sys)  # Reload does the trick!\n",
    "# sys.setdefaultencoding('UTF8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from time import time\n",
    "\n",
    "from time import time\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "english_stemmer=nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection.univariate_selection import SelectKBest, chi2, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor, LogisticRegression, PassiveAggressiveClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_wordlist( review, remove_stopwords=False):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review, \"lxml\").get_text()\n",
    "\n",
    "    #\n",
    "    # 2. Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (True by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "\n",
    "    b=[]\n",
    "    stemmer = english_stemmer #PorterStemmer()\n",
    "    for word in words:\n",
    "        b.append(stemmer.stem(word))\n",
    "\n",
    "    # 5. Return a list of words\n",
    "    return(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25191, 2)\n",
      "(8309, 1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('sentiment_train.xlsx')\n",
    "print (df.shape)\n",
    "\n",
    "holdout = pd.read_excel('sentiment_test.xlsx')\n",
    "print (holdout.shape)\n",
    "\n",
    "holdout['content'] = holdout['content'].apply(str)\n",
    "df['content'] = df['content'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used: 11.59s\n"
     ]
    }
   ],
   "source": [
    "start=time()\n",
    "clean_train_reviews = []\n",
    "for review in df['content']:\n",
    "    clean_train_reviews.append( \" \".join(review_to_wordlist(review)))\n",
    "    \n",
    "clean_test_reviews = []\n",
    "for review in holdout['content']:\n",
    "    clean_test_reviews.append( \" \".join(review_to_wordlist(review)))\n",
    "    \n",
    "print ('used: {:.2f}s'.format(time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['funer ceremoni gloomi friday',\n",
       " 'dannycastillo we want to trade with someon who has houston ticket but no one will',\n",
       " 're ping ghostridah whi didn t you go to prom bc my bf didn t like my friend',\n",
       " 'i should be sleep but im not think about an old friend who i want but he s marri now damn amp he want me scandal',\n",
       " 'hmmm http www djhero com is down',\n",
       " 'charviray charlen my love i miss you',\n",
       " 'kelcouch i m sorri at least it s friday',\n",
       " 'cant fall asleep',\n",
       " 'brodyjenn if u watch the hill in london u will realis what tourtur it is becaus were week and week late i just watch itonlinelol',\n",
       " 'got the news']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_reviews[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used: 6.99s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<25191x1085757 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1292973 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start=time()\n",
    "\n",
    "# vectorizer = TfidfVectorizer(\n",
    "# #     min_df=1, max_df=0.95,\n",
    "#                              max_features = 1000000, ngram_range = ( 1, 5 ),\n",
    "# #                               sublinear_tf = True \n",
    "# )\n",
    "\n",
    "vectorizer = CountVectorizer( \n",
    "#     min_df=2, max_df=0.95, \n",
    "#                              max_features = 400000, \n",
    "                             ngram_range = ( 1, 5 ),\n",
    "                              )\n",
    "\n",
    "# vectorizer = HashingVectorizer( ngram_range = ( 1, 5 ),)\n",
    "\n",
    "vectorizer = vectorizer.fit(clean_train_reviews+clean_test_reviews)\n",
    "train_features = vectorizer.transform(clean_train_reviews)\n",
    "\n",
    "test_features = vectorizer.transform(clean_test_reviews)\n",
    "\n",
    "print ('used: {:.2f}s'.format(time()-start))\n",
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori = train_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fselect = SelectKBest(chi2 , k=65400)\n",
    "train_features = fselect.fit_transform(ori, df[\"sentiment\"])\n",
    "\n",
    "test_features = fselect.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used: 7.46s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.41150794,  0.44770788,  0.49364827,  0.4837237 ,  0.43963463])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "model5 = LogisticRegression(\n",
    "#     solver='lbfgs'\n",
    ")\n",
    "# model5.fit( train_features, train[\"sentiment\"] )\n",
    "cv_result = cross_val_score( model5, train_features, df['sentiment'], cv=5)\n",
    "\n",
    "print ('used: {:.2f}s'.format(time()-start))\n",
    "cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used: 33.43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.3640873 ,  0.3826156 ,  0.4162366 ,  0.41127432,  0.37787927])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "model5 = XGBClassifier(\n",
    "    silent=0\n",
    "#     solver='lbfgs'\n",
    ")\n",
    "# model5.fit( train_features, train[\"sentiment\"] )\n",
    "cv_result = cross_val_score( model5, train_features, df['sentiment'], cv=5)\n",
    "\n",
    "print ('used: {:.2f}s'.format(time()-start))\n",
    "cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.55794288\n",
      "Validation score: 0.446825\n",
      "Iteration 2, loss = 1.13033878\n",
      "Validation score: 0.472619\n",
      "Iteration 3, loss = 0.91946503\n",
      "Validation score: 0.482937\n",
      "Iteration 4, loss = 0.80483726\n",
      "Validation score: 0.501190\n",
      "Iteration 5, loss = 0.72891243\n",
      "Validation score: 0.492063\n",
      "Iteration 6, loss = 0.67245485\n",
      "Validation score: 0.494444\n",
      "Iteration 7, loss = 0.62897122\n",
      "Validation score: 0.500794\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "used: 79.31s\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "model5 = MLPClassifier(\n",
    "    early_stopping=True,\n",
    "    verbose=1\n",
    "#     solver='lbfgs'\n",
    ")\n",
    "model5.fit( train_features, df[\"sentiment\"] )\n",
    "# cv_result = cross_val_score( model5, train_features, df['sentiment'], cv=5)\n",
    "\n",
    "print ('used: {:.2f}s'.format(time()-start))\n",
    "# cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, ..., 1, 5, 5]),\n",
       " Index(['sadness', 'neutral', 'worry', 'surprise', 'happiness', 'love'], dtype='object'))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = pd.factorize(df['sentiment'])[0]\n",
    "pd.factorize(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20152, 65400), (5039, 65400), (20152,), (5039,))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_features, label, \n",
    "                                                      test_size = 0.20, \n",
    "                                                      random_state = 345)\n",
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.60635918\n",
      "Validation score: 0.444940\n",
      "Iteration 2, loss = 1.17966750\n",
      "Validation score: 0.478671\n",
      "Iteration 3, loss = 0.94606176\n",
      "Validation score: 0.499008\n",
      "Iteration 4, loss = 0.81789545\n",
      "Validation score: 0.504960\n",
      "Iteration 5, loss = 0.72829096\n",
      "Validation score: 0.496528\n",
      "Iteration 6, loss = 0.66206185\n",
      "Validation score: 0.502480\n",
      "Iteration 7, loss = 0.61222124\n",
      "Validation score: 0.505456\n",
      "Iteration 8, loss = 0.57023453\n",
      "Validation score: 0.495536\n",
      "Iteration 9, loss = 0.53747579\n",
      "Validation score: 0.501488\n",
      "Iteration 10, loss = 0.50950245\n",
      "Validation score: 0.501488\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "used: 90.43s\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "model23 = MLPClassifier(\n",
    "    early_stopping=True,\n",
    "    verbose=1\n",
    "#     solver='lbfgs'\n",
    ")\n",
    "model23.fit( X_train, y_train )\n",
    "# cv_result = cross_val_score( model5, train_features, df['sentiment'], cv=5)\n",
    "\n",
    "print ('used: {:.2f}s'.format(time()-start))\n",
    "# cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78339618896387453"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model23.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48422306013097838"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model23.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = xgb.DMatrix(x_train, y_train)\n",
    "d_valid = xgb.DMatrix(x_valid, y_valid)\n",
    "\n",
    "d_test = xgb.DMatrix(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  5., ...,  4.,  4.,  2.], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_train.get_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(d_train.get_label(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 2017\n",
    "params = {\n",
    "#     'min_child_weight': 1,\n",
    "#     'eta': 0.01,\n",
    "#     'colsample_bytree': 0.5,\n",
    "#     'max_depth': 13,\n",
    "#     'subsample': 0.8,\n",
    "#     'alpha': 1,\n",
    "#     'gamma': 1,\n",
    "#     'silent': 0,\n",
    "    'learning_rate':0.5,\n",
    "    'verbose_eval': True,\n",
    "    'seed': RANDOM_STATE,\n",
    "    'objective':\"multi:softmax\", \n",
    "    'num_class':6\n",
    "    \n",
    "}\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "def xg_eval(pred, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    return 'acc', accuracy_score(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-acc:0.388001\tvalid-acc:0.380036\n",
      "Multiple eval metrics have been passed: 'valid-acc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-acc hasn't improved in 150 rounds.\n",
      "[20]\ttrain-acc:0.505161\tvalid-acc:0.4102\n",
      "[40]\ttrain-acc:0.557116\tvalid-acc:0.413376\n",
      "[60]\ttrain-acc:0.59076\tvalid-acc:0.412979\n",
      "[80]\ttrain-acc:0.616068\tvalid-acc:0.416749\n",
      "[100]\ttrain-acc:0.635768\tvalid-acc:0.418535\n",
      "[120]\ttrain-acc:0.65264\tvalid-acc:0.419726\n",
      "[140]\ttrain-acc:0.666534\tvalid-acc:0.418932\n",
      "[160]\ttrain-acc:0.679933\tvalid-acc:0.421711\n",
      "[180]\ttrain-acc:0.691693\tvalid-acc:0.423497\n",
      "[200]\ttrain-acc:0.701717\tvalid-acc:0.422306\n",
      "[220]\ttrain-acc:0.7105\tvalid-acc:0.420718\n",
      "[240]\ttrain-acc:0.71839\tvalid-acc:0.420123\n",
      "[260]\ttrain-acc:0.727124\tvalid-acc:0.421512\n",
      "[280]\ttrain-acc:0.733873\tvalid-acc:0.419329\n",
      "[300]\ttrain-acc:0.742408\tvalid-acc:0.418734\n",
      "[320]\ttrain-acc:0.748313\tvalid-acc:0.419925\n",
      "Stopping. Best iteration:\n",
      "[184]\ttrain-acc:0.693827\tvalid-acc:0.424687\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'!!! used 42.83 s'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start=time()\n",
    "\n",
    "clf = xgb.train(params, d_train, 10000, watchlist, early_stopping_rounds=150, \n",
    "                verbose_eval=20, feval=xg_eval, maximize=True)\n",
    "                \n",
    "\n",
    "\n",
    "'!!! used %.2f s'%(time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  4.,  1., ...,  0.,  5.,  1.], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(d_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
