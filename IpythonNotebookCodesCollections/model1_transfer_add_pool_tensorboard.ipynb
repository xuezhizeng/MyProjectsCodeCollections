{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/keras-team/keras/issues/1538"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gogul09.github.io/software/flower-recognition-deep-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = 20000\n",
    "nb_validation_samples = 2500\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "img_width=299\n",
    "img_height=299\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 299, 299\n",
    "\n",
    "top_model_weights_path = 'model/inceptionV3_model.h5'\n",
    "train_data_dir = 'train/train'\n",
    "validation_data_dir = 'train/validation'\n",
    "\n",
    "\n",
    "def save_bottlebeck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    body = applications.InceptionV3(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3))\n",
    "    \n",
    "    head = body.output\n",
    "    head = GlobalAveragePooling2D()(head)\n",
    "    model = Model(body.input, head)    \n",
    "    \n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=False)\n",
    "    \n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, math.ceil(nb_train_samples / batch_size),\n",
    "        verbose=1)\n",
    "    \n",
    "    np.save('model/inceptionV3_train_pool.npy',\n",
    "            bottleneck_features_train)\n",
    "\n",
    "    \n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=False)\n",
    "    \n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, math.ceil(nb_validation_samples / batch_size),\n",
    "        verbose=1)\n",
    "    \n",
    "    np.save('model/inceptionV3_valid_pool.npy',\n",
    "            bottleneck_features_validation)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#save_bottlebeck_features()\n",
    "#train_top_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "1250/1250 [==============================] - 191s 153ms/step\n",
      "Found 2500 images belonging to 2 classes.\n",
      "157/157 [==============================] - 24s 152ms/step\n"
     ]
    }
   ],
   "source": [
    "save_bottlebeck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 2048)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep = np.load('model/inceptionV3_train_pool.npy')\n",
    "ep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "import math\n",
    "from keras.optimizers import RMSprop\n",
    "from time import time\n",
    "\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = 20000\n",
    "nb_validation_samples = 2500\n",
    "epochs = 50\n",
    "batch_size = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 0.2\n",
    "# decay_rate = learning_rate / epochs\n",
    "# momentum = 0.8\n",
    "# rmsprop = RMSprop(lr=learning_rate, decay=decay_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_top_model():\n",
    "    train_data = np.load('model/inceptionV3_train_pool.npy')\n",
    "    train_labels = np.array(\n",
    "        [0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
    "\n",
    "    validation_data = np.load('model/inceptionV3_valid_pool.npy')\n",
    "    validation_labels = np.array(\n",
    "        [0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
    "\n",
    "    model = Sequential()\n",
    "    #model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu', input_shape=train_data.shape[1:]))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    filepath=\"f_inceptionV3_model-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "    \n",
    "    callbacks_list = [\n",
    "    ModelCheckpoint('model/'+filepath, monitor='val_acc', verbose=1, save_best_only=True),\n",
    "    EarlyStopping(monitor='val_acc', patience=10, verbose=0),\n",
    "    TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "]\n",
    "\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels),\n",
    "              callbacks=callbacks_list)\n",
    "    model.save_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 2500 samples\n",
      "Epoch 1/50\n",
      "20000/20000 [==============================] - 5s 264us/step - loss: 0.0493 - acc: 0.9854 - val_loss: 0.0140 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.99520, saving model to model/f_inceptionV3_model-01-0.9952.hdf5\n",
      "Epoch 2/50\n",
      "20000/20000 [==============================] - 5s 249us/step - loss: 0.0309 - acc: 0.9908 - val_loss: 0.0141 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00002: val_acc did not improve\n",
      "Epoch 3/50\n",
      "20000/20000 [==============================] - 5s 248us/step - loss: 0.0258 - acc: 0.9921 - val_loss: 0.0154 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.99520 to 0.99560, saving model to model/f_inceptionV3_model-03-0.9956.hdf5\n",
      "Epoch 4/50\n",
      "20000/20000 [==============================] - 5s 250us/step - loss: 0.0246 - acc: 0.9919 - val_loss: 0.0261 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00004: val_acc did not improve\n",
      "Epoch 5/50\n",
      "20000/20000 [==============================] - 5s 247us/step - loss: 0.0221 - acc: 0.9929 - val_loss: 0.0179 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00005: val_acc did not improve\n",
      "Epoch 6/50\n",
      "20000/20000 [==============================] - 5s 247us/step - loss: 0.0186 - acc: 0.9931 - val_loss: 0.0460 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00006: val_acc did not improve\n",
      "Epoch 7/50\n",
      "20000/20000 [==============================] - 5s 250us/step - loss: 0.0183 - acc: 0.9937 - val_loss: 0.0173 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.99560 to 0.99640, saving model to model/f_inceptionV3_model-07-0.9964.hdf5\n",
      "Epoch 8/50\n",
      "20000/20000 [==============================] - 5s 252us/step - loss: 0.0168 - acc: 0.9941 - val_loss: 0.0170 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00008: val_acc did not improve\n",
      "Epoch 9/50\n",
      "20000/20000 [==============================] - 5s 246us/step - loss: 0.0170 - acc: 0.9943 - val_loss: 0.0140 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00009: val_acc did not improve\n",
      "Epoch 10/50\n",
      "20000/20000 [==============================] - 5s 263us/step - loss: 0.0154 - acc: 0.9946 - val_loss: 0.0153 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00010: val_acc did not improve\n",
      "Epoch 11/50\n",
      "20000/20000 [==============================] - 5s 250us/step - loss: 0.0135 - acc: 0.9956 - val_loss: 0.0208 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00011: val_acc did not improve\n",
      "Epoch 12/50\n",
      "20000/20000 [==============================] - 5s 253us/step - loss: 0.0142 - acc: 0.9951 - val_loss: 0.0156 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00012: val_acc did not improve\n",
      "Epoch 13/50\n",
      "20000/20000 [==============================] - 5s 256us/step - loss: 0.0133 - acc: 0.9951 - val_loss: 0.0238 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00013: val_acc did not improve\n",
      "Epoch 14/50\n",
      "20000/20000 [==============================] - 5s 258us/step - loss: 0.0125 - acc: 0.9956 - val_loss: 0.0166 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00014: val_acc did not improve\n",
      "Epoch 15/50\n",
      "20000/20000 [==============================] - 5s 256us/step - loss: 0.0117 - acc: 0.9960 - val_loss: 0.0179 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00015: val_acc did not improve\n",
      "Epoch 16/50\n",
      "20000/20000 [==============================] - 5s 249us/step - loss: 0.0116 - acc: 0.9962 - val_loss: 0.0179 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00016: val_acc did not improve\n",
      "Epoch 17/50\n",
      "20000/20000 [==============================] - 5s 252us/step - loss: 0.0087 - acc: 0.9968 - val_loss: 0.0167 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00017: val_acc did not improve\n"
     ]
    }
   ],
   "source": [
    "# save_bottlebeck_features()\n",
    "train_top_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = applications.InceptionV3(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3))\n",
    "\n",
    "head = body.output\n",
    "head = GlobalAveragePooling2D()(head)\n",
    "model = Model(body.input, head)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "final = keras.models.load_model('./model/f_inceptionV3_model-07-0.9964.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict helper func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper(start, end):\n",
    "    result = []\n",
    "    for p in range(start,end+1):\n",
    "\n",
    "        result.append([p,final.predict_proba(\n",
    "            model.predict(\n",
    "                img_to_array(load_img('./test/test/{}.jpg'.format(p), \n",
    "                                      target_size=(299,299,3)\n",
    "                                     )).reshape(-1,299,299,3)/255.0\n",
    "            ))[0][0]])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500, 2)\n",
      "Wall time: 5min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.DataFrame(helper(1,12500))\n",
    "print (df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=['id','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('pool_transfer_mobelnet.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper2(start, end):\n",
    "    result = []\n",
    "    for p in range(start,end+1):\n",
    "\n",
    "        result.append(final.predict_proba(\n",
    "            pre_model.predict(\n",
    "                img_to_array(load_img('./test1/test/{}.jpg'.format(p), \n",
    "                                      target_size=(224,224,3)\n",
    "                                     )).reshape(-1,224,224,3)/255.0\n",
    "            ))[0][0])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df2 = pd.DataFrame(helper2(0,999))\n",
    "print (df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['file']=df2.index\n",
    "df2['file'] = df2['file'].apply(lambda x: str(x)+'.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns=['label','file']\n",
    "df2 = df2[['file','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['label'] = (df2['label']<0.5).map({True:'cat', False:'dog'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('transfersmall2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>970.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>971.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>972.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>973.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>974.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>975.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>976.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>977.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>978.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>979.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>980.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>981.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>982.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>983.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>984.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>985.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>986.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>987.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>988.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>989.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>990.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>991.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>992.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>993.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>994.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        file label\n",
       "0      0.jpg   cat\n",
       "1      1.jpg   cat\n",
       "2      2.jpg   cat\n",
       "3      3.jpg   cat\n",
       "4      4.jpg   dog\n",
       "5      5.jpg   dog\n",
       "6      6.jpg   dog\n",
       "7      7.jpg   dog\n",
       "8      8.jpg   cat\n",
       "9      9.jpg   cat\n",
       "10    10.jpg   dog\n",
       "11    11.jpg   cat\n",
       "12    12.jpg   dog\n",
       "13    13.jpg   cat\n",
       "14    14.jpg   dog\n",
       "15    15.jpg   dog\n",
       "16    16.jpg   dog\n",
       "17    17.jpg   cat\n",
       "18    18.jpg   dog\n",
       "19    19.jpg   dog\n",
       "20    20.jpg   dog\n",
       "21    21.jpg   dog\n",
       "22    22.jpg   dog\n",
       "23    23.jpg   dog\n",
       "24    24.jpg   cat\n",
       "25    25.jpg   dog\n",
       "26    26.jpg   cat\n",
       "27    27.jpg   dog\n",
       "28    28.jpg   dog\n",
       "29    29.jpg   dog\n",
       "..       ...   ...\n",
       "970  970.jpg   cat\n",
       "971  971.jpg   cat\n",
       "972  972.jpg   dog\n",
       "973  973.jpg   dog\n",
       "974  974.jpg   cat\n",
       "975  975.jpg   cat\n",
       "976  976.jpg   cat\n",
       "977  977.jpg   dog\n",
       "978  978.jpg   dog\n",
       "979  979.jpg   dog\n",
       "980  980.jpg   dog\n",
       "981  981.jpg   dog\n",
       "982  982.jpg   dog\n",
       "983  983.jpg   cat\n",
       "984  984.jpg   cat\n",
       "985  985.jpg   cat\n",
       "986  986.jpg   cat\n",
       "987  987.jpg   dog\n",
       "988  988.jpg   cat\n",
       "989  989.jpg   cat\n",
       "990  990.jpg   cat\n",
       "991  991.jpg   cat\n",
       "992  992.jpg   dog\n",
       "993  993.jpg   dog\n",
       "994  994.jpg   dog\n",
       "995  995.jpg   dog\n",
       "996  996.jpg   dog\n",
       "997  997.jpg   cat\n",
       "998  998.jpg   cat\n",
       "999  999.jpg   dog\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
