{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 23.1 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "# !ls -hl|grep csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time, ctime\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, classification, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, StratifiedShuffleSplit\n",
    "\n",
    "dim=lambda *x: [i.shape for i in x]\n",
    "\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10881385210393610675\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11322956186\n",
      "locality {\n",
      "  bus_id: 2\n",
      "}\n",
      "incarnation: 9180730991985362561\n",
      "physical_device_desc: \"device: 0, name: Tesla K40m, pci bus id: 0000:82:00.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "num_cores = 4\n",
    "\n",
    "GPU=True\n",
    "CPU=False\n",
    "\n",
    "if GPU:\n",
    "    num_GPU = 1\n",
    "    num_CPU = 1\n",
    "if CPU:\n",
    "    num_CPU = 1\n",
    "    num_GPU = 0\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\\\n",
    "        inter_op_parallelism_threads=num_cores, allow_soft_placement=True,\\\n",
    "        device_count = {'CPU' : num_CPU, 'GPU' : num_GPU})\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "df = pd.read_csv('./ready.csv')\n",
    "print (df.shape)\n",
    "X=df.values\n",
    "\n",
    "# In[6]:\n",
    "y=pd.read_csv('./label_ready.csv')['label'].values\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                   random_state=7)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "# fit on training set\n",
    "X_train = sc.fit_transform(X_train)\n",
    "# only transform on test set\n",
    "X_test = sc.transform(X_test)\n",
    "print (dim(X_train,X_test, y_train, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 1024)              4599808   \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 5,607,873\n",
      "Trainable params: 5,607,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier = Sequential()\n",
    "# first hidden layer\n",
    "classifier.add(Dense(units = 1024, \n",
    "                     input_dim=4491,\n",
    "                     kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.8))\n",
    "# second hidden layer\n",
    "classifier.add(Dense(units = 512,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.7))\n",
    "# second hidden layer\n",
    "classifier.add(Dense(units = 256,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.6))\n",
    "# thrid hidden layer\n",
    "classifier.add(Dense(units = 128,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.5))\n",
    "# thrid hidden layer\n",
    "classifier.add(Dense(units = 64,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.4))\n",
    "# thrid hidden layer\n",
    "classifier.add(Dense(units = 32,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.3))\n",
    "# thrid hidden layer\n",
    "classifier.add(Dense(units = 32,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.2))\n",
    "# thrid hidden layer\n",
    "classifier.add(Dense(units = 64,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "# thrid hidden layer\n",
    "classifier.add(Dense(units = 128,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "# thrid hidden layer\n",
    "classifier.add(Dense(units = 256,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "# thrid hidden layer\n",
    "classifier.add(Dense(units = 1024,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "# # ouput layer\n",
    "classifier.add(Dense(units = 1,  kernel_initializer='uniform', activation='sigmoid'))\n",
    "# compiling the ANN\n",
    "classifier.compile(optimizer='adam',loss='binary_crossentropy', metrics= ['accuracy'])\n",
    "print (classifier.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34482 samples, validate on 14778 samples\n",
      "Epoch 1/64\n",
      "14656/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.4770643329334801, acc: 0.8197997023246498\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.4776 - acc: 0.8193 - val_loss: 0.4771 - val_acc: 0.8198\n",
      "Epoch 2/64\n",
      "14144/14778 [===========================>..] - ETA: 0s\n",
      "Testing loss: 0.4622755135843244, acc: 0.8197997023246498\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.4686 - acc: 0.8200 - val_loss: 0.4623 - val_acc: 0.8198\n",
      "Epoch 3/64\n",
      "14778/14778 [==============================] - 1s     \n",
      "\n",
      "Testing loss: 0.4596625715554656, acc: 0.8197997023246498\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.4531 - acc: 0.8200 - val_loss: 0.4597 - val_acc: 0.8198\n",
      "Epoch 4/64\n",
      "14720/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.4664444545719262, acc: 0.8197997023246498\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.4388 - acc: 0.8200 - val_loss: 0.4664 - val_acc: 0.8198\n",
      "Epoch 5/64\n",
      "14720/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.4723216198200237, acc: 0.8159426174687829\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.4237 - acc: 0.8214 - val_loss: 0.4723 - val_acc: 0.8159\n",
      "Epoch 6/64\n",
      "14752/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.4698181317750874, acc: 0.8118148599914518\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.4125 - acc: 0.8271 - val_loss: 0.4698 - val_acc: 0.8118\n",
      "Epoch 7/64\n",
      "14778/14778 [==============================] - 1s     \n",
      "\n",
      "Testing loss: 0.47151612053302744, acc: 0.8147245906721934\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.4024 - acc: 0.8272 - val_loss: 0.4715 - val_acc: 0.8147\n",
      "Epoch 8/64\n",
      "14778/14778 [==============================] - 1s     \n",
      "\n",
      "Testing loss: 0.4763532683327905, acc: 0.7995669239266572\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.3926 - acc: 0.8341 - val_loss: 0.4764 - val_acc: 0.7996\n",
      "Epoch 9/64\n",
      "14656/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.4753529687891924, acc: 0.8106645013502284\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.3823 - acc: 0.8389 - val_loss: 0.4754 - val_acc: 0.8107\n",
      "Epoch 10/64\n",
      "14688/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.4780440663215288, acc: 0.807416429949123\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.3714 - acc: 0.8448 - val_loss: 0.4780 - val_acc: 0.8074\n",
      "Epoch 11/64\n",
      "14720/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.4779229360385683, acc: 0.8061984031525334\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.3610 - acc: 0.8500 - val_loss: 0.4779 - val_acc: 0.8062\n",
      "Epoch 12/64\n",
      "14688/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.5100214958820118, acc: 0.7965895250340828\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.3541 - acc: 0.8524 - val_loss: 0.5100 - val_acc: 0.7966\n",
      "Epoch 13/64\n",
      "14752/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.5347313880597743, acc: 0.7929354446443141\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.3429 - acc: 0.8598 - val_loss: 0.5347 - val_acc: 0.7929\n",
      "Epoch 14/64\n",
      "14688/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.5173436185958373, acc: 0.7884693463901525\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.3336 - acc: 0.8636 - val_loss: 0.5173 - val_acc: 0.7885\n",
      "Epoch 15/64\n",
      "14720/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.5493261869293473, acc: 0.7900257139635725\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.3260 - acc: 0.8662 - val_loss: 0.5493 - val_acc: 0.7900\n",
      "Epoch 16/64\n",
      "14720/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.539636695101839, acc: 0.7929354446927142\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.3177 - acc: 0.8714 - val_loss: 0.5396 - val_acc: 0.7929\n",
      "Epoch 17/64\n",
      "14688/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.5278123160195232, acc: 0.797604547412974\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.3041 - acc: 0.8772 - val_loss: 0.5278 - val_acc: 0.7976\n",
      "Epoch 18/64\n",
      "14752/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.5167888051594912, acc: 0.7670185410907037\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.2965 - acc: 0.8831 - val_loss: 0.5168 - val_acc: 0.7670\n",
      "Epoch 19/64\n",
      "14720/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.5410475787322372, acc: 0.7626877791956743\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.2868 - acc: 0.8870 - val_loss: 0.5410 - val_acc: 0.7627\n",
      "Epoch 20/64\n",
      "14778/14778 [==============================] - 1s     \n",
      "\n",
      "Testing loss: 0.5432425988899837, acc: 0.7741236974041426\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.2778 - acc: 0.8912 - val_loss: 0.5432 - val_acc: 0.7741\n",
      "Epoch 21/64\n",
      "14752/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.55704511215842, acc: 0.7909054000317316\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.2704 - acc: 0.8932 - val_loss: 0.5570 - val_acc: 0.7909\n",
      "Epoch 22/64\n",
      "14656/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.5851473987207375, acc: 0.7404926243485319\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.2615 - acc: 0.8971 - val_loss: 0.5851 - val_acc: 0.7405\n",
      "Epoch 23/64\n",
      "14752/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.5722764631919084, acc: 0.7745973744917052\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.2461 - acc: 0.9032 - val_loss: 0.5723 - val_acc: 0.7746\n",
      "Epoch 24/64\n",
      "14144/14778 [===========================>..] - ETA: 0s\n",
      "Testing loss: 0.6095275200015073, acc: 0.7638381377884976\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.2454 - acc: 0.9022 - val_loss: 0.6095 - val_acc: 0.7638\n",
      "Epoch 25/64\n",
      "14624/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.6142262782428113, acc: 0.7415753147859893\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.2343 - acc: 0.9080 - val_loss: 0.6142 - val_acc: 0.7416\n",
      "Epoch 26/64\n",
      "14720/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.6072430548462692, acc: 0.7804168359015885\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.2246 - acc: 0.9123 - val_loss: 0.6072 - val_acc: 0.7804\n",
      "Epoch 27/64\n",
      "14720/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.597069192939399, acc: 0.7665448640515411\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.2199 - acc: 0.9133 - val_loss: 0.5971 - val_acc: 0.7665\n",
      "Epoch 28/64\n",
      "14688/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.6077577869984726, acc: 0.774462038229373\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.2111 - acc: 0.9182 - val_loss: 0.6078 - val_acc: 0.7745\n",
      "Epoch 29/64\n",
      "14720/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.6509668667740098, acc: 0.7331167953652287\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.2018 - acc: 0.9218 - val_loss: 0.6510 - val_acc: 0.7331\n",
      "Epoch 30/64\n",
      "14778/14778 [==============================] - 1s     \n",
      "\n",
      "Testing loss: 0.6537564509791634, acc: 0.7444850454102642\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.2041 - acc: 0.9201 - val_loss: 0.6538 - val_acc: 0.7445\n",
      "Epoch 31/64\n",
      "14778/14778 [==============================] - 1s     \n",
      "\n",
      "Testing loss: 0.6266209257037831, acc: 0.7650561645850872\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1925 - acc: 0.9258 - val_loss: 0.6266 - val_acc: 0.7651\n",
      "Epoch 32/64\n",
      "14656/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.7642294382077783, acc: 0.7520638788112657\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1886 - acc: 0.9292 - val_loss: 0.7642 - val_acc: 0.7521\n",
      "Epoch 33/64\n",
      "14752/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.7506572785961853, acc: 0.741778319139154\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1842 - acc: 0.9302 - val_loss: 0.7507 - val_acc: 0.7418\n",
      "Epoch 34/64\n",
      "14656/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.6881041954973421, acc: 0.7570713223083559\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34482/34482 [==============================] - 9s - loss: 0.1823 - acc: 0.9312 - val_loss: 0.6881 - val_acc: 0.7571\n",
      "Epoch 35/64\n",
      "14720/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.7951851527977093, acc: 0.7599810529326309\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1826 - acc: 0.9309 - val_loss: 0.7952 - val_acc: 0.7600\n",
      "Epoch 36/64\n",
      "14688/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.6621343076091962, acc: 0.7502368386163814\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1763 - acc: 0.9336 - val_loss: 0.6621 - val_acc: 0.7502\n",
      "Epoch 37/64\n",
      "14144/14778 [===========================>..] - ETA: 0s\n",
      "Testing loss: 0.8221343897816485, acc: 0.7679658953142289\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1762 - acc: 0.9338 - val_loss: 0.8221 - val_acc: 0.7680\n",
      "Epoch 38/64\n",
      "14208/14778 [===========================>..] - ETA: 0s\n",
      "Testing loss: 0.7342788622333807, acc: 0.7385302477380487\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1664 - acc: 0.9366 - val_loss: 0.7343 - val_acc: 0.7385\n",
      "Epoch 39/64\n",
      "14688/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.8370425635317308, acc: 0.7203275139042385\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1653 - acc: 0.9374 - val_loss: 0.8370 - val_acc: 0.7203\n",
      "Epoch 40/64\n",
      "14624/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.8047860880386266, acc: 0.729192042297529\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1603 - acc: 0.9403 - val_loss: 0.8048 - val_acc: 0.7292\n",
      "Epoch 41/64\n",
      "14720/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.7635808029586527, acc: 0.7365678712324323\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1556 - acc: 0.9415 - val_loss: 0.7636 - val_acc: 0.7366\n",
      "Epoch 42/64\n",
      "14656/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.7731100473518154, acc: 0.7468534309529439\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1517 - acc: 0.9432 - val_loss: 0.7731 - val_acc: 0.7469\n",
      "Epoch 43/64\n",
      "14592/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.7087395535679886, acc: 0.7318987685686391\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1476 - acc: 0.9448 - val_loss: 0.7087 - val_acc: 0.7319\n",
      "Epoch 44/64\n",
      "14752/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.7813574113329881, acc: 0.7348761672918134\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1433 - acc: 0.9469 - val_loss: 0.7814 - val_acc: 0.7349\n",
      "Epoch 45/64\n",
      "14720/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.8186379956294016, acc: 0.7371768846387937\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1444 - acc: 0.9455 - val_loss: 0.8186 - val_acc: 0.7372\n",
      "Epoch 46/64\n",
      "14144/14778 [===========================>..] - ETA: 0s\n",
      "Testing loss: 0.7571099197159505, acc: 0.7303424009952192\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1352 - acc: 0.9505 - val_loss: 0.7571 - val_acc: 0.7303\n",
      "Epoch 47/64\n",
      "14592/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.6914769430769717, acc: 0.7346054947268158\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1376 - acc: 0.9494 - val_loss: 0.6915 - val_acc: 0.7346\n",
      "Epoch 48/64\n",
      "14720/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.7434696872641873, acc: 0.746041412935284\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1330 - acc: 0.9514 - val_loss: 0.7435 - val_acc: 0.7460\n",
      "Epoch 49/64\n",
      "14656/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.8026563056768204, acc: 0.7561916362885968\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1286 - acc: 0.9535 - val_loss: 0.8027 - val_acc: 0.7562\n",
      "Epoch 50/64\n",
      "14778/14778 [==============================] - 1s     \n",
      "\n",
      "Testing loss: 0.9042005083818755, acc: 0.7526728921530937\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1297 - acc: 0.9526 - val_loss: 0.9042 - val_acc: 0.7527\n",
      "Epoch 51/64\n",
      "14752/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.9864639126612379, acc: 0.7450263906531929\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1267 - acc: 0.9520 - val_loss: 0.9865 - val_acc: 0.7450\n",
      "Epoch 52/64\n",
      "14752/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.7189935031481212, acc: 0.7517932061898013\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1297 - acc: 0.9532 - val_loss: 0.7190 - val_acc: 0.7518\n",
      "Epoch 53/64\n",
      "14496/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.9483874851553152, acc: 0.7472594397802736\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1266 - acc: 0.9531 - val_loss: 0.9484 - val_acc: 0.7473\n",
      "Epoch 54/64\n",
      "14778/14778 [==============================] - 1s     \n",
      "\n",
      "Testing loss: 1.0295206275694844, acc: 0.7637704696331316\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1252 - acc: 0.9544 - val_loss: 1.0295 - val_acc: 0.7638\n",
      "Epoch 55/64\n",
      "14688/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.9251360733610059, acc: 0.762755447310707\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1217 - acc: 0.9557 - val_loss: 0.9251 - val_acc: 0.7628\n",
      "Epoch 56/64\n",
      "14720/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.890849254735995, acc: 0.7509811883334749\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1201 - acc: 0.9584 - val_loss: 0.8908 - val_acc: 0.7510\n",
      "Epoch 57/64\n",
      "14778/14778 [==============================] - 1s     \n",
      "\n",
      "Testing loss: 0.7388199861623354, acc: 0.7475977806135707\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1216 - acc: 0.9568 - val_loss: 0.7388 - val_acc: 0.7476\n",
      "Epoch 58/64\n",
      "14720/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.9041749339478637, acc: 0.7354851806981748\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1198 - acc: 0.9565 - val_loss: 0.9042 - val_acc: 0.7355\n",
      "Epoch 59/64\n",
      "14688/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 1.1028386253250002, acc: 0.7367708756985305\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1186 - acc: 0.9570 - val_loss: 1.1028 - val_acc: 0.7368\n",
      "Epoch 60/64\n",
      "14144/14778 [===========================>..] - ETA: 0s\n",
      "Testing loss: 0.8663421061804014, acc: 0.7528082285767593\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1189 - acc: 0.9570 - val_loss: 0.8663 - val_acc: 0.7528\n",
      "Epoch 61/64\n",
      "14688/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 1.0285325127148728, acc: 0.7607254027545912\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1133 - acc: 0.9612 - val_loss: 1.0285 - val_acc: 0.7607\n",
      "Epoch 62/64\n",
      "14778/14778 [==============================] - 1s     \n",
      "\n",
      "Testing loss: 1.0440573205820745, acc: 0.7403572879409996\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1157 - acc: 0.9577 - val_loss: 1.0441 - val_acc: 0.7404\n",
      "Epoch 63/64\n",
      "14778/14778 [==============================] - 1s     \n",
      "\n",
      "Testing loss: 0.9349161804303182, acc: 0.7536879146449185\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1131 - acc: 0.9603 - val_loss: 0.9349 - val_acc: 0.7537\n",
      "Epoch 64/64\n",
      "14720/14778 [============================>.] - ETA: 0s\n",
      "Testing loss: 0.9969902053416897, acc: 0.7327107863200987\n",
      "\n",
      "34482/34482 [==============================] - 9s - loss: 0.1058 - acc: 0.9625 - val_loss: 0.9970 - val_acc: 0.7327\n",
      "0.732710786304\n",
      "[[ 961 1702]\n",
      " [2248 9867]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "class TestCallback(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "        \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=1)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "stopping = EarlyStopping(monitor='acc', min_delta=0,\n",
    "                              patience=6, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "# fitting ANN with training set\n",
    "classifier.fit(X_train, y_train, \n",
    "               batch_size=64, epochs=64,\n",
    "               validation_data=(X_test, y_test),\n",
    "          callbacks=[TestCallback((X_test, y_test))])\n",
    "#           callbacks=[stopping])\n",
    "    \n",
    "\n",
    "\n",
    "# In[53]:\n",
    "\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred> 0.5)\n",
    "\n",
    "print (accuracy_score(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print (cm)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU3",
   "language": "python",
   "name": "gpu3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
