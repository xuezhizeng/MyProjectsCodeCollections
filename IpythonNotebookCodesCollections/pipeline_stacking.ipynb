{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "#from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "#init_notebook_mode(connected=True)\n",
    "\n",
    "#import plotly\n",
    "#plotly.tools.set_credentials_file(username='sayasong23333', api_key='8XWuK3gwZwUj1NALsq7o')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', chunksize=100)\n",
    "df = df.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shj16110/anaconda2/envs/new2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning:\n",
      "\n",
      "This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor, ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LengthVectorizer:\n",
    "    \n",
    "    VEC_LEN = np.vectorize(len)\n",
    "\n",
    "    def transform(self, data):\n",
    "        return self.VEC_LEN(data).astype(float)\n",
    "\n",
    "    def fit(self, *_):\n",
    "        return self\n",
    "    \n",
    "    \n",
    "class TextExtractor:\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def transform(self, data):\n",
    "        return np.asarray(data[self.column]).astype(str)\n",
    "\n",
    "    def fit(self, *_):\n",
    "        return self    \n",
    "    \n",
    "class ArrayUpDimension:\n",
    "    def transform(self, data):\n",
    "        return data.reshape((-1, 1))\n",
    "\n",
    "    def fit(self, *_):\n",
    "        return self    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from time import time\n",
    "class ModelTransformer(TransformerMixin):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, *args, **kwargs):\n",
    "        start = time()\n",
    "        self.model.fit(*args, **kwargs)\n",
    "        print(str(self.model)+'\\n used: {:.2f} s\\n'.format(time()-start))\n",
    "#         print (time()-start)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        return pd.DataFrame(self.model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline1 = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('len', Pipeline([\n",
    "#             ('desc_extractor', TextExtractor('comment_text')),\n",
    "            ('length', LengthVectorizer()),\n",
    "            ('updim_array', ArrayUpDimension()),\n",
    "            ('scaler', StandardScaler()),\n",
    "\n",
    "        ])),\n",
    "        ('tf-idf', Pipeline([\n",
    "#             ('desc_extractor', TextExtractor('comment_text')),\n",
    "            ('count', CountVectorizer()),\n",
    "            ('tf-idf', TfidfTransformer()),\n",
    "        ]))\n",
    "    ])),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makePipe():\n",
    "     \n",
    "    pipeline2 =  Pipeline([\n",
    "        ('estimators', FeatureUnion([\n",
    "            ('gbr', ModelTransformer(GradientBoostingRegressor())),\n",
    "            ('dtr', ModelTransformer(DecisionTreeRegressor())),\n",
    "            ('etr', ModelTransformer(ExtraTreesRegressor(n_jobs=-1))),\n",
    "            ('rfr', ModelTransformer(RandomForestRegressor(n_jobs=-1))),\n",
    "            ('par', ModelTransformer(PassiveAggressiveRegressor())),\n",
    "            ('en', ModelTransformer(ElasticNet())),\n",
    "        ])),\n",
    "        ('final', LogisticRegression(n_jobs=-1))\n",
    "    ])\n",
    "    return pipeline2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['comment_text']\n",
    "X_test = test['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'scipy.sparse.csr.csr_matrix'>, (159571, 189769))\n",
      "CPU times: user 9.85 s, sys: 199 ms, total: 10.1 s\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_features = pipeline1.fit_transform(X_train)\n",
    "print(type(train_features), train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'scipy.sparse.csr.csr_matrix'>, (153164, 189769))\n",
      "CPU times: user 8.42 s, sys: 101 ms, total: 8.52 s\n",
      "Wall time: 8.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_features = pipeline1.transform(X_test)\n",
    "print(type(test_features), test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pipeline each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "             min_impurity_split=None, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=100, presort='auto', random_state=None,\n",
      "             subsample=1.0, verbose=0, warm_start=False)\n",
      " used: 246.66 s\n",
      "\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best')\n",
      " used: 380.44 s\n",
      "\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "          oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      " used: 218.84 s\n",
      "\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      " used: 287.14 s\n",
      "\n",
      "PassiveAggressiveRegressor(C=1.0, average=False, epsilon=0.1,\n",
      "              fit_intercept=True, loss='epsilon_insensitive',\n",
      "              max_iter=None, n_iter=None, random_state=None, shuffle=True,\n",
      "              tol=None, verbose=0, warm_start=False)\n",
      " used: 0.33 s\n",
      "\n",
      "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      " used: 42.66 s\n",
      "\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "             min_impurity_split=None, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=100, presort='auto', random_state=None,\n",
      "             subsample=1.0, verbose=0, warm_start=False)\n",
      " used: 244.71 s\n",
      "\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best')\n",
      " used: 170.32 s\n",
      "\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "          oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      " used: 58.74 s\n",
      "\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      " used: 122.22 s\n",
      "\n",
      "PassiveAggressiveRegressor(C=1.0, average=False, epsilon=0.1,\n",
      "              fit_intercept=True, loss='epsilon_insensitive',\n",
      "              max_iter=None, n_iter=None, random_state=None, shuffle=True,\n",
      "              tol=None, verbose=0, warm_start=False)\n",
      " used: 0.31 s\n",
      "\n",
      "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      " used: 42.66 s\n",
      "\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "             min_impurity_split=None, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=100, presort='auto', random_state=None,\n",
      "             subsample=1.0, verbose=0, warm_start=False)\n",
      " used: 246.86 s\n",
      "\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best')\n",
      " used: 483.31 s\n",
      "\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "          oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      " used: 144.64 s\n",
      "\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      " used: 314.30 s\n",
      "\n",
      "PassiveAggressiveRegressor(C=1.0, average=False, epsilon=0.1,\n",
      "              fit_intercept=True, loss='epsilon_insensitive',\n",
      "              max_iter=None, n_iter=None, random_state=None, shuffle=True,\n",
      "              tol=None, verbose=0, warm_start=False)\n",
      " used: 0.32 s\n",
      "\n",
      "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      " used: 42.67 s\n",
      "\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "             min_impurity_split=None, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=100, presort='auto', random_state=None,\n",
      "             subsample=1.0, verbose=0, warm_start=False)\n",
      " used: 238.11 s\n",
      "\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best')\n",
      " used: 152.46 s\n",
      "\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "          oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      " used: 44.12 s\n",
      "\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      " used: 94.78 s\n",
      "\n",
      "PassiveAggressiveRegressor(C=1.0, average=False, epsilon=0.1,\n",
      "              fit_intercept=True, loss='epsilon_insensitive',\n",
      "              max_iter=None, n_iter=None, random_state=None, shuffle=True,\n",
      "              tol=None, verbose=0, warm_start=False)\n",
      " used: 0.30 s\n",
      "\n",
      "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      " used: 42.67 s\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "             min_impurity_split=None, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=100, presort='auto', random_state=None,\n",
      "             subsample=1.0, verbose=0, warm_start=False)\n",
      " used: 246.71 s\n",
      "\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best')\n",
      " used: 319.96 s\n",
      "\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "          oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      " used: 138.07 s\n",
      "\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      " used: 371.30 s\n",
      "\n",
      "PassiveAggressiveRegressor(C=1.0, average=False, epsilon=0.1,\n",
      "              fit_intercept=True, loss='epsilon_insensitive',\n",
      "              max_iter=None, n_iter=None, random_state=None, shuffle=True,\n",
      "              tol=None, verbose=0, warm_start=False)\n",
      " used: 0.33 s\n",
      "\n",
      "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      " used: 42.66 s\n",
      "\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "             min_impurity_split=None, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=100, presort='auto', random_state=None,\n",
      "             subsample=1.0, verbose=0, warm_start=False)\n",
      " used: 243.64 s\n",
      "\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best')\n",
      " used: 275.57 s\n",
      "\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "          oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      " used: 87.42 s\n",
      "\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      " used: 170.32 s\n",
      "\n",
      "PassiveAggressiveRegressor(C=1.0, average=False, epsilon=0.1,\n",
      "              fit_intercept=True, loss='epsilon_insensitive',\n",
      "              max_iter=None, n_iter=None, random_state=None, shuffle=True,\n",
      "              tol=None, verbose=0, warm_start=False)\n",
      " used: 0.31 s\n",
      "\n",
      "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      " used: 42.59 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']:\n",
    "    y = train[label]\n",
    "    model = makePipe()\n",
    "    model.fit(train_features, y)\n",
    "    test[label] = model.predict_proba(test_features)[:, 1]\n",
    "    \n",
    "test.drop('comment_text', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "test.to_csv('ensemble_pipeline.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.999717</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.996507</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.999599</td>\n",
       "      <td>0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00024115d4cbde0f</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00025358d4737918</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00026d1092fe71cc</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0002eadc3b301559</td>\n",
       "      <td>0.112725</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0002f87b16116a7f</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0003806b11932181</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0003e1cccfd5a40a</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00059ace3e3e9a53</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>000634272d0d44eb</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>000663aff0fffc80</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000689dd34e20979</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>000834769115370c</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>000844b52dee5f3f</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00084da5d4ead7aa</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00091c35fa9d0465</td>\n",
       "      <td>0.023086</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.074546</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>000968ce11f5ee34</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0009734200a85047</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00097b6214686db5</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0009aef4bd9e1697</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>000a02d807ae0254</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>000a6c6d4e89b9bc</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>000bafe2080bba82</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.060039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>000bf0a9894b2807</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153134</th>\n",
       "      <td>fff3ae2e177b6bb3</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153135</th>\n",
       "      <td>fff4109e837f7acc</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153136</th>\n",
       "      <td>fff4373a81ef9f2a</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153137</th>\n",
       "      <td>fff460574ddbcd80</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153138</th>\n",
       "      <td>fff4fc0a1555be5c</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153139</th>\n",
       "      <td>fff5b9bb944d634c</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153140</th>\n",
       "      <td>fff5c4a77fe0c05f</td>\n",
       "      <td>0.004038</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153141</th>\n",
       "      <td>fff5fb61bd637c82</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153142</th>\n",
       "      <td>fff69311f306df44</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153143</th>\n",
       "      <td>fff6ad63666fb304</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.999609</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.999676</td>\n",
       "      <td>0.000092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153144</th>\n",
       "      <td>fff7159b3ee95618</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153145</th>\n",
       "      <td>fff718ffe5f05559</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153146</th>\n",
       "      <td>fff7fc22a0cdccd3</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153147</th>\n",
       "      <td>fff83b80284d8440</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153148</th>\n",
       "      <td>fff8ef316d0c6990</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153149</th>\n",
       "      <td>fff8f521a7dbcd47</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153150</th>\n",
       "      <td>fff8f64043129fa2</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153151</th>\n",
       "      <td>fff9d70fe0722906</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.466108</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.998522</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153152</th>\n",
       "      <td>fff9fa508f400ee6</td>\n",
       "      <td>0.832274</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.004508</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153153</th>\n",
       "      <td>fffa3fae1890b40a</td>\n",
       "      <td>0.971001</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.947977</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.005406</td>\n",
       "      <td>0.000132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153154</th>\n",
       "      <td>fffa8a11c4378854</td>\n",
       "      <td>0.004362</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.001399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153155</th>\n",
       "      <td>fffac2a094c8e0e2</td>\n",
       "      <td>0.999605</td>\n",
       "      <td>0.008326</td>\n",
       "      <td>0.999428</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.998045</td>\n",
       "      <td>0.220686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153156</th>\n",
       "      <td>fffb5451268fb5ba</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>0.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153157</th>\n",
       "      <td>fffc2b34bbe61c8d</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153158</th>\n",
       "      <td>fffc489742ffe69b</td>\n",
       "      <td>0.999575</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.999630</td>\n",
       "      <td>0.000084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>fffcd0960ee309b5</td>\n",
       "      <td>0.999808</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.366447</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>fffd7a9a6eb32c16</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>fffda9e8d6fafa9e</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>fffe8f1340a79fc2</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>ffffce3fb183ee80</td>\n",
       "      <td>0.627613</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.999511</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153164 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id     toxic  severe_toxic   obscene    threat  \\\n",
       "0       00001cee341fdb12  0.999717      0.001969  0.996507  0.000141   \n",
       "1       0000247867823ef7  0.000110      0.000080  0.000096  0.000102   \n",
       "2       00013b17ad220c46  0.000100      0.000082  0.000100  0.000087   \n",
       "3       00017563c3f7919a  0.000070      0.000116  0.000091  0.000124   \n",
       "4       00017695ad8997eb  0.000072      0.000081  0.000103  0.000080   \n",
       "5       0001ea8717f6de06  0.000229      0.000075  0.000102  0.000091   \n",
       "6       00024115d4cbde0f  0.000090      0.000091  0.000094  0.000085   \n",
       "7       000247e83dcc1211  0.000260      0.000074  0.000115  0.000102   \n",
       "8       00025358d4737918  0.000779      0.000091  0.000092  0.000090   \n",
       "9       00026d1092fe71cc  0.000089      0.000092  0.000099  0.000095   \n",
       "10      0002eadc3b301559  0.112725      0.000077  0.000537  0.000105   \n",
       "11      0002f87b16116a7f  0.001126      0.000075  0.000246  0.000103   \n",
       "12      0003806b11932181  0.000884      0.000132  0.000123  0.000114   \n",
       "13      0003e1cccfd5a40a  0.000139      0.000087  0.000109  0.000091   \n",
       "14      00059ace3e3e9a53  0.000110      0.000092  0.000078  0.000087   \n",
       "15      000634272d0d44eb  0.000105      0.000092  0.000110  0.000083   \n",
       "16      000663aff0fffc80  0.000108      0.000081  0.000105  0.000090   \n",
       "17      000689dd34e20979  0.000117      0.000087  0.000100  0.000092   \n",
       "18      000834769115370c  0.000065      0.000100  0.000096  0.000104   \n",
       "19      000844b52dee5f3f  0.000111      0.000083  0.000069  0.000058   \n",
       "20      00084da5d4ead7aa  0.000075      0.000086  0.000087  0.000064   \n",
       "21      00091c35fa9d0465  0.023086      0.000120  0.074546  0.000161   \n",
       "22      000968ce11f5ee34  0.000148      0.000081  0.000103  0.000097   \n",
       "23      0009734200a85047  0.000074      0.000095  0.000083  0.000105   \n",
       "24      00097b6214686db5  0.000266      0.000083  0.000158  0.000094   \n",
       "25      0009aef4bd9e1697  0.000090      0.000100  0.000093  0.000090   \n",
       "26      000a02d807ae0254  0.000090      0.000071  0.000086  0.000115   \n",
       "27      000a6c6d4e89b9bc  0.000157      0.000081  0.000139  0.000095   \n",
       "28      000bafe2080bba82  0.000151      0.000094  0.000134  0.000121   \n",
       "29      000bf0a9894b2807  0.000073      0.000106  0.000087  0.000084   \n",
       "...                  ...       ...           ...       ...       ...   \n",
       "153134  fff3ae2e177b6bb3  0.000079      0.000098  0.000091  0.000092   \n",
       "153135  fff4109e837f7acc  0.000061      0.000105  0.000047  0.000100   \n",
       "153136  fff4373a81ef9f2a  0.000058      0.000085  0.000073  0.000086   \n",
       "153137  fff460574ddbcd80  0.000088      0.000084  0.000086  0.000081   \n",
       "153138  fff4fc0a1555be5c  0.000107      0.000107  0.000093  0.000076   \n",
       "153139  fff5b9bb944d634c  0.000082      0.000086  0.000103  0.000092   \n",
       "153140  fff5c4a77fe0c05f  0.004038      0.000084  0.000122  0.000104   \n",
       "153141  fff5fb61bd637c82  0.000087      0.000082  0.000082  0.000094   \n",
       "153142  fff69311f306df44  0.000107      0.000086  0.000085  0.000088   \n",
       "153143  fff6ad63666fb304  0.999820      0.000284  0.999609  0.000095   \n",
       "153144  fff7159b3ee95618  0.000078      0.000082  0.000094  0.000086   \n",
       "153145  fff718ffe5f05559  0.000094      0.000092  0.000076  0.000083   \n",
       "153146  fff7fc22a0cdccd3  0.000077      0.000069  0.000080  0.000099   \n",
       "153147  fff83b80284d8440  0.000116      0.000153  0.000078  0.000076   \n",
       "153148  fff8ef316d0c6990  0.000122      0.000068  0.000100  0.000082   \n",
       "153149  fff8f521a7dbcd47  0.004693      0.000148  0.000155  0.000119   \n",
       "153150  fff8f64043129fa2  0.000085      0.000100  0.000110  0.000109   \n",
       "153151  fff9d70fe0722906  0.999548      0.000096  0.466108  0.000080   \n",
       "153152  fff9fa508f400ee6  0.832274      0.000072  0.004508  0.000108   \n",
       "153153  fffa3fae1890b40a  0.971001      0.000165  0.947977  0.000257   \n",
       "153154  fffa8a11c4378854  0.004362      0.000090  0.000079  0.000097   \n",
       "153155  fffac2a094c8e0e2  0.999605      0.008326  0.999428  0.000068   \n",
       "153156  fffb5451268fb5ba  0.000253      0.000090  0.000089  0.000101   \n",
       "153157  fffc2b34bbe61c8d  0.000076      0.000097  0.000090  0.000074   \n",
       "153158  fffc489742ffe69b  0.999575      0.000069  0.003208  0.000061   \n",
       "153159  fffcd0960ee309b5  0.999808      0.000065  0.366447  0.000083   \n",
       "153160  fffd7a9a6eb32c16  0.000199      0.000094  0.000102  0.000109   \n",
       "153161  fffda9e8d6fafa9e  0.000095      0.000089  0.000085  0.000096   \n",
       "153162  fffe8f1340a79fc2  0.000110      0.000085  0.000118  0.000093   \n",
       "153163  ffffce3fb183ee80  0.627613      0.000087  0.999511  0.000109   \n",
       "\n",
       "          insult  identity_hate  \n",
       "0       0.999599       0.000191  \n",
       "1       0.000073       0.000064  \n",
       "2       0.000081       0.000073  \n",
       "3       0.000086       0.000086  \n",
       "4       0.000068       0.000084  \n",
       "5       0.000091       0.000107  \n",
       "6       0.000093       0.000095  \n",
       "7       0.000121       0.000055  \n",
       "8       0.000109       0.000080  \n",
       "9       0.000103       0.000100  \n",
       "10      0.000082       0.000093  \n",
       "11      0.000100       0.000118  \n",
       "12      0.000082       0.000091  \n",
       "13      0.000077       0.000081  \n",
       "14      0.000078       0.000086  \n",
       "15      0.000097       0.000076  \n",
       "16      0.000082       0.000074  \n",
       "17      0.000099       0.000111  \n",
       "18      0.000083       0.000093  \n",
       "19      0.000088       0.000071  \n",
       "20      0.000074       0.000070  \n",
       "21      0.000091       0.000134  \n",
       "22      0.000110       0.000120  \n",
       "23      0.000088       0.000093  \n",
       "24      0.000128       0.000083  \n",
       "25      0.000115       0.000110  \n",
       "26      0.000076       0.000093  \n",
       "27      0.000088       0.000071  \n",
       "28      0.000103       0.060039  \n",
       "29      0.000082       0.000088  \n",
       "...          ...            ...  \n",
       "153134  0.000102       0.000093  \n",
       "153135  0.000044       0.000078  \n",
       "153136  0.000081       0.000098  \n",
       "153137  0.000128       0.000071  \n",
       "153138  0.000084       0.000087  \n",
       "153139  0.000076       0.000084  \n",
       "153140  0.000077       0.000087  \n",
       "153141  0.000091       0.000086  \n",
       "153142  0.000099       0.000084  \n",
       "153143  0.999676       0.000092  \n",
       "153144  0.000103       0.000087  \n",
       "153145  0.000091       0.000093  \n",
       "153146  0.000082       0.000087  \n",
       "153147  0.000068       0.000078  \n",
       "153148  0.000186       0.000086  \n",
       "153149  0.000146       0.000120  \n",
       "153150  0.000077       0.000099  \n",
       "153151  0.998522       0.000088  \n",
       "153152  0.000102       0.000087  \n",
       "153153  0.005406       0.000132  \n",
       "153154  0.000112       0.001399  \n",
       "153155  0.998045       0.220686  \n",
       "153156  0.002172       0.000091  \n",
       "153157  0.000079       0.000107  \n",
       "153158  0.999630       0.000084  \n",
       "153159  0.000114       0.000083  \n",
       "153160  0.000095       0.000119  \n",
       "153161  0.000088       0.000085  \n",
       "153162  0.000080       0.000094  \n",
       "153163  0.003818       0.000104  \n",
       "\n",
       "[153164 rows x 7 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new2",
   "language": "python",
   "name": "new2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
