{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shj16110/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 591 ms, sys: 2.21 s, total: 2.8 s\n",
      "Wall time: 4.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, make_scorer, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "from time import strftime, strptime, mktime, time, ctime\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier,\\\n",
    "ExtraTreesClassifier, GradientBoostingClassifier, VotingClassifier, RandomForestClassifier\n",
    "\n",
    "from mlxtend.classifier import StackingClassifier, StackingCVClassifier\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69713, 22)\n",
      "(30037, 21)\n",
      "CPU times: user 13.2 s, sys: 7.01 s, total: 20.2 s\n",
      "Wall time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('./train.csv')\n",
    "print df.shape\n",
    "test = pd.read_csv('./test.csv')\n",
    "print test.shape\n",
    "\n",
    "y = df.pop('Approved')\n",
    "train_id = df.pop('ID')\n",
    "test_id = test.pop('ID')\n",
    "\n",
    "def helper(x):\n",
    "    try:\n",
    "        tmp = strptime(x, '%d/%m/%y')\n",
    "        tmp = mktime(tmp)\n",
    "    except:\n",
    "        tmp = 563000400\n",
    "    return tmp\n",
    "\n",
    "df['Lead_Creation_Date'] = df['Lead_Creation_Date'].apply(helper)\n",
    "test['Lead_Creation_Date'] = test['Lead_Creation_Date'].apply(helper)\n",
    "\n",
    "df['DOB'] = df['DOB'].apply(helper)\n",
    "test['DOB'] = test['DOB'].apply(helper)\n",
    "\n",
    "df = df.fillna(axis=1, value=-1)\n",
    "test = test.fillna(axis=1, value=-1)\n",
    "\n",
    "df = pd.get_dummies(df)\n",
    "test = pd.get_dummies(test)\n",
    "test = test.reindex(columns = df.columns, fill_value=0)\n",
    "\n",
    "test_o = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37295 121\n",
      "CPU times: user 33.6 s, sys: 1e+03 Âµs, total: 33.6 s\n",
      "Wall time: 33.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rid = []\n",
    "\n",
    "for i in df:\n",
    "    if df[i].value_counts().head(1).values[0]>df.shape[0]*0.9975:\n",
    "        rid.append(i)\n",
    "print len(rid), df.shape[1]-len(rid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### from 99 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City_Code_C10022 69315\n",
      "City_Code_C10023 69362\n",
      "City_Code_C10024 69355\n",
      "City_Code_C10025 69413\n",
      "City_Code_C10026 69415\n",
      "City_Code_C10027 69427\n",
      "City_Code_C10028 69458\n",
      "City_Code_C10029 69481\n",
      "Customer_Existing_Primary_Bank_Code_B021 69312\n",
      "Customer_Existing_Primary_Bank_Code_B027 69445\n",
      "Customer_Existing_Primary_Bank_Code_B026 69451\n",
      "Customer_Existing_Primary_Bank_Code_B025 69386\n",
      "Customer_Existing_Primary_Bank_Code_B024 69378\n",
      "City_Code_C10032 69511\n",
      "City_Code_C10031 69506\n",
      "City_Code_C10030 69493\n",
      "City_Code_C10035 69534\n",
      "City_Code_C10034 69520\n",
      "Customer_Existing_Primary_Bank_Code_B030 69511\n",
      "Customer_Existing_Primary_Bank_Code_B031 69512\n",
      "Customer_Existing_Primary_Bank_Code_B032 69526\n",
      "Customer_Existing_Primary_Bank_Code_B033 69525\n",
      "Customer_Existing_Primary_Bank_Code_B034 69529\n",
      "Source_S144 69470\n",
      "Customer_Existing_Primary_Bank_Code_B029 69507\n",
      "Customer_Existing_Primary_Bank_Code_B028 69455\n",
      "Customer_Existing_Primary_Bank_Code_B023 69358\n",
      "Customer_Existing_Primary_Bank_Code_B022 69325\n",
      "Employer_Code_COM0000003 69389\n",
      "Employer_Code_COM0000005 69470\n",
      "Employer_Code_COM0000004 69451\n",
      "Employer_Code_COM0000007 69524\n",
      "Employer_Code_COM0000006 69518\n",
      "Source_S156 69463\n",
      "Source_S153 69310\n"
     ]
    }
   ],
   "source": [
    "for i in set(df.columns)-set(rid):\n",
    "    v = df[i].value_counts().head(1).values[0]\n",
    "    if v>69300:\n",
    "        print i, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37317, 37316)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_rid = rid + ['Customer_Existing_Primary_Bank_Code_B027']\n",
    "len(update_rid), len(rid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update_rid=rid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update_rid = set(df.columns) - set(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update_rid = rid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69713, 121) (30037, 121)\n",
      "CPU times: user 1.21 s, sys: 1.44 s, total: 2.65 s\n",
      "Wall time: 2.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test = test_o.copy()\n",
    "train = df.drop(update_rid, axis=1)\n",
    "test = test.drop(update_rid, axis=1)\n",
    "\n",
    "s = StandardScaler()\n",
    "train = s.fit_transform(train)\n",
    "test = s.transform(test)\n",
    "\n",
    "print train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(55770, 121), (55770,), (13943, 121), (13943,)]\n",
      "CPU times: user 69 ms, sys: 33 ms, total: 102 ms\n",
      "Wall time: 101 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m = lambda *x: [i.shape for i in x]\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, y, stratify=y, test_size=0.2, random_state=23333)\n",
    "print m(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 84 ms, sys: 21 ms, total: 105 ms\n",
      "Wall time: 104 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "d_test = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 2018\n",
    "params = {\n",
    "    'min_child_weight': 0.8,\n",
    "#     'eta': 0.1,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'max_depth': 12,\n",
    "    'subsample': 0.8,\n",
    "    'alpha': 0.3,\n",
    "    'lambda':0.9,\n",
    "    'gamma': 0.3,\n",
    "    'silent': 0,\n",
    "    'learning_rate':0.02,\n",
    "    'verbose_eval': True,\n",
    "    'seed': RANDOM_STATE,\n",
    "    'objective':\"binary:logistic\",\n",
    "#     'eval_metric':'error'\n",
    "#     'num_class':1\n",
    "    'n_jobs':24,\n",
    "    'eval_metric':'auc'\n",
    "    \n",
    "}\n",
    "watchlist = [(d_train, 'train'), (d_test, 'test')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.74433\ttest-auc:0.752664\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 200 rounds.\n",
      "[50]\ttrain-auc:0.872783\ttest-auc:0.837361\n",
      "[100]\ttrain-auc:0.918073\ttest-auc:0.845522\n",
      "[150]\ttrain-auc:0.953087\ttest-auc:0.851378\n",
      "[200]\ttrain-auc:0.973094\ttest-auc:0.855812\n",
      "[250]\ttrain-auc:0.98465\ttest-auc:0.858781\n",
      "[300]\ttrain-auc:0.990822\ttest-auc:0.859448\n",
      "[350]\ttrain-auc:0.994381\ttest-auc:0.860006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'!!! used 13.96 s'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start=time()\n",
    "\n",
    "clf = xgb.train(params, d_train, 357, watchlist, early_stopping_rounds=200, \n",
    "                verbose_eval=50,  maximize=True,\n",
    "               )\n",
    "                \n",
    "\n",
    "\n",
    "'!!! used %.2f s'%(time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.32 s, sys: 7 ms, total: 1.33 s\n",
      "Wall time: 102 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtest = xgb.DMatrix(test)\n",
    "predb = clf.predict(dtest)\n",
    "\n",
    "submit = pd.concat([pd.DataFrame(test_id.values, columns=['ID']), pd.DataFrame(predb, columns=['Approved'])], axis=1)\n",
    "submit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit.to_csv('./submit/xgb_rm_rd.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### lb .852388"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf.save_model('xgb_0.852586.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roc_auc_score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30037, 2)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit2 = pd.concat([pd.DataFrame(test_id.values, columns=['ID']), pd.DataFrame(pred, columns=['Approved'])], axis=1)\n",
    "submit2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9834325467976762"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, [0]*y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87807502, 1.        , 0.99992828, 1.        , 0.98759145])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestClassifier(n_estimators=50, n_jobs=24), df.iloc[:,:-1], df.iloc[:,-1], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr = RandomForestClassifier(n_estimators=50)\n",
    "fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr.fit(df.iloc[:,:-1], df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fr.predict_log_proba"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
