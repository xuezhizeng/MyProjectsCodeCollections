{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from time import time, ctime\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "# import recur7down\n",
    "from info import diary_link\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "\n",
    "reload(sys)\n",
    "sys.setdefaultencoding(\"utf-8\")\n",
    "\n",
    "ct = ctime().split()\n",
    "folder= ct[2]+ct[1]+ct[-1]+'_htmls_diary/'\n",
    "from info import diary_link\n",
    "\n",
    "try:os.mkdir(folder)\n",
    "except:print 'exists'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getsingle(ID):\n",
    "    global fail, n\n",
    "    n+=1\n",
    "    if n%5000==0 or n==1:\n",
    "        print ctime(), 'of ', n, 'failed', len(fail)\n",
    "    try:\n",
    "        one=requests.get(diary_link.format(ID))\n",
    "    except:\n",
    "#         print 'X',\n",
    "        fail.append(ID)\n",
    "    with open(folder+'{}.html'.format(ID), 'w+') as fl:\n",
    "        fl.write(one.text)\n",
    "#     print 'O',\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def batch(allnames):\n",
    "    global n\n",
    "    n=0\n",
    "    start=time()\n",
    "\n",
    "    pool = ThreadPool(cpu)\n",
    "    \n",
    "    results = pool.map(getsingle, allnames)\n",
    "    \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    end = time()\n",
    "    elapse = end - start \n",
    "    now=ctime()[4:]\n",
    "\n",
    "    print 'diary ',len(allnames),'  used ',elapse,'s', now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def html_main():\n",
    "    \n",
    "    n=0\n",
    "    fail=[]\n",
    "    cpu = int(raw_input('(multi-processing) how many process to run ? '))\n",
    "    \n",
    "    try:\n",
    "        f=pd.read_csv('diary_html_fail.csv')\n",
    "    print 'fail exists'\n",
    "        if f.shape[0]>20:\n",
    "            fail=[]\n",
    "            batch(f.values)\n",
    "            os.remove('diary_html_fail.csv')\n",
    "        print 'Done!'\n",
    "        print 1\n",
    "        exit()\n",
    "            # pd.DataFrame(fail, columns=['username']).to_csv('fail.csv',index=False)\n",
    "        else:\n",
    "            print 'Scrape Success!!!'\n",
    "            print len(os.listdir(folder))\n",
    "            os.remove('diary_html_fail.csv')\n",
    "        print 2\n",
    "            exit()\n",
    "        \n",
    "    except:\n",
    "        print 3\n",
    "        print 'fail not exists'\n",
    "        \n",
    "            df=pd.read_csv('diary_all.csv', usecols=['group_id'])\n",
    "            print 'start scraping', ctime()\n",
    "            print len(df['group_id'].unique()), df.shape\n",
    "            \n",
    "            all_ids=df['group_id'].tolist()\n",
    "            \n",
    "            print len(all_ids)\n",
    "            \n",
    "            fail=[]\n",
    "            batch(all_ids)\n",
    "            \n",
    "    if len(fail)>-1:\n",
    "        \n",
    "        pd.DataFrame(fail, columns=['group_id']).to_csv('diary_html_fail.csv',index=False)\n",
    "    else:\n",
    "        print 'done!', ctime()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
