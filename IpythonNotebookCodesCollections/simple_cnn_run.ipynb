{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.1 s, sys: 1.23 s, total: 14.3 s\n",
      "Wall time: 26.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from glob import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import gc\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "\n",
    "# from keras import backend as K\n",
    "# K.set_session(K.tf.Session(config=K.tf.ConfigProto(intra_op_parallelism_threads=24, inter_op_parallelism_threads=24)))\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import IPython.display as ipd\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "from time import time, ctime\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "from time import time, ctime\n",
    "\n",
    "L = 16000\n",
    "legal_labels = 'yes no up down left right on off stop go silence unknown'.split()\n",
    "\n",
    "#src folders\n",
    "root_path = r'.'\n",
    "out_path = r'.'\n",
    "model_path = r'.'\n",
    "train_data_path = os.path.join(root_path, 'data', 'train', 'audio')\n",
    "test_data_path = os.path.join(root_path, 'data', 'test', 'audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_audio(samples):\n",
    "    if len(samples) >= L: return samples\n",
    "    else: return np.pad(samples, pad_width=(L - len(samples), 0), mode='constant', constant_values=(0, 0))\n",
    "\n",
    "def chop_audio(samples, L=16000, num=20):\n",
    "    for i in range(num):\n",
    "        beg = np.random.randint(0, len(samples) - L)\n",
    "        yield samples[beg: beg + L]\n",
    "\n",
    "def label_transform(labels):\n",
    "    nlabels = []\n",
    "    for label in labels:\n",
    "        if label == '_background_noise_':\n",
    "            nlabels.append('silence')\n",
    "        elif label not in legal_labels:\n",
    "            nlabels.append('unknown')\n",
    "        else:\n",
    "            nlabels.append(label)\n",
    "    return pd.get_dummies(pd.Series(nlabels))\n",
    "\n",
    "def custom_fft(y, fs):\n",
    "    T = 1.0 / fs\n",
    "    N = y.shape[0]\n",
    "    yf = fft(y)\n",
    "    xf = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "    # FFT is simmetrical, so we take just the first half\n",
    "    # FFT is also complex, to we take just the real part (abs)\n",
    "    vals = 2.0/N * np.abs(yf[0:N//2])\n",
    "    return xf, vals\n",
    "\n",
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)\n",
    "\n",
    "def list_wavs_fname(dirpath, ext='wav'):\n",
    "    print(dirpath)\n",
    "    fpaths = glob(os.path.join(dirpath, r'*/*' + ext))\n",
    "    pat = r'.+/(\\w+)/\\w+\\.' + ext + '$'\n",
    "    labels = []\n",
    "    for fpath in fpaths:\n",
    "        r = re.match(pat, fpath)\n",
    "        if r:\n",
    "            labels.append(r.group(1))\n",
    "    pat = r'.+/(\\w+\\.' + ext + ')$'\n",
    "    fnames = []\n",
    "    for fpath in fpaths:\n",
    "        r = re.match(pat, fpath)\n",
    "        if r:\n",
    "            fnames.append(r.group(1))\n",
    "    return labels, fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### skip here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/train/audio\n",
      "1/64 2/64 3/64 4/64 5/64 6/64 7/64 8/64 9/64 10/64 11/64 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shj16110/anaconda2/envs/3.6.1/lib/python3.6/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/64 13/64 14/64 15/64 16/64 17/64 18/64 19/64 20/64 21/64 22/64 23/64 24/64 25/64 26/64 27/64 28/64 29/64 30/64 31/64 32/64 33/64 34/64 35/64 36/64 37/64 38/64 39/64 40/64 41/64 42/64 43/64 44/64 45/64 46/64 47/64 48/64 49/64 50/64 51/64 52/64 53/64 54/64 55/64 56/64 57/64 58/64 59/64 60/64 61/64 62/64 63/64 64/64 (64841, 99, 161, 1) (64841, 12) <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "CPU times: user 1min 51s, sys: 9.46 s, total: 2min 1s\n",
      "Wall time: 18min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labels, fnames = list_wavs_fname(train_data_path)\n",
    "\n",
    "new_sample_rate = 16000\n",
    "y_train = []\n",
    "x_train = []\n",
    "\n",
    "n=0\n",
    "for label, fname in zip(labels, fnames):\n",
    "    n+=1\n",
    "    if n%1000==0:\n",
    "        print(int(n/1000), end='/{} '.format(int(len(labels)/1000)))\n",
    "    sample_rate, samples = wavfile.read(os.path.join(train_data_path, label, fname))\n",
    "    \n",
    "    samples = pad_audio(samples)\n",
    "    \n",
    "    if len(samples) > 16000:\n",
    "        n_samples = chop_audio(samples)\n",
    "    else: n_samples = [samples]\n",
    "        \n",
    "    for samples in n_samples:\n",
    "        resampled = signal.resample(samples, int(new_sample_rate / sample_rate * samples.shape[0]))\n",
    "        _, _, specgram = log_specgram(resampled, sample_rate=new_sample_rate)\n",
    "        \n",
    "        y_train.append(label)\n",
    "        x_train.append(specgram)\n",
    "        \n",
    "x_train = np.array(x_train)\n",
    "x_train = x_train.reshape(tuple(list(x_train.shape) + [1]))\n",
    "y_train = label_transform(y_train)\n",
    "label_index = y_train.columns.values\n",
    "y_train = y_train.values\n",
    "y_train = np.array(y_train)\n",
    "del labels, fnames\n",
    "gc.collect()\n",
    "\n",
    "X = x_train.copy()\n",
    "Y = y_train.copy()\n",
    "print (X.shape, Y.shape, type(X), type(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2359\n",
       "1      2372\n",
       "2      2353\n",
       "3      2375\n",
       "4      2357\n",
       "5      2367\n",
       "6      2367\n",
       "7       120\n",
       "8      2380\n",
       "9     41039\n",
       "10     2375\n",
       "11     2377\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['down', 'go', 'left', 'no', 'off', 'on', 'right', 'silence', 'stop',\n",
       "       'unknown', 'up', 'yes'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = label_index.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 ms, sys: 912 ms, total: 917 ms\n",
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.save('X_16k.npy', X)\n",
    "np.save('Y_16k.npy', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mid start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 1.47 s, total: 1.47 s\n",
      "Wall time: 2.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = np.load('X_16k.npy')\n",
    "Y = np.load('Y_16k.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 99, 161, 1)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 99, 161, 1)        4         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 98, 160, 8)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 97, 159, 8)        264       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 24, 39, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 24, 39, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 22, 37, 24)        1752      \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 20, 35, 24)        5208      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 6, 11, 24)         0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 6, 11, 24)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 4, 9, 48)          10416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 1, 3, 48)          0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1, 3, 48)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               37120     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 90,784\n",
      "Trainable params: 90,014\n",
      "Non-trainable params: 770\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (99, 161, 1)\n",
    "nclass = 12\n",
    "inp = Input(shape=input_shape)\n",
    "norm_inp = BatchNormalization()(inp)\n",
    "img_1 = Convolution2D(8, kernel_size=2, activation=activations.relu)(norm_inp)\n",
    "img_1 = Convolution2D(8, kernel_size=2, activation=activations.relu)(img_1)\n",
    "img_1 = MaxPooling2D(pool_size=(4, 4))(img_1)\n",
    "img_1 = Dropout(rate=0.2)(img_1)\n",
    "img_1 = Convolution2D(24, kernel_size=3, activation=activations.relu)(img_1)\n",
    "img_1 = Convolution2D(24, kernel_size=3, activation=activations.relu)(img_1)\n",
    "img_1 = MaxPooling2D(pool_size=(3, 3))(img_1)\n",
    "img_1 = Dropout(rate=0.2)(img_1)\n",
    "img_1 = Convolution2D(48, kernel_size=3, activation=activations.relu)(img_1)\n",
    "img_1 = MaxPooling2D(pool_size=(3, 3))(img_1)\n",
    "img_1 = Dropout(rate=0.2)(img_1)\n",
    "img_1 = Flatten()(img_1)\n",
    "\n",
    "dense_1 = BatchNormalization()(Dense(256, activation=activations.relu)(img_1))\n",
    "dense_1 = BatchNormalization()(Dense(128, activation=activations.relu)(dense_1))\n",
    "dense_1 = Dense(nclass, activation=activations.softmax)(dense_1)\n",
    "\n",
    "model = models.Model(inputs=inp, outputs=dense_1)\n",
    "opt = optimizers.Adam()\n",
    "\n",
    "model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/check-point-deep-learning-models-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "# checkpoint\n",
    "filepath=\"models/F9W-{epoch:02d}-{val_acc:.5f}_.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58356, 99, 161, 1) <class 'numpy.ndarray'>\n",
      "(58356, 12) <class 'numpy.ndarray'>\n",
      "(6485, 99, 161, 1) <class 'numpy.ndarray'>\n",
      "(6485, 12) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = lambda *x: [print(i.shape, type(i)) for i in x]\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.1, random_state=2018)\n",
    "S(x_train, y_train, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 58356 samples, validate on 6485 samples\n",
      "Epoch 1/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.1829 - acc: 0.9375Epoch 00000: val_acc improved from -inf to 0.94945, saving model to models/F9W-00-0.94945_.hdf5\n",
      "58356/58356 [==============================] - 58s - loss: 0.1828 - acc: 0.9375 - val_loss: 0.1328 - val_acc: 0.9494\n",
      "Epoch 2/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.1195 - acc: 0.9550Epoch 00001: val_acc improved from 0.94945 to 0.96777, saving model to models/F9W-01-0.96777_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.1195 - acc: 0.9550 - val_loss: 0.0849 - val_acc: 0.9678\n",
      "Epoch 3/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0963 - acc: 0.9636Epoch 00002: val_acc improved from 0.96777 to 0.97232, saving model to models/F9W-02-0.97232_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0963 - acc: 0.9636 - val_loss: 0.0721 - val_acc: 0.9723\n",
      "Epoch 4/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0866 - acc: 0.9672Epoch 00003: val_acc improved from 0.97232 to 0.97750, saving model to models/F9W-03-0.97750_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0866 - acc: 0.9672 - val_loss: 0.0628 - val_acc: 0.9775\n",
      "Epoch 5/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9697Epoch 00004: val_acc improved from 0.97750 to 0.97899, saving model to models/F9W-04-0.97899_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0802 - acc: 0.9697 - val_loss: 0.0590 - val_acc: 0.9790\n",
      "Epoch 6/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9714Epoch 00005: val_acc improved from 0.97899 to 0.98033, saving model to models/F9W-05-0.98033_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0760 - acc: 0.9714 - val_loss: 0.0566 - val_acc: 0.9803\n",
      "Epoch 7/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9727Epoch 00006: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0726 - acc: 0.9727 - val_loss: 0.0561 - val_acc: 0.9798\n",
      "Epoch 8/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9740Epoch 00007: val_acc improved from 0.98033 to 0.98098, saving model to models/F9W-07-0.98098_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0695 - acc: 0.9740 - val_loss: 0.0533 - val_acc: 0.9810\n",
      "Epoch 9/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9745Epoch 00008: val_acc improved from 0.98098 to 0.98219, saving model to models/F9W-08-0.98219_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0681 - acc: 0.9745 - val_loss: 0.0501 - val_acc: 0.9822\n",
      "Epoch 10/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9750Epoch 00009: val_acc improved from 0.98219 to 0.98300, saving model to models/F9W-09-0.98300_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0664 - acc: 0.9750 - val_loss: 0.0491 - val_acc: 0.9830\n",
      "Epoch 11/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0644 - acc: 0.9758Epoch 00010: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0644 - acc: 0.9758 - val_loss: 0.0473 - val_acc: 0.9828\n",
      "Epoch 12/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9765Epoch 00011: val_acc improved from 0.98300 to 0.98310, saving model to models/F9W-11-0.98310_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0633 - acc: 0.9765 - val_loss: 0.0466 - val_acc: 0.9831\n",
      "Epoch 13/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9771Epoch 00012: val_acc improved from 0.98310 to 0.98404, saving model to models/F9W-12-0.98404_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0620 - acc: 0.9770 - val_loss: 0.0432 - val_acc: 0.9840\n",
      "Epoch 14/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9775Epoch 00013: val_acc improved from 0.98404 to 0.98493, saving model to models/F9W-13-0.98493_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0606 - acc: 0.9774 - val_loss: 0.0433 - val_acc: 0.9849\n",
      "Epoch 15/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9777Epoch 00014: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0598 - acc: 0.9777 - val_loss: 0.0433 - val_acc: 0.9845\n",
      "Epoch 16/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9781Epoch 00015: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0590 - acc: 0.9781 - val_loss: 0.0458 - val_acc: 0.9840\n",
      "Epoch 17/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9785Epoch 00016: val_acc improved from 0.98493 to 0.98530, saving model to models/F9W-16-0.98530_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0580 - acc: 0.9785 - val_loss: 0.0423 - val_acc: 0.9853\n",
      "Epoch 18/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9789Epoch 00017: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0570 - acc: 0.9789 - val_loss: 0.0436 - val_acc: 0.9849\n",
      "Epoch 19/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9785Epoch 00018: val_acc improved from 0.98530 to 0.98648, saving model to models/F9W-18-0.98648_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0576 - acc: 0.9785 - val_loss: 0.0395 - val_acc: 0.9865\n",
      "Epoch 20/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9788Epoch 00019: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0569 - acc: 0.9788 - val_loss: 0.0426 - val_acc: 0.9847\n",
      "Epoch 21/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0556 - acc: 0.9794Epoch 00020: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0556 - acc: 0.9794 - val_loss: 0.0407 - val_acc: 0.9857\n",
      "Epoch 22/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9795Epoch 00021: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0550 - acc: 0.9795 - val_loss: 0.0414 - val_acc: 0.9855\n",
      "Epoch 23/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9797Epoch 00022: val_acc improved from 0.98648 to 0.98666, saving model to models/F9W-22-0.98666_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0546 - acc: 0.9797 - val_loss: 0.0388 - val_acc: 0.9867\n",
      "Epoch 24/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0536 - acc: 0.9801Epoch 00023: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0536 - acc: 0.9801 - val_loss: 0.0391 - val_acc: 0.9861\n",
      "Epoch 25/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9799Epoch 00024: val_acc improved from 0.98666 to 0.98680, saving model to models/F9W-24-0.98680_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0540 - acc: 0.9799 - val_loss: 0.0382 - val_acc: 0.9868\n",
      "Epoch 26/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9802Epoch 00025: val_acc improved from 0.98680 to 0.98688, saving model to models/F9W-25-0.98688_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0535 - acc: 0.9802 - val_loss: 0.0377 - val_acc: 0.9869\n",
      "Epoch 27/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0527 - acc: 0.9805Epoch 00026: val_acc improved from 0.98688 to 0.98689, saving model to models/F9W-26-0.98689_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0527 - acc: 0.9805 - val_loss: 0.0365 - val_acc: 0.9869\n",
      "Epoch 28/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9807Epoch 00027: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0525 - acc: 0.9807 - val_loss: 0.0383 - val_acc: 0.9862\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9806Epoch 00028: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0523 - acc: 0.9806 - val_loss: 0.0382 - val_acc: 0.9864\n",
      "Epoch 30/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9806Epoch 00029: val_acc improved from 0.98689 to 0.98697, saving model to models/F9W-29-0.98697_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0522 - acc: 0.9806 - val_loss: 0.0370 - val_acc: 0.9870\n",
      "Epoch 31/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9811Epoch 00030: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0515 - acc: 0.9811 - val_loss: 0.0381 - val_acc: 0.9862\n",
      "Epoch 32/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9809Epoch 00031: val_acc improved from 0.98697 to 0.98714, saving model to models/F9W-31-0.98714_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0515 - acc: 0.9809 - val_loss: 0.0367 - val_acc: 0.9871\n",
      "Epoch 33/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9811Epoch 00032: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0514 - acc: 0.9811 - val_loss: 0.0368 - val_acc: 0.9870\n",
      "Epoch 34/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9814Epoch 00033: val_acc improved from 0.98714 to 0.98781, saving model to models/F9W-33-0.98781_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0505 - acc: 0.9813 - val_loss: 0.0354 - val_acc: 0.9878\n",
      "Epoch 35/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9813Epoch 00034: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0509 - acc: 0.9813 - val_loss: 0.0375 - val_acc: 0.9867\n",
      "Epoch 36/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9815Epoch 00035: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0503 - acc: 0.9815 - val_loss: 0.0362 - val_acc: 0.9870\n",
      "Epoch 37/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9816Epoch 00036: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0500 - acc: 0.9815 - val_loss: 0.0374 - val_acc: 0.9866\n",
      "Epoch 38/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9819Epoch 00037: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0492 - acc: 0.9819 - val_loss: 0.0358 - val_acc: 0.9873\n",
      "Epoch 39/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9818Epoch 00038: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0496 - acc: 0.9818 - val_loss: 0.0370 - val_acc: 0.9867\n",
      "Epoch 40/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9818Epoch 00039: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0490 - acc: 0.9818 - val_loss: 0.0373 - val_acc: 0.9866\n",
      "Epoch 41/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0489 - acc: 0.9820Epoch 00040: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0489 - acc: 0.9820 - val_loss: 0.0361 - val_acc: 0.9875\n",
      "Epoch 42/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9819Epoch 00041: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0487 - acc: 0.9819 - val_loss: 0.0363 - val_acc: 0.9870\n",
      "Epoch 43/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9820Epoch 00042: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0490 - acc: 0.9820 - val_loss: 0.0358 - val_acc: 0.9872\n",
      "Epoch 44/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9824Epoch 00043: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0483 - acc: 0.9824 - val_loss: 0.0344 - val_acc: 0.9875\n",
      "Epoch 45/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9822Epoch 00044: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0483 - acc: 0.9822 - val_loss: 0.0352 - val_acc: 0.9875\n",
      "Epoch 46/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9825Epoch 00045: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0477 - acc: 0.9825 - val_loss: 0.0358 - val_acc: 0.9873\n",
      "Epoch 47/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9824Epoch 00046: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0476 - acc: 0.9824 - val_loss: 0.0359 - val_acc: 0.9872\n",
      "Epoch 48/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9821Epoch 00047: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0474 - acc: 0.9821 - val_loss: 0.0348 - val_acc: 0.9878\n",
      "Epoch 49/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9825Epoch 00048: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0476 - acc: 0.9825 - val_loss: 0.0349 - val_acc: 0.9876\n",
      "Epoch 50/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9826Epoch 00049: val_acc improved from 0.98781 to 0.98815, saving model to models/F9W-49-0.98815_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0472 - acc: 0.9826 - val_loss: 0.0334 - val_acc: 0.9882\n",
      "Epoch 51/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9826Epoch 00050: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0470 - acc: 0.9826 - val_loss: 0.0353 - val_acc: 0.9871\n",
      "Epoch 52/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9829Epoch 00051: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0467 - acc: 0.9829 - val_loss: 0.0328 - val_acc: 0.9880\n",
      "Epoch 53/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9827Epoch 00052: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0467 - acc: 0.9827 - val_loss: 0.0344 - val_acc: 0.9881\n",
      "Epoch 54/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9827Epoch 00053: val_acc improved from 0.98815 to 0.98822, saving model to models/F9W-53-0.98822_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0467 - acc: 0.9827 - val_loss: 0.0336 - val_acc: 0.9882\n",
      "Epoch 55/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9829Epoch 00054: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0464 - acc: 0.9829 - val_loss: 0.0350 - val_acc: 0.9876\n",
      "Epoch 56/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9829Epoch 00055: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0463 - acc: 0.9829 - val_loss: 0.0330 - val_acc: 0.9881\n",
      "Epoch 57/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9830Epoch 00056: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0460 - acc: 0.9830 - val_loss: 0.0328 - val_acc: 0.9882\n",
      "Epoch 58/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9832Epoch 00057: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0455 - acc: 0.9832 - val_loss: 0.0341 - val_acc: 0.9880\n",
      "Epoch 59/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9831Epoch 00058: val_acc improved from 0.98822 to 0.98825, saving model to models/F9W-58-0.98825_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0456 - acc: 0.9831 - val_loss: 0.0329 - val_acc: 0.9883\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9831Epoch 00059: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0457 - acc: 0.9831 - val_loss: 0.0349 - val_acc: 0.9876\n",
      "Epoch 61/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9831Epoch 00060: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0458 - acc: 0.9831 - val_loss: 0.0338 - val_acc: 0.9881\n",
      "Epoch 62/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9834Epoch 00061: val_acc improved from 0.98825 to 0.98840, saving model to models/F9W-61-0.98840_.hdf5\n",
      "58356/58356 [==============================] - 57s - loss: 0.0450 - acc: 0.9834 - val_loss: 0.0331 - val_acc: 0.9884\n",
      "Epoch 63/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9832Epoch 00062: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0455 - acc: 0.9832 - val_loss: 0.0358 - val_acc: 0.9871\n",
      "Epoch 64/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9834Epoch 00063: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0452 - acc: 0.9834 - val_loss: 0.0338 - val_acc: 0.9882\n",
      "Epoch 65/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9832Epoch 00064: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0448 - acc: 0.9832 - val_loss: 0.0339 - val_acc: 0.9881\n",
      "Epoch 66/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9833Epoch 00065: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0455 - acc: 0.9833 - val_loss: 0.0339 - val_acc: 0.9880\n",
      "Epoch 67/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9834Epoch 00066: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0446 - acc: 0.9834 - val_loss: 0.0334 - val_acc: 0.9879\n",
      "Epoch 68/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9836Epoch 00067: val_acc did not improve\n",
      "58356/58356 [==============================] - 57s - loss: 0.0443 - acc: 0.9836 - val_loss: 0.0334 - val_acc: 0.9880\n",
      "CPU times: user 48min 36s, sys: 10min 26s, total: 59min 3s\n",
      "Wall time: 1h 4min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b170893ff28>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Fit the model\n",
    "model.fit(x_train, y_train, batch_size=64, validation_data=(x_valid, y_valid), \n",
    "          epochs=100, shuffle=True, verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(os.path.join(model_path, 'cnn.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn.model\t      F9W-61-0.98840_.hdf5\r\n",
      "F9W-00-0.94945_.hdf5  weights-improvement-00-0.96690_.hdf5\r\n",
      "F9W-01-0.96777_.hdf5  weights-improvement-00-0.97.hdf5\r\n",
      "F9W-02-0.97232_.hdf5  weights-improvement-00-0.99.hdf5\r\n",
      "F9W-03-0.97750_.hdf5  weights-improvement-01-0.97809_.hdf5\r\n",
      "F9W-04-0.97899_.hdf5  weights-improvement-01-0.99.hdf5\r\n",
      "F9W-05-0.98033_.hdf5  weights-improvement-02-0.98144_.hdf5\r\n",
      "F9W-07-0.98098_.hdf5  weights-improvement-02-0.99.hdf5\r\n",
      "F9W-08-0.98219_.hdf5  weights-improvement-03-0.98531_.hdf5\r\n",
      "F9W-09-0.98300_.hdf5  weights-improvement-04-0.98585_.hdf5\r\n",
      "F9W-11-0.98310_.hdf5  weights-improvement-04-0.99.hdf5\r\n",
      "F9W-12-0.98404_.hdf5  weights-improvement-05-0.98909_.hdf5\r\n",
      "F9W-13-0.98493_.hdf5  weights-improvement-05-0.99.hdf5\r\n",
      "F9W-16-0.98530_.hdf5  weights-improvement-06-0.99.hdf5\r\n",
      "F9W-18-0.98648_.hdf5  weights-improvement-08-0.98913_.hdf5\r\n",
      "F9W-22-0.98666_.hdf5  weights-improvement-08-0.99.hdf5\r\n",
      "F9W-24-0.98680_.hdf5  weights-improvement-09-0.99013_.hdf5\r\n",
      "F9W-25-0.98688_.hdf5  weights-improvement-10-0.99050_.hdf5\r\n",
      "F9W-26-0.98689_.hdf5  weights-improvement-11-0.99.hdf5\r\n",
      "F9W-29-0.98697_.hdf5  weights-improvement-12-0.99088_.hdf5\r\n",
      "F9W-31-0.98714_.hdf5  weights-improvement-13-0.99140_.hdf5\r\n",
      "F9W-33-0.98781_.hdf5  weights-improvement-14-0.99.hdf5\r\n",
      "F9W-49-0.98815_.hdf5  weights-improvement-16-0.99180_.hdf5\r\n",
      "F9W-53-0.98822_.hdf5  weights-improvement-17-0.99226_.hdf5\r\n",
      "F9W-58-0.98825_.hdf5  weights-improvement-18-0.99247_.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "!ls models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mname = 'models/F9W-61-0.98840_.hdf5'\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model(Mname)\n",
    "\n",
    "label_index = np.array(['down', 'go', 'left', 'no', 'off', 'on', 'right',\n",
    "                        'silence', 'stop', 'unknown', 'up', 'yes']).astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_data_generator(batch=16):\n",
    "    fpaths = glob(os.path.join(test_data_path, '*wav'))\n",
    "    i = 0\n",
    "    for path in fpaths:\n",
    "        if i == 0:\n",
    "            imgs = []\n",
    "            fnames = []\n",
    "        i += 1\n",
    "        rate, samples = wavfile.read(path)\n",
    "        samples = pad_audio(samples)\n",
    "        resampled = signal.resample(samples, int(new_sample_rate / rate * samples.shape[0]))\n",
    "        _, _, specgram = log_specgram(resampled, sample_rate=new_sample_rate)\n",
    "        imgs.append(specgram)\n",
    "        fnames.append(path.split('\\\\')[-1])\n",
    "        if i == batch:\n",
    "            i = 0\n",
    "            imgs = np.array(imgs)\n",
    "            imgs = imgs.reshape(tuple(list(imgs.shape) + [1]))\n",
    "            yield fnames, imgs\n",
    "    if i < batch:\n",
    "        imgs = np.array(imgs)\n",
    "        imgs = imgs.reshape(tuple(list(imgs.shape) + [1]))\n",
    "        yield fnames, imgs\n",
    "    raise StopIteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used: 13.73 s :640 used: 13.25 s :1280 used: 12.88 s :1920 used: 13.40 s :2560 used: 12.69 s :3200 used: 11.78 s :3840 used: 12.75 s :4480 used: 31.98 s :5120 used: 20.51 s :5760 used: 14.33 s :6400 used: 18.25 s :7040 used: 13.73 s :7680 used: 12.88 s :8320 used: 12.99 s :8960 used: 13.00 s :9600 used: 12.50 s :10240 used: 11.69 s :10880 used: 13.10 s :11520 used: 13.14 s :12160 used: 12.76 s :12800 used: 13.42 s :13440 used: 14.64 s :14080 used: 13.36 s :14720 used: 11.46 s :15360 used: 12.71 s :16000 used: 13.51 s :16640 used: 13.35 s :17280 used: 13.24 s :17920 used: 12.90 s :18560 used: 12.72 s :19200 used: 11.89 s :19840 used: 12.87 s :20480 used: 13.08 s :21120 used: 13.36 s :21760 used: 12.83 s :22400 used: 12.72 s :23040 used: 12.59 s :23680 used: 11.65 s :24320 used: 12.89 s :24960 used: 12.76 s :25600 used: 12.93 s :26240 used: 12.85 s :26880 used: 13.63 s :27520 used: 11.63 s :28160 used: 12.00 s :28800 used: 12.90 s :29440 used: 13.33 s :30080 used: 13.10 s :30720 used: 13.32 s :31360 used: 12.90 s :32000 used: 11.21 s :32640 used: 12.99 s :33280 used: 13.14 s :33920 used: 12.83 s :34560 used: 13.31 s :35200 used: 29.76 s :35840 used: 16.11 s :36480 used: 19.81 s :37120 used: 17.74 s :37760 used: 14.33 s :38400 used: 12.63 s :39040 used: 10.96 s :39680 used: 12.74 s :40320 used: 13.11 s :40960 used: 30.95 s :41600 used: 20.94 s :42240 used: 14.95 s :42880 used: 10.54 s :43520 used: 18.14 s :44160 used: 15.02 s :44800 used: 11.94 s :45440 used: 12.99 s :46080 used: 13.04 s :46720 used: 13.27 s :47360 used: 12.78 s :48000 used: 11.46 s :48640 used: 11.49 s :49280 used: 13.12 s :49920 used: 12.96 s :50560 used: 12.91 s :51200 used: 13.04 s :51840 used: 12.68 s :52480 used: 11.95 s :53120 used: 13.27 s :53760 used: 13.19 s :54400 used: 12.88 s :55040 used: 12.91 s :55680 used: 12.98 s :56320 used: 12.96 s :56960 used: 12.61 s :57600 used: 12.48 s :58240 used: 16.87 s :58880 used: 30.52 s :59520 used: 17.48 s :60160 used: 14.26 s :60800 used: 18.38 s :61440 used: 17.02 s :62080 used: 12.52 s :62720 used: 12.87 s :63360 used: 13.43 s :64000 used: 11.62 s :64640 used: 13.11 s :65280 used: 13.24 s :65920 used: 13.29 s :66560 used: 13.60 s :67200 used: 12.85 s :67840 used: 12.61 s :68480 used: 12.47 s :69120 used: 12.89 s :69760 used: 13.19 s :70400 used: 29.13 s :71040 used: 22.08 s :71680 used: 13.84 s :72320 used: 20.16 s :72960 used: 16.41 s :73600 used: 11.95 s :74240 used: 13.04 s :74880 used: 13.01 s :75520 used: 12.38 s :76160 used: 13.55 s :76800 used: 12.92 s :77440 used: 13.06 s :78080 used: 13.06 s :78720 used: 13.41 s :79360 used: 12.25 s :80000 used: 12.50 s :80640 used: 12.94 s :81280 used: 13.20 s :81920 used: 12.63 s :82560 used: 12.56 s :83200 used: 12.96 s :83840 used: 11.90 s :84480 used: 12.54 s :85120 used: 13.03 s :85760 used: 13.38 s :86400 used: 12.91 s :87040 used: 13.03 s :87680 used: 13.03 s :88320 used: 11.83 s :88960 used: 12.57 s :89600 used: 13.04 s :90240 used: 13.29 s :90880 used: 12.64 s :91520 used: 13.06 s :92160 used: 13.80 s :92800 used: 11.61 s :93440 used: 12.78 s :94080 used: 13.44 s :94720 used: 12.83 s :95360 used: 12.90 s :96000 used: 13.08 s :96640 used: 13.13 s :97280 used: 12.26 s :97920 used: 12.95 s :98560 used: 13.08 s :99200 used: 12.89 s :99840 used: 13.02 s :100480 used: 13.16 s :101120 used: 12.92 s :101760 used: 13.09 s :102400 used: 12.92 s :103040 used: 13.77 s :103680 used: 17.79 s :104320 used: 32.16 s :104960 used: 18.76 s :105600 used: 18.75 s :106240 used: 16.73 s :106880 used: 12.83 s :107520 used: 12.86 s :108160 used: 12.95 s :108800 used: 12.74 s :109440 used: 13.22 s :110080 used: 13.08 s :110720 used: 13.03 s :111360 used: 13.02 s :112000 used: 13.26 s :112640 used: 13.03 s :113280 used: 12.90 s :113920 used: 13.93 s :114560 used: 12.73 s :115200 used: 12.78 s :115840 used: 13.27 s :116480 used: 12.70 s :117120 used: 12.75 s :117760 used: 12.98 s :118400 used: 13.16 s :119040 used: 12.94 s :119680 used: 13.25 s :120320 used: 12.71 s :120960 used: 13.01 s :121600 used: 12.74 s :122240 used: 12.93 s :122880 used: 12.86 s :123520 used: 12.86 s :124160 used: 12.79 s :124800 used: 12.84 s :125440 used: 13.11 s :126080 used: 13.29 s :126720 used: 12.97 s :127360 used: 13.00 s :128000 used: 12.84 s :128640 used: 12.41 s :129280 used: 13.77 s :129920 used: 12.95 s :130560 used: 14.08 s :131200 used: 15.08 s :131840 used: 14.89 s :132480 used: 14.04 s :133120 used: 14.93 s :133760 used: 14.75 s :134400 used: 13.73 s :135040 used: 15.57 s :135680 used: 14.72 s :136320 used: 14.56 s :136960 used: 14.27 s :137600 used: 14.56 s :138240 used: 13.57 s :138880 used: 13.50 s :139520 used: 12.94 s :140160 used: 13.00 s :140800 used: 12.02 s :141440 used: 11.15 s :142080 used: 11.11 s :142720 used: 11.26 s :143360 used: 11.06 s :144000 used: 12.15 s :144640 used: 12.62 s :145280 used: 11.25 s :145920 used: 11.66 s :146560 used: 11.35 s :147200 used: 11.32 s :147840 used: 11.64 s :148480 used: 11.14 s :149120 used: 11.10 s :149760 used: 11.22 s :150400 used: 11.63 s :151040 used: 12.00 s :151680 used: 12.19 s :152320 used: 11.48 s :152960 used: 29.72 s :153600 used: 13.50 s :154240 used: 12.74 s :154880 used: 13.21 s :155520 used: 12.82 s :156160 used: 12.29 s :156800 used: 12.21 s :157440 used: 11.60 s :158080 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shj16110/anaconda2/envs/3.6.1/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: generator 'test_data_generator' raised StopIteration\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 51s, sys: 20.9 s, total: 5min 12s\n",
      "Wall time: 56min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch = 64\n",
    "start = time()\n",
    "\n",
    "\n",
    "#exit() #delete this\n",
    "#del x_train, y_train\n",
    "gc.collect()\n",
    "\n",
    "index = []\n",
    "results = []\n",
    "N=0\n",
    "for fnames, imgs in test_data_generator(batch=batch):\n",
    "    N+=1\n",
    "    if N%10==0:\n",
    "        print ('used: {:.2f} s'.format(time()-start), end=' :{} '.format(N*batch))\n",
    "        start = time()\n",
    "    predicts = model.predict(imgs)\n",
    "    predicts = np.argmax(predicts, axis=1)\n",
    "    predicts = [label_index[p] for p in predicts]\n",
    "    index.extend(fnames)\n",
    "    results.extend(predicts)\n",
    "\n",
    "df = pd.DataFrame(columns=['fname', 'label'])\n",
    "df['fname'] = index\n",
    "df['label'] = results\n",
    "\n",
    "\n",
    "df['fname'] = df['fname'].apply(lambda x:x.split('audio/')[-1])\n",
    "df.to_csv(os.path.join(out_path, Mname.split('/')[-1]+'_submission.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(os.path.join(out_path, Mname.split('/')[-1]+'_submission.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU3",
   "language": "python",
   "name": "gpu3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
