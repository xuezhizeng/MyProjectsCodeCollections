{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !ls -hl|grep csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time, ctime\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, classification, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, StratifiedShuffleSplit\n",
    "\n",
    "from helper import plot_confusion_matrix, plot_confusion_matrix2\n",
    "dim=lambda *x: [i.shape for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10585739437251976968\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "K.set_session(sess)\n",
    "\n",
    "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34219, 853)\n",
      "CPU times: user 2.26 s, sys: 153 ms, total: 2.42 s\n",
      "Wall time: 2.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('./prepared_for_GPU.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_index= [0, 1, 2, 3, 4, 747, 748, 749, 757, 766, 767, 768, 769, 770, 771, 774, \n",
    "            775, 836, 837, 838, 839, 840, 841, 842, 843, 846, 847, 848, 849, 850]\n",
    "len(cat_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=df.iloc[:, 2:]\n",
    "y=df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username_split_predict</th>\n",
       "      <th>last</th>\n",
       "      <th>last_two</th>\n",
       "      <th>first</th>\n",
       "      <th>first2</th>\n",
       "      <th>about.company</th>\n",
       "      <th>about.hourly_rate</th>\n",
       "      <th>about.primary_language</th>\n",
       "      <th>Month</th>\n",
       "      <th>city_3</th>\n",
       "      <th>...</th>\n",
       "      <th>identity_verified</th>\n",
       "      <th>payment_verified</th>\n",
       "      <th>phone_verified</th>\n",
       "      <th>profile_complete</th>\n",
       "      <th>country_5</th>\n",
       "      <th>timezone_5</th>\n",
       "      <th>pred_about.username_sentence</th>\n",
       "      <th>pred_about.username</th>\n",
       "      <th>pred_about.display_name</th>\n",
       "      <th>pred_about.public_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>659</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>124</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>559</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19537</td>\n",
       "      <td>124</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8503</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>194</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>694</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>337</td>\n",
       "      <td>124</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4700</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>362</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19538</td>\n",
       "      <td>124</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5797</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>170</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>559</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>124</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>307</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>170</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   username_split_predict  last  last_two  first  first2  about.company  \\\n",
       "0                       1    22       659      0       0             26   \n",
       "1                       2    14       284      0       0          19537   \n",
       "2                       0    22       694      0       0            337   \n",
       "3                       2    23       362      0       1          19538   \n",
       "4                       2    28       559      0       1             26   \n",
       "\n",
       "   about.hourly_rate  about.primary_language  Month  city_3  \\\n",
       "0                124                       5      2     559   \n",
       "1                124                       5      5    8503   \n",
       "2                124                       5      1    4700   \n",
       "3                124                       5      7    5797   \n",
       "4                124                       5      8     307   \n",
       "\n",
       "            ...            identity_verified  payment_verified  \\\n",
       "0           ...                            1                 2   \n",
       "1           ...                            1                 1   \n",
       "2           ...                            1                 1   \n",
       "3           ...                            1                 1   \n",
       "4           ...                            1                 1   \n",
       "\n",
       "   phone_verified  profile_complete  country_5  timezone_5  \\\n",
       "0               1                 2        169         220   \n",
       "1               1                 2         14         194   \n",
       "2               1                 1        170          57   \n",
       "3               1                 2        170          95   \n",
       "4               1                 2        170          95   \n",
       "\n",
       "   pred_about.username_sentence  pred_about.username  pred_about.display_name  \\\n",
       "0                             1                    1                        1   \n",
       "1                             2                    2                        2   \n",
       "2                             0                    0                        0   \n",
       "3                             2                    2                        2   \n",
       "4                             2                    2                        2   \n",
       "\n",
       "   pred_about.public_name  \n",
       "0                       1  \n",
       "1                       2  \n",
       "2                       0  \n",
       "3                       2  \n",
       "4                       2  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[:,cat_index].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in X.iloc[:,cat_index]:\n",
    "#     print (i, len(X[i].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34219, 851)\n",
      "(34219, 37603)\n",
      "CPU times: user 2.06 s, sys: 1.96 s, total: 4.02 s\n",
      "Wall time: 4.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "print (X.shape)\n",
    "onehotencoder = OneHotEncoder(categorical_features = cat_index)\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34219, 37603)\n",
      "CPU times: user 16.6 s, sys: 8.76 s, total: 25.4 s\n",
      "Wall time: 25.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X=sc.fit_transform(X)\n",
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(23953, 37603), (10266, 37603), (23953,), (10266,)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                   random_state=7)\n",
    "dim(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# # fit on training set\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# # only transform on test set\n",
    "# X_test = sc.transform(X_test)\n",
    "# print dim(X_train,X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               4813312   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 4,879,489\n",
      "Trainable params: 4,879,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "# first hidden layer\n",
    "classifier.add(Dense(units = 128, \n",
    "                     input_dim=37603,\n",
    "                     kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.5))\n",
    "# second hidden layer\n",
    "classifier.add(Dense(units = 128,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.4))\n",
    "# second hidden layer\n",
    "classifier.add(Dense(units = 128,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.3))\n",
    "# thrid hidden layer\n",
    "classifier.add(Dense(units = 128,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.2))\n",
    "# thrid hidden layer\n",
    "classifier.add(Dense(units = 128,  kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "# # ouput layer\n",
    "classifier.add(Dense(units = 1,  kernel_initializer='uniform', activation='sigmoid'))\n",
    "# compiling the ANN\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics= ['accuracy'])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback, EarlyStopping\n",
    "class TestCallback(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "        \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=1)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopping = EarlyStopping(monitor='acc', min_delta=0,\n",
    "                              patience=16, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23953 samples, validate on 10266 samples\n",
      "Epoch 1/300\n",
      "23953/23953 [==============================] - 10s - loss: 0.4590 - acc: 0.8299 - val_loss: 0.4381 - val_acc: 0.8323\n",
      "Epoch 2/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.3466 - acc: 0.8455 - val_loss: 0.4601 - val_acc: 0.8336\n",
      "Epoch 3/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.1831 - acc: 0.9287 - val_loss: 0.5145 - val_acc: 0.8201\n",
      "Epoch 4/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0825 - acc: 0.9686 - val_loss: 0.7834 - val_acc: 0.8179\n",
      "Epoch 5/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0525 - acc: 0.9798 - val_loss: 0.9328 - val_acc: 0.8179\n",
      "Epoch 6/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0375 - acc: 0.9866 - val_loss: 1.1134 - val_acc: 0.8035\n",
      "Epoch 7/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0248 - acc: 0.9908 - val_loss: 1.2419 - val_acc: 0.8060\n",
      "Epoch 8/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0232 - acc: 0.9917 - val_loss: 1.1423 - val_acc: 0.8071\n",
      "Epoch 9/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0202 - acc: 0.9929 - val_loss: 1.0843 - val_acc: 0.7855\n",
      "Epoch 10/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0195 - acc: 0.9940 - val_loss: 1.6067 - val_acc: 0.8269\n",
      "Epoch 11/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0156 - acc: 0.9948 - val_loss: 1.5259 - val_acc: 0.7996\n",
      "Epoch 12/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0141 - acc: 0.9960 - val_loss: 1.1727 - val_acc: 0.8118\n",
      "Epoch 13/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0104 - acc: 0.9969 - val_loss: 1.3757 - val_acc: 0.8008\n",
      "Epoch 14/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0108 - acc: 0.9972 - val_loss: 1.5467 - val_acc: 0.8134\n",
      "Epoch 15/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0099 - acc: 0.9972 - val_loss: 1.3539 - val_acc: 0.8223\n",
      "Epoch 16/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0085 - acc: 0.9972 - val_loss: 1.7943 - val_acc: 0.8118\n",
      "Epoch 17/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0093 - acc: 0.9975 - val_loss: 1.6425 - val_acc: 0.8222\n",
      "Epoch 18/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0093 - acc: 0.9978 - val_loss: 1.8206 - val_acc: 0.8220\n",
      "Epoch 19/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0097 - acc: 0.9971 - val_loss: 1.6685 - val_acc: 0.8177\n",
      "Epoch 20/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0067 - acc: 0.9980 - val_loss: 1.8791 - val_acc: 0.8170\n",
      "Epoch 21/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0066 - acc: 0.9983 - val_loss: 2.0056 - val_acc: 0.7982\n",
      "Epoch 22/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0064 - acc: 0.9985 - val_loss: 1.7289 - val_acc: 0.8087\n",
      "Epoch 23/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0112 - acc: 0.9975 - val_loss: 1.4328 - val_acc: 0.8184\n",
      "Epoch 24/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0087 - acc: 0.9970 - val_loss: 1.7115 - val_acc: 0.8111\n",
      "Epoch 25/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0085 - acc: 0.9978 - val_loss: 1.8327 - val_acc: 0.8135\n",
      "Epoch 26/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0077 - acc: 0.9977 - val_loss: 1.7791 - val_acc: 0.8027\n",
      "Epoch 27/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0056 - acc: 0.9982 - val_loss: 1.9398 - val_acc: 0.8163\n",
      "Epoch 28/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0049 - acc: 0.9984 - val_loss: 2.0957 - val_acc: 0.8088\n",
      "Epoch 29/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0074 - acc: 0.9977 - val_loss: 1.8193 - val_acc: 0.8174\n",
      "Epoch 30/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0057 - acc: 0.9981 - val_loss: 1.9256 - val_acc: 0.8193\n",
      "Epoch 31/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0052 - acc: 0.9983 - val_loss: 1.8008 - val_acc: 0.8130\n",
      "Epoch 32/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0059 - acc: 0.9980 - val_loss: 1.9415 - val_acc: 0.8209\n",
      "Epoch 33/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0039 - acc: 0.9990 - val_loss: 2.3155 - val_acc: 0.8132\n",
      "Epoch 34/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0076 - acc: 0.9977 - val_loss: 1.8138 - val_acc: 0.7968\n",
      "Epoch 35/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0070 - acc: 0.9979 - val_loss: 1.8114 - val_acc: 0.8227\n",
      "Epoch 36/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0052 - acc: 0.9979 - val_loss: 1.8415 - val_acc: 0.7946\n",
      "Epoch 37/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0089 - acc: 0.9977 - val_loss: 1.9354 - val_acc: 0.8135\n",
      "Epoch 38/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0057 - acc: 0.9982 - val_loss: 1.9824 - val_acc: 0.7983\n",
      "Epoch 39/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0063 - acc: 0.9983 - val_loss: 1.8089 - val_acc: 0.8026\n",
      "Epoch 40/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0071 - acc: 0.9980 - val_loss: 2.0820 - val_acc: 0.8119\n",
      "Epoch 41/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0055 - acc: 0.9982 - val_loss: 2.1363 - val_acc: 0.8255\n",
      "Epoch 42/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0050 - acc: 0.9986 - val_loss: 2.2995 - val_acc: 0.8237\n",
      "Epoch 43/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0077 - acc: 0.9979 - val_loss: 2.0641 - val_acc: 0.8203\n",
      "Epoch 44/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0107 - acc: 0.9971 - val_loss: 1.8643 - val_acc: 0.8200\n",
      "Epoch 45/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0051 - acc: 0.9988 - val_loss: 2.0376 - val_acc: 0.8143\n",
      "Epoch 46/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0075 - acc: 0.9980 - val_loss: 1.8828 - val_acc: 0.8052\n",
      "Epoch 47/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0067 - acc: 0.9980 - val_loss: 2.0814 - val_acc: 0.8136071 - acc: - ETA: 1s - loss: 0.00\n",
      "Epoch 48/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0050 - acc: 0.9981 - val_loss: 2.0854 - val_acc: 0.8170\n",
      "Epoch 49/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0051 - acc: 0.9984 - val_loss: 2.2262 - val_acc: 0.8247\n",
      "Epoch 50/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0030 - acc: 0.9990 - val_loss: 2.2111 - val_acc: 0.8196\n",
      "Epoch 51/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0032 - acc: 0.9990 - val_loss: 2.1686 - val_acc: 0.8094\n",
      "Epoch 52/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0052 - acc: 0.9983 - val_loss: 2.2188 - val_acc: 0.8211\n",
      "Epoch 53/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0036 - acc: 0.9987 - val_loss: 2.2084 - val_acc: 0.8245\n",
      "Epoch 54/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0060 - acc: 0.9986 - val_loss: 2.2945 - val_acc: 0.8253\n",
      "Epoch 55/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0049 - acc: 0.9986 - val_loss: 2.2721 - val_acc: 0.8255\n",
      "Epoch 56/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0060 - acc: 0.9982 - val_loss: 2.0891 - val_acc: 0.8157\n",
      "Epoch 57/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0056 - acc: 0.9984 - val_loss: 2.2009 - val_acc: 0.8165\n",
      "Epoch 58/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0056 - acc: 0.9987 - val_loss: 2.1866 - val_acc: 0.8283\n",
      "Epoch 59/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0062 - acc: 0.9985 - val_loss: 2.1122 - val_acc: 0.8182\n",
      "Epoch 60/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0082 - acc: 0.9981 - val_loss: 1.8028 - val_acc: 0.8075\n",
      "Epoch 61/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0052 - acc: 0.9984 - val_loss: 2.0765 - val_acc: 0.8075\n",
      "Epoch 62/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0058 - acc: 0.9982 - val_loss: 2.2199 - val_acc: 0.8063\n",
      "Epoch 63/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23953/23953 [==============================] - 9s - loss: 0.0048 - acc: 0.9984 - val_loss: 1.9916 - val_acc: 0.8111\n",
      "Epoch 64/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0052 - acc: 0.9989 - val_loss: 2.2280 - val_acc: 0.8206\n",
      "Epoch 65/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0039 - acc: 0.9988 - val_loss: 2.1605 - val_acc: 0.8160\n",
      "Epoch 66/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0063 - acc: 0.9983 - val_loss: 2.0667 - val_acc: 0.8156\n",
      "Epoch 67/300\n",
      "23953/23953 [==============================] - 9s - loss: 0.0051 - acc: 0.9982 - val_loss: 2.0611 - val_acc: 0.8139\n",
      "Epoch 00066: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2abe0cd16510>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting ANN with training set\n",
    "classifier.fit(X_train, y_train, \n",
    "               batch_size=96, epochs=300,\n",
    "               validation_data=(X_test, y_test),\n",
    "#           callbacks=[TestCallback((X_test, y_test))])\n",
    "          callbacks=[stopping])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.808007013442\n",
      "Confusion matrix, without normalization\n",
      "[[ 372 1350]\n",
      " [ 621 7923]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVkAAAEmCAYAAADIhuPPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZM3MCshB1sysgBxkzcwKyEHWzKyA/h9inSo+5cTfKwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b63419f7630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred> 0.5)\n",
    "\n",
    "print (accuracy_score(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plot_confusion_matrix(cm, ['female','male'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
