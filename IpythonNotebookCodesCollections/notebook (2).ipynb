{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "37070448-9c94-480d-8ad4-55d84b7349b0",
    "_uuid": "c20c67f2226b24051e2d64a63555059d96969829",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#changes:\n",
    "#optimizing RNN and Ridge again\n",
    "#based on https://www.kaggle.com/valkling/mercari-rnn-2ridge-models-with-notes-0-42755\n",
    "#required libraries\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime \n",
    "start_real = datetime.now()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dropout, Dense, concatenate, GRU, Embedding, Flatten, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from nltk.corpus import stopwords\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dd34009a-f007-487c-9acf-f653dbf05083",
    "_uuid": "41233bd862bb32f02ecb44fcd50dd6aeb97cf457",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set seed\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "da19503f-4c26-4289-a393-10979eec831b",
    "_uuid": "2283bddbecd96beda65dd05063efdb8ae7af3bd2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the train and test data\n",
    "train_df = pd.read_table('../input/train.tsv')\n",
    "test_df = pd.read_table('../input/test.tsv')\n",
    "#check the shape of the dataframes\n",
    "print('train:',train_df.shape, ',test:',test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "01a1d8a6-5c33-4895-b38a-e653405d4515",
    "_uuid": "c5b4b04003b5bef8dfe77956404fcb679bbe92fe",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check the head\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5c8ee26f-8e0f-4a41-9cda-9e3ab5345c8b",
    "_uuid": "a684c1c62a0be7051428097c89a3e9c70b66b3f9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# removing prices less than 3\n",
    "train_df = train_df.drop(train_df[(train_df.price < 3.0)].index)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6be124d1-47e0-47dc-9c9b-ffc6cb65e198",
    "_uuid": "cb8e74d18f6fdcea8c872fd4db0e2d965ba4e6c7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# handling categorical variables\n",
    "def wordCount(text):\n",
    "    try:\n",
    "        if text == 'No description yet':\n",
    "            return 0\n",
    "        else:\n",
    "            text = text.lower()\n",
    "            words = [w for w in text.split(\" \")]\n",
    "            return len(words)\n",
    "    except: \n",
    "        return 0\n",
    "train_df['desc_len'] = train_df['item_description'].apply(lambda x: wordCount(x))\n",
    "test_df['desc_len'] = test_df['item_description'].apply(lambda x: wordCount(x))\n",
    "train_df['name_len'] = train_df['name'].apply(lambda x: wordCount(x))\n",
    "test_df['name_len'] = test_df['name'].apply(lambda x: wordCount(x))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "abeccd2c-58e6-41c1-a6c1-1dd6ef8bd865",
    "_uuid": "613ddbe40aa121bd0db4bb1dd54e296af2280d2a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#splitting category_name into subcategories\n",
    "def split_cat(text):\n",
    "    try: return text.split(\"/\")\n",
    "    except: return (\"No Label\", \"No Label\", \"No Label\")\n",
    "train_df['subcat_0'], train_df['subcat_1'], train_df['subcat_2'] = \\\n",
    "zip(*train_df['category_name'].apply(lambda x: split_cat(x)))\n",
    "test_df['subcat_0'], test_df['subcat_1'], test_df['subcat_2'] = \\\n",
    "zip(*test_df['category_name'].apply(lambda x: split_cat(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4def964e-beef-4462-9320-a8580bca5266",
    "_uuid": "e234460ad55200f02527c96732ac0a7bb03141bd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combine the train and test dataframes\n",
    "full_set = pd.concat([train_df,test_df])\n",
    "#handling brand_name\n",
    "all_brands = set(full_set['brand_name'].values)\n",
    "#fill NA values\n",
    "train_df.brand_name.fillna(value=\"missing\", inplace=True)\n",
    "test_df.brand_name.fillna(value=\"missing\", inplace=True)\n",
    "premissing = len(train_df.loc[train_df['brand_name'] == 'missing'])\n",
    "def brandfinder(line):\n",
    "    brand = line[0]\n",
    "    name = line[1]\n",
    "    namesplit = name.split(' ')\n",
    "    if brand == 'missing':\n",
    "        for x in namesplit:\n",
    "            if x in all_brands:\n",
    "                return name\n",
    "    if name in all_brands:\n",
    "        return name\n",
    "    return brand\n",
    "train_df['brand_name'] = train_df[['brand_name','name']].apply(brandfinder, axis = 1)\n",
    "test_df['brand_name'] = test_df[['brand_name','name']].apply(brandfinder, axis = 1)\n",
    "found = premissing-len(train_df.loc[train_df['brand_name'] == 'missing'])\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6c0bc548-902b-487c-b5a7-9764929a1dc8",
    "_uuid": "bc45b6f2ba18ccc18e7384d3b3c45e03f3e469ee",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scale target variable-price to log\n",
    "train_df[\"target\"] = np.log1p(train_df.price)\n",
    "# Split training examples into train/dev\n",
    "train_df, dev_df = train_test_split(train_df, random_state=123, train_size=0.99)\n",
    "# Calculate number of train/dev/test examples.\n",
    "n_trains = train_df.shape[0]\n",
    "n_devs = dev_df.shape[0]\n",
    "n_tests = test_df.shape[0]\n",
    "print(\"Training on:\", n_trains, \"examples\")\n",
    "print(\"Validating on:\", n_devs, \"examples\")\n",
    "print(\"Testing on:\", n_tests, \"examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c64b37da-5520-463b-ac9a-1e252f480f43",
    "_uuid": "ad39cb0df2bceff7137f5e1f2adedf9b4dfca644",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate train - dev - test data for easy to handle\n",
    "full_df = pd.concat([train_df, dev_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1a1ed869-50a4-47c5-bc03-09bae865e122",
    "_uuid": "e3e38892529ad682f04a110a55e61658fde6b0fb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filling missing values in combine dataset\n",
    "def fill_missing_values(df):\n",
    "    df.category_name.fillna(value=\"missing\", inplace=True)\n",
    "    df.brand_name.fillna(value=\"missing\", inplace=True)\n",
    "    df.item_description.fillna(value=\"missing\", inplace=True)\n",
    "    df.item_description.replace('No description yet',\"missing\", inplace=True)\n",
    "    return df\n",
    "\n",
    "print(\"Filling missing data...\")\n",
    "full_df = fill_missing_values(full_df)\n",
    "print(full_df.category_name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dd15ba39-9e3c-4862-bbab-0863baeb811e",
    "_uuid": "970dd182726a09c9724cad94672012ab697dea7a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Processing categorical data...\")\n",
    "le = LabelEncoder()\n",
    "le.fit(full_df.category_name)\n",
    "full_df['category'] = le.transform(full_df.category_name)\n",
    "\n",
    "le.fit(full_df.brand_name)\n",
    "full_df.brand_name = le.transform(full_df.brand_name)\n",
    "\n",
    "le.fit(full_df.subcat_0)\n",
    "full_df.subcat_0 = le.transform(full_df.subcat_0)\n",
    "\n",
    "le.fit(full_df.subcat_1)\n",
    "full_df.subcat_1 = le.transform(full_df.subcat_1)\n",
    "\n",
    "le.fit(full_df.subcat_2)\n",
    "full_df.subcat_2 = le.transform(full_df.subcat_2)\n",
    "\n",
    "del le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "39237335-633c-49d0-8e3b-e93bc844a4bf",
    "_uuid": "f803773e74c1f4b232eaf9be4737a8b2ec199df1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Transforming text data to sequences...\")\n",
    "raw_text = np.hstack([full_df.item_description.str.lower(), full_df.name.str.lower(), full_df.category_name.str.lower()])\n",
    "\n",
    "print(\"Fitting tokenizer...\")\n",
    "tok_raw = Tokenizer()\n",
    "tok_raw.fit_on_texts(raw_text)\n",
    "\n",
    "print(\"Transforming text to sequences...\")\n",
    "full_df['seq_item_description'] = tok_raw.texts_to_sequences(full_df.item_description.str.lower())\n",
    "full_df['seq_name'] = tok_raw.texts_to_sequences(full_df.name.str.lower())\n",
    "\n",
    "del tok_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1bb2d470-fce8-4102-93c4-bb0aa7e9ac35",
    "_uuid": "3bfc9b047052fe46521a81f3dc454bcb4fd0222f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#constants to use in RNN model\n",
    "MAX_NAME_SEQ = 10\n",
    "MAX_ITEM_DESC_SEQ = 75\n",
    "MAX_CATEGORY_SEQ = 8\n",
    "MAX_TEXT = np.max([\n",
    "    np.max(full_df.seq_name.max()),\n",
    "    np.max(full_df.seq_item_description.max()),\n",
    "]) + 100\n",
    "MAX_CATEGORY = np.max(full_df.category.max()) + 1\n",
    "MAX_BRAND = np.max(full_df.brand_name.max()) + 1\n",
    "MAX_CONDITION = np.max(full_df.item_condition_id.max()) + 1\n",
    "MAX_DESC_LEN = np.max(full_df.desc_len.max()) + 1\n",
    "MAX_NAME_LEN = np.max(full_df.name_len.max()) + 1\n",
    "MAX_SUBCAT_0 = np.max(full_df.subcat_0.max()) + 1\n",
    "MAX_SUBCAT_1 = np.max(full_df.subcat_1.max()) + 1\n",
    "MAX_SUBCAT_2 = np.max(full_df.subcat_2.max()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6b1f5cfa-e61a-4f62-a2fd-4ddaba4ceab7",
    "_uuid": "3dd651e67151c5463388ceed8b445455d398d19b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#transform the data for RNN model\n",
    "def get_rnn_data(dataset):\n",
    "    X = {\n",
    "        'name': pad_sequences(dataset.seq_name, maxlen=MAX_NAME_SEQ),\n",
    "        'item_desc': pad_sequences(dataset.seq_item_description, maxlen=MAX_ITEM_DESC_SEQ),\n",
    "        'brand_name': np.array(dataset.brand_name),\n",
    "        'category': np.array(dataset.category),\n",
    "        'item_condition': np.array(dataset.item_condition_id),\n",
    "        'num_vars': np.array(dataset[[\"shipping\"]]),\n",
    "        'desc_len': np.array(dataset[[\"desc_len\"]]),\n",
    "        'name_len': np.array(dataset[[\"name_len\"]]),\n",
    "        'subcat_0': np.array(dataset.subcat_0),\n",
    "        'subcat_1': np.array(dataset.subcat_1),\n",
    "        'subcat_2': np.array(dataset.subcat_2),\n",
    "    }\n",
    "    return X\n",
    "\n",
    "train = full_df[:n_trains]\n",
    "dev = full_df[n_trains:n_trains+n_devs]\n",
    "test = full_df[n_trains+n_devs:]\n",
    "\n",
    "X_train = get_rnn_data(train)\n",
    "Y_train = train.target.values.reshape(-1, 1)\n",
    "\n",
    "X_dev = get_rnn_data(dev)\n",
    "Y_dev = dev.target.values.reshape(-1, 1)\n",
    "\n",
    "X_test = get_rnn_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "de4976e7-bcc1-4841-b7ac-04c3689a6e4b",
    "_uuid": "cd509f83a3d9b911f825715c99725cac55571731",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#our own loss function\n",
    "def root_mean_squared_logarithmic_error(y_true, y_pred):\n",
    "    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
    "    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n",
    "    return K.sqrt(K.mean(K.square(first_log - second_log), axis=-1)+0.0000001)\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)+0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0ac3b518-2121-47d1-ba0e-cf348e69ca08",
    "_uuid": "ff62be98838b6763440d3a7f402304ff28a9647f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#build the model\n",
    "np.random.seed(123)\n",
    "\n",
    "def new_rnn_model(lr=0.001, decay=0.0):\n",
    "    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n",
    "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n",
    "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
    "    item_condition = Input(shape=[1], name=\"item_condition\")\n",
    "    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n",
    "    desc_len = Input(shape=[1], name=\"desc_len\")\n",
    "    name_len = Input(shape=[1], name=\"name_len\")\n",
    "    subcat_0 = Input(shape=[1], name=\"subcat_0\")\n",
    "    subcat_1 = Input(shape=[1], name=\"subcat_1\")\n",
    "    subcat_2 = Input(shape=[1], name=\"subcat_2\")\n",
    "\n",
    "    # Embeddings layers (adjust outputs to help model)\n",
    "    emb_name = Embedding(MAX_TEXT, 20)(name)\n",
    "    emb_item_desc = Embedding(MAX_TEXT, 60)(item_desc)\n",
    "    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n",
    "    emb_item_condition = Embedding(MAX_CONDITION, 5)(item_condition)\n",
    "    emb_desc_len = Embedding(MAX_DESC_LEN, 5)(desc_len)\n",
    "    emb_name_len = Embedding(MAX_NAME_LEN, 5)(name_len)\n",
    "    emb_subcat_0 = Embedding(MAX_SUBCAT_0, 10)(subcat_0)\n",
    "    emb_subcat_1 = Embedding(MAX_SUBCAT_1, 10)(subcat_1)\n",
    "    emb_subcat_2 = Embedding(MAX_SUBCAT_2, 10)(subcat_2)\n",
    "    \n",
    "\n",
    "    # rnn layers (GRUs are faster than LSTMs and speed is important here)\n",
    "    rnn_layer1 = GRU(16) (emb_item_desc)\n",
    "    rnn_layer2 = GRU(8) (emb_name)\n",
    "\n",
    "    # main layers\n",
    "    main_l = concatenate([\n",
    "        Flatten() (emb_brand_name)\n",
    "        , Flatten() (emb_item_condition)\n",
    "        , Flatten() (emb_desc_len)\n",
    "        , Flatten() (emb_name_len)\n",
    "        , Flatten() (emb_subcat_0)\n",
    "        , Flatten() (emb_subcat_1)\n",
    "        , Flatten() (emb_subcat_2)\n",
    "        , rnn_layer1\n",
    "        , rnn_layer2\n",
    "        , num_vars\n",
    "    ])\n",
    "    \n",
    "    # (incressing the nodes or adding layers does not effect the time quite as much as the rnn layers)\n",
    "    main_l = Dropout(0.1)(Dense(512,kernel_initializer='normal',activation='relu') (main_l))\n",
    "    main_l = Dropout(0.1)(Dense(256,kernel_initializer='normal',activation='relu') (main_l))\n",
    "    main_l = Dropout(0.1)(Dense(128,kernel_initializer='normal',activation='relu') (main_l))\n",
    "    main_l = Dropout(0.1)(Dense(64,kernel_initializer='normal',activation='relu') (main_l))\n",
    "\n",
    "    # the output layer.\n",
    "    output = Dense(1, activation=\"linear\") (main_l)\n",
    "    \n",
    "    model = Model([name, item_desc, brand_name , item_condition, \n",
    "                   num_vars, desc_len, name_len, subcat_0, subcat_1, subcat_2], output)\n",
    "\n",
    "    optimizer = Adam(lr=lr, decay=decay)\n",
    "    \n",
    "    # (mean squared error loss function works as well as custom functions)  \n",
    "    model.compile(loss = 'mse', optimizer = optimizer)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = new_rnn_model()\n",
    "model.summary()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c869b8ff-1c8d-4bcb-93b6-ebb5a02ca47a",
    "_uuid": "707c0feb2a8310823e51cae17e72529b44be9868",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Fit RNN model to train data\n",
    "\n",
    "# Set hyper parameters for the model\n",
    "BATCH_SIZE = 512 * 3\n",
    "epochs = 2\n",
    "\n",
    "# Calculate learning rate decay\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "steps = int(len(X_train['name']) / BATCH_SIZE) * epochs\n",
    "lr_init, lr_fin = 0.005, 0.001\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "\n",
    "# Create model and fit it with training dataset.\n",
    "rnn_model = new_rnn_model(lr=lr_init, decay=lr_decay)\n",
    "rnn_model.fit(\n",
    "        X_train, Y_train, epochs=epochs, batch_size=BATCH_SIZE,\n",
    "        validation_data=(X_dev, Y_dev), verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4cdd48a1-6f99-4399-81af-bf0c5ce10a92",
    "_uuid": "1b2c86508e2c8820efc2f1dacc5c28e4a3aac02f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define RMSL Error Function for checking prediction\n",
    "def rmsle(Y, Y_pred):\n",
    "    assert Y.shape == Y_pred.shape\n",
    "    return np.sqrt(np.mean(np.square(Y_pred - Y )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dc4e5faa-5b08-4449-916d-7b9ae1ce7f6f",
    "_uuid": "55b8eeb768e87f8b5c857950cd17713eebe008cb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Evaluating the model on validation data...\")\n",
    "Y_dev_preds_rnn = rnn_model.predict(X_dev, batch_size=BATCH_SIZE)\n",
    "print(\" RMSLE error:\", rmsle(Y_dev, Y_dev_preds_rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6b55c3dd-1a69-45a3-8321-f06de00af125",
    "_uuid": "77c6a2dfade8fb0ccc61c4b8bd099ee23ea3a09d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prediction for test data\n",
    "rnn_preds = rnn_model.predict(X_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "rnn_preds = np.expm1(rnn_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3e52acb0-56f1-4b29-bcf9-4395a5a02feb",
    "_uuid": "776ebda8f629ae01758e2e75cd15d0d4090685d3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ridge modelling\n",
    "# Concatenate train - dev - test data for furthur handling\n",
    "full_df = pd.concat([train_df, dev_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4482a57a-5838-422e-bcac-0c8a6febdf30",
    "_uuid": "993fd20a8a5ac48dbe3b972c1c76f191f4ca8169",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Handling missing values...\")\n",
    "full_df['category_name'] = full_df['category_name'].fillna('missing').astype(str)\n",
    "full_df['subcat_0'] = full_df['subcat_0'].astype(str)\n",
    "full_df['subcat_1'] = full_df['subcat_1'].astype(str)\n",
    "full_df['subcat_2'] = full_df['subcat_2'].astype(str)\n",
    "full_df['brand_name'] = full_df['brand_name'].fillna('missing').astype(str)\n",
    "full_df['shipping'] = full_df['shipping'].astype(str)\n",
    "full_df['item_condition_id'] = full_df['item_condition_id'].astype(str)\n",
    "full_df['desc_len'] = full_df['desc_len'].astype(str)\n",
    "full_df['name_len'] = full_df['name_len'].astype(str)\n",
    "full_df['item_description'] = full_df['item_description'].fillna('No description yet').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "be6edeb5-536a-4632-945e-024defa512a6",
    "_uuid": "79ae2186779aa4201e34ff401a52efc654daf8e6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Vectorizing data for Ridge Modeling...\")\n",
    "default_preprocessor = CountVectorizer().build_preprocessor()\n",
    "def build_preprocessor(field):\n",
    "    field_idx = list(full_df.columns).index(field)\n",
    "    return lambda x: default_preprocessor(x[field_idx])\n",
    "\n",
    "vectorizer = FeatureUnion([\n",
    "    ('name', CountVectorizer(\n",
    "        ngram_range=(1, 2),\n",
    "        max_features=50000,\n",
    "        preprocessor=build_preprocessor('name'))),\n",
    "    ('subcat_0', CountVectorizer(\n",
    "        token_pattern='.+',\n",
    "        preprocessor=build_preprocessor('subcat_0'))),\n",
    "    ('subcat_1', CountVectorizer(\n",
    "        token_pattern='.+',\n",
    "        preprocessor=build_preprocessor('subcat_1'))),\n",
    "    ('subcat_2', CountVectorizer(\n",
    "        token_pattern='.+',\n",
    "        preprocessor=build_preprocessor('subcat_2'))),\n",
    "    ('brand_name', CountVectorizer(\n",
    "        token_pattern='.+',\n",
    "        preprocessor=build_preprocessor('brand_name'))),\n",
    "    ('shipping', CountVectorizer(\n",
    "        token_pattern='\\d+',\n",
    "        preprocessor=build_preprocessor('shipping'))),\n",
    "    ('item_condition_id', CountVectorizer(\n",
    "        token_pattern='\\d+',\n",
    "        preprocessor=build_preprocessor('item_condition_id'))),\n",
    "    ('desc_len', CountVectorizer(\n",
    "        token_pattern='\\d+',\n",
    "        preprocessor=build_preprocessor('desc_len'))),\n",
    "    ('name_len', CountVectorizer(\n",
    "        token_pattern='\\d+',\n",
    "        preprocessor=build_preprocessor('name_len'))),\n",
    "    ('item_description', TfidfVectorizer(\n",
    "        ngram_range=(1, 3),\n",
    "        max_features=100000,\n",
    "        preprocessor=build_preprocessor('item_description'))),\n",
    "])\n",
    "\n",
    "X = vectorizer.fit_transform(full_df.values)\n",
    "\n",
    "X_train = X[:n_trains]\n",
    "Y_train = train_df.target.values.reshape(-1, 1)\n",
    "\n",
    "X_dev = X[n_trains:n_trains+n_devs]\n",
    "Y_dev = dev_df.target.values.reshape(-1, 1)\n",
    "\n",
    "X_test = X[n_trains+n_devs:]\n",
    "print(X.shape, X_train.shape, X_dev.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "83014200-caf3-43e0-8954-f37505c71f0b",
    "_uuid": "f23d12a0925df8e346bba1a46379e28bd647bc79",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Fitting Ridge model on training examples...\")\n",
    "ridge_model = Ridge(\n",
    "    solver='auto', fit_intercept=True, alpha=1.0,\n",
    "    max_iter=100, normalize=False, tol=0.05, random_state = 1,\n",
    ")\n",
    "ridge_modelCV = RidgeCV(\n",
    "    fit_intercept=True, alphas=[5.0],\n",
    "    normalize=False, cv = 2, scoring='neg_mean_squared_error',\n",
    ")\n",
    "ridge_model.fit(X_train, Y_train)\n",
    "ridge_modelCV.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4ae09c19-ca30-4ac7-ba66-16aeb3bbd200",
    "_uuid": "3e78b9961fe9207a973e7c340fde2ecf030177dd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Evaluating Ridge model on dev data\n",
    "Y_dev_preds_ridge = ridge_model.predict(X_dev)\n",
    "Y_dev_preds_ridge = Y_dev_preds_ridge.reshape(-1, 1)\n",
    "print(\"RMSL error on dev set:\", rmsle(Y_dev, Y_dev_preds_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0852edbd-ac60-425d-838a-e56c2831d3bf",
    "_uuid": "9b52065ba99fbb275fbe98569f8aafd2a8b3f6ee",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_dev_preds_ridgeCV = ridge_modelCV.predict(X_dev)\n",
    "Y_dev_preds_ridgeCV = Y_dev_preds_ridgeCV.reshape(-1, 1)\n",
    "print(\"CV RMSL error on dev set:\", rmsle(Y_dev, Y_dev_preds_ridgeCV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0787a567-84ee-4512-a165-c91f109558f6",
    "_uuid": "ecc7b459b45a8116b881d342610b68e4c41f2d2a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#prediction for test data\n",
    "ridge_preds = ridge_model.predict(X_test)\n",
    "ridge_preds = np.expm1(ridge_preds)\n",
    "ridgeCV_preds = ridge_modelCV.predict(X_test)\n",
    "ridgeCV_preds = np.expm1(ridgeCV_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "63532ab8-4b0f-4f29-9d9f-ad867c86c030",
    "_uuid": "53773836ce4b4eb009f8cf8e4469ab0881ce44aa",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#combine all predictions\n",
    "def aggregate_predicts3(Y1, Y2, Y3, ratio1, ratio2):\n",
    "    assert Y1.shape == Y2.shape\n",
    "    return Y1 * ratio1 + Y2 * ratio2 + Y3 * (1.0 - ratio1-ratio2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4282d2be-6493-4e34-884b-f4dd64a9671c",
    "_uuid": "0e1b468a4bf3b42bbe8d9c97d6339327e9159be8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#ratio optimum finder for 3 models\n",
    "best1 = 0\n",
    "best2 = 0\n",
    "lowest = 0.99\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "        r = i*0.01\n",
    "        r2 = j*0.01\n",
    "        if r+r2 < 1.0:\n",
    "            Y_dev_preds = aggregate_predicts3(Y_dev_preds_rnn, Y_dev_preds_ridgeCV, Y_dev_preds_ridge, r, r2)\n",
    "            fpred = rmsle(Y_dev, Y_dev_preds)\n",
    "            if fpred < lowest:\n",
    "                best1 = r\n",
    "                best2 = r2\n",
    "                lowest = fpred\n",
    "Y_dev_preds = aggregate_predicts3(Y_dev_preds_rnn, Y_dev_preds_ridgeCV, Y_dev_preds_ridge, best1, best2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b9abb667-bbcd-443d-935b-062ba46a6a38",
    "_uuid": "a98d7c19335d88159dedc5e51a806728bac769e0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"(Best) RMSL error for RNN + Ridge + RidgeCV on dev set:\", rmsle(Y_dev, Y_dev_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fae667bb-4c77-49f9-bced-b169ce88daf4",
    "_uuid": "444a4754b58c8385988cf684f5244801fa73a521",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best predicted submission\n",
    "preds = aggregate_predicts3(rnn_preds, ridgeCV_preds, ridge_preds, best1, best2)\n",
    "submission = pd.DataFrame({\n",
    "        \"test_id\": test_df.test_id,\n",
    "        \"price\": preds.reshape(-1),\n",
    "})\n",
    "submission.to_csv(\"./rnn_ridge_submission.csv\", index=False)\n",
    "print(\"completed time:\")\n",
    "stop_real = datetime.now()\n",
    "execution_time_real = stop_real-start_real \n",
    "print(execution_time_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2aa46af6-fb85-4401-9d97-d076fc172318",
    "_uuid": "a65d465072232d55e25ef731d40ceb5eb95076a4",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
