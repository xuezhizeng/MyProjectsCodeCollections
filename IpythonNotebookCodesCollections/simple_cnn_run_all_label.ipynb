{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.3 s, sys: 1.23 s, total: 15.5 s\n",
      "Wall time: 26.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from glob import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import gc\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "\n",
    "# from keras import backend as K\n",
    "# K.set_session(K.tf.Session(config=K.tf.ConfigProto(intra_op_parallelism_threads=24, inter_op_parallelism_threads=24)))\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import IPython.display as ipd\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "from time import time, ctime\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "from time import time, ctime\n",
    "\n",
    "L = 16000\n",
    "legal_labels = 'yes no up down left right on off stop go silence unknown'.split()\n",
    "\n",
    "#src folders\n",
    "root_path = r'.'\n",
    "out_path = r'.'\n",
    "model_path = r'.'\n",
    "train_data_path = os.path.join(root_path, 'data', 'train', 'audio')\n",
    "test_data_path = os.path.join(root_path, 'data', 'test', 'audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_audio(samples):\n",
    "    if len(samples) >= L: return samples\n",
    "    else: return np.pad(samples, pad_width=(L - len(samples), 0), mode='constant', constant_values=(0, 0))\n",
    "\n",
    "def chop_audio(samples, L=16000, num=20):\n",
    "    for i in range(num):\n",
    "        beg = np.random.randint(0, len(samples) - L)\n",
    "        yield samples[beg: beg + L]\n",
    "\n",
    "def label_transform(labels):\n",
    "    nlabels = []\n",
    "    for label in labels:\n",
    "        if label == '_background_noise_':\n",
    "            nlabels.append('silence')\n",
    "#         elif label not in legal_labels:\n",
    "#             nlabels.append('unknown')\n",
    "        else:\n",
    "            nlabels.append(label)\n",
    "    return pd.get_dummies(pd.Series(nlabels))\n",
    "\n",
    "def custom_fft(y, fs):\n",
    "    T = 1.0 / fs\n",
    "    N = y.shape[0]\n",
    "    yf = fft(y)\n",
    "    xf = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "    # FFT is simmetrical, so we take just the first half\n",
    "    # FFT is also complex, to we take just the real part (abs)\n",
    "    vals = 2.0/N * np.abs(yf[0:N//2])\n",
    "    return xf, vals\n",
    "\n",
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)\n",
    "\n",
    "def list_wavs_fname(dirpath, ext='wav'):\n",
    "    print(dirpath)\n",
    "    fpaths = glob(os.path.join(dirpath, r'*/*' + ext))\n",
    "    pat = r'.+/(\\w+)/\\w+\\.' + ext + '$'\n",
    "    labels = []\n",
    "    for fpath in fpaths:\n",
    "        r = re.match(pat, fpath)\n",
    "        if r:\n",
    "            labels.append(r.group(1))\n",
    "    pat = r'.+/(\\w+\\.' + ext + ')$'\n",
    "    fnames = []\n",
    "    for fpath in fpaths:\n",
    "        r = re.match(pat, fpath)\n",
    "        if r:\n",
    "            fnames.append(r.group(1))\n",
    "    return labels, fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### skip here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/train/audio\n",
      "1/64 2/64 3/64 4/64 5/64 6/64 7/64 8/64 9/64 10/64 11/64 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shj16110/anaconda2/envs/3.6.1/lib/python3.6/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/64 13/64 14/64 15/64 16/64 17/64 18/64 19/64 20/64 21/64 22/64 23/64 24/64 25/64 26/64 27/64 28/64 29/64 30/64 31/64 32/64 33/64 34/64 35/64 36/64 37/64 38/64 39/64 40/64 41/64 42/64 43/64 44/64 45/64 46/64 47/64 48/64 49/64 50/64 51/64 52/64 53/64 54/64 55/64 56/64 57/64 58/64 59/64 60/64 61/64 62/64 63/64 64/64 (64841, 99, 161, 1) (64841, 31) <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "CPU times: user 1min 49s, sys: 7.31 s, total: 1min 56s\n",
      "Wall time: 17min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labels, fnames = list_wavs_fname(train_data_path)\n",
    "\n",
    "new_sample_rate = 16000\n",
    "y_train = []\n",
    "x_train = []\n",
    "\n",
    "n=0\n",
    "for label, fname in zip(labels, fnames):\n",
    "    n+=1\n",
    "    if n%1000==0:\n",
    "        print(int(n/1000), end='/{} '.format(int(len(labels)/1000)))\n",
    "    sample_rate, samples = wavfile.read(os.path.join(train_data_path, label, fname))\n",
    "    \n",
    "    samples = pad_audio(samples)\n",
    "    \n",
    "    if len(samples) > 16000:\n",
    "        n_samples = chop_audio(samples)\n",
    "    else: n_samples = [samples]\n",
    "        \n",
    "    for samples in n_samples:\n",
    "        resampled = signal.resample(samples, int(new_sample_rate / sample_rate * samples.shape[0]))\n",
    "        _, _, specgram = log_specgram(resampled, sample_rate=new_sample_rate)\n",
    "        \n",
    "        y_train.append(label)\n",
    "        x_train.append(specgram)\n",
    "        \n",
    "x_train = np.array(x_train)\n",
    "x_train = x_train.reshape(tuple(list(x_train.shape) + [1]))\n",
    "y_train = label_transform(y_train)\n",
    "\n",
    "label_index = y_train.columns.values\n",
    "\n",
    "y_train = y_train.values\n",
    "y_train = np.array(y_train)\n",
    "del labels, fnames\n",
    "gc.collect()\n",
    "\n",
    "X = x_train.copy()\n",
    "Y = y_train.copy()\n",
    "print (X.shape, Y.shape, type(X), type(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index = np.array(list(['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go',\n",
    "       'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on',\n",
    "       'one', 'right', 'seven', 'sheila', 'silence', 'six', 'stop',\n",
    "       'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero'])).astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 877 ms, total: 877 ms\n",
      "Wall time: 1.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.save('X_31label_16k.npy', X)\n",
    "np.save('Y_31label_16k.npy', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mid start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 1.32 s, total: 1.32 s\n",
      "Wall time: 1.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = np.load('X_31label_16k.npy')\n",
    "Y = np.load('Y_31label_16k.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 99, 161, 1)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 99, 161, 1)        4         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 98, 160, 12)       60        \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 97, 159, 12)       588       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 32, 53, 12)        0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 32, 53, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 30, 51, 24)        2616      \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 28, 49, 24)        5208      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 9, 16, 24)         0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 9, 16, 24)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 7, 14, 32)         6944      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 2, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 2, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 168)               43176     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 168)               672       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 168)               28392     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 168)               672       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 31)                5239      \n",
      "=================================================================\n",
      "Total params: 93,571\n",
      "Trainable params: 92,897\n",
      "Non-trainable params: 674\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (99, 161, 1)\n",
    "nclass = 31\n",
    "inp = Input(shape=input_shape)\n",
    "norm_inp = BatchNormalization()(inp)\n",
    "img_1 = Convolution2D(12, kernel_size=2, activation=activations.relu)(norm_inp)\n",
    "img_1 = Convolution2D(12, kernel_size=2, activation=activations.relu)(img_1)\n",
    "img_1 = MaxPooling2D(pool_size=(3, 3))(img_1)\n",
    "img_1 = Dropout(rate=0.2)(img_1)\n",
    "img_1 = Convolution2D(24, kernel_size=3, activation=activations.relu)(img_1)\n",
    "img_1 = Convolution2D(24, kernel_size=3, activation=activations.relu)(img_1)\n",
    "img_1 = MaxPooling2D(pool_size=(3, 3))(img_1)\n",
    "img_1 = Dropout(rate=0.2)(img_1)\n",
    "img_1 = Convolution2D(32, kernel_size=3, activation=activations.relu)(img_1)\n",
    "img_1 = MaxPooling2D(pool_size=(3, 3))(img_1)\n",
    "img_1 = Dropout(rate=0.2)(img_1)\n",
    "img_1 = Flatten()(img_1)\n",
    "\n",
    "dense_1 = BatchNormalization()(Dense(168, activation=activations.relu)(img_1))\n",
    "dense_1 = BatchNormalization()(Dense(168, activation=activations.relu)(dense_1))\n",
    "dense_1 = Dense(nclass, activation=activations.softmax)(dense_1)\n",
    "\n",
    "model = models.Model(inputs=inp, outputs=dense_1)\n",
    "opt = optimizers.Adam()\n",
    "\n",
    "model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/check-point-deep-learning-models-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "# checkpoint\n",
    "filepath=\"models/F9W-31L-{epoch:02d}-{val_acc:.5f}_.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58356, 99, 161, 1) <class 'numpy.ndarray'>\n",
      "(58356, 31) <class 'numpy.ndarray'>\n",
      "(6485, 99, 161, 1) <class 'numpy.ndarray'>\n",
      "(6485, 31) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = lambda *x: [print(i.shape, type(i)) for i in x]\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.1, random_state=2018)\n",
    "S(x_train, y_train, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 58356 samples, validate on 6485 samples\n",
      "Epoch 1/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.1045 - acc: 0.9706Epoch 00000: val_acc improved from -inf to 0.97945, saving model to models/F9W-31L-00-0.97945_.hdf5\n",
      "58356/58356 [==============================] - 80s - loss: 0.1045 - acc: 0.9706 - val_loss: 0.0616 - val_acc: 0.9794\n",
      "Epoch 2/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9801Epoch 00001: val_acc improved from 0.97945 to 0.98678, saving model to models/F9W-31L-01-0.98678_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0582 - acc: 0.9801 - val_loss: 0.0388 - val_acc: 0.9868\n",
      "Epoch 3/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9843Epoch 00002: val_acc improved from 0.98678 to 0.98928, saving model to models/F9W-31L-02-0.98928_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0455 - acc: 0.9843 - val_loss: 0.0314 - val_acc: 0.9893\n",
      "Epoch 4/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9862Epoch 00003: val_acc improved from 0.98928 to 0.99156, saving model to models/F9W-31L-03-0.99156_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0400 - acc: 0.9862 - val_loss: 0.0258 - val_acc: 0.9916\n",
      "Epoch 5/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9874Epoch 00004: val_acc improved from 0.99156 to 0.99230, saving model to models/F9W-31L-04-0.99230_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0367 - acc: 0.9874 - val_loss: 0.0231 - val_acc: 0.9923\n",
      "Epoch 6/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9882Epoch 00005: val_acc improved from 0.99230 to 0.99265, saving model to models/F9W-31L-05-0.99265_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0343 - acc: 0.9882 - val_loss: 0.0221 - val_acc: 0.9927\n",
      "Epoch 7/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9887Epoch 00006: val_acc improved from 0.99265 to 0.99301, saving model to models/F9W-31L-06-0.99301_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0329 - acc: 0.9887 - val_loss: 0.0214 - val_acc: 0.9930\n",
      "Epoch 8/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9891Epoch 00007: val_acc improved from 0.99301 to 0.99313, saving model to models/F9W-31L-07-0.99313_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0317 - acc: 0.9891 - val_loss: 0.0208 - val_acc: 0.9931\n",
      "Epoch 9/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9895Epoch 00008: val_acc improved from 0.99313 to 0.99336, saving model to models/F9W-31L-08-0.99336_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0306 - acc: 0.9895 - val_loss: 0.0206 - val_acc: 0.9934\n",
      "Epoch 10/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9898Epoch 00009: val_acc improved from 0.99336 to 0.99381, saving model to models/F9W-31L-09-0.99381_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0300 - acc: 0.9898 - val_loss: 0.0192 - val_acc: 0.9938\n",
      "Epoch 11/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9901Epoch 00010: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0289 - acc: 0.9901 - val_loss: 0.0193 - val_acc: 0.9937\n",
      "Epoch 12/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9905Epoch 00011: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0281 - acc: 0.9905 - val_loss: 0.0199 - val_acc: 0.9936\n",
      "Epoch 13/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9905Epoch 00012: val_acc improved from 0.99381 to 0.99409, saving model to models/F9W-31L-12-0.99409_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0277 - acc: 0.9905 - val_loss: 0.0184 - val_acc: 0.9941\n",
      "Epoch 14/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9907Epoch 00013: val_acc improved from 0.99409 to 0.99411, saving model to models/F9W-31L-13-0.99411_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0274 - acc: 0.9907 - val_loss: 0.0177 - val_acc: 0.9941\n",
      "Epoch 15/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9910Epoch 00014: val_acc improved from 0.99411 to 0.99432, saving model to models/F9W-31L-14-0.99432_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0265 - acc: 0.9910 - val_loss: 0.0176 - val_acc: 0.9943\n",
      "Epoch 16/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9909Epoch 00015: val_acc improved from 0.99432 to 0.99442, saving model to models/F9W-31L-15-0.99442_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0266 - acc: 0.9909 - val_loss: 0.0175 - val_acc: 0.9944\n",
      "Epoch 17/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9912Epoch 00016: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0257 - acc: 0.9912 - val_loss: 0.0176 - val_acc: 0.9942\n",
      "Epoch 18/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9913Epoch 00017: val_acc improved from 0.99442 to 0.99449, saving model to models/F9W-31L-17-0.99449_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0256 - acc: 0.9913 - val_loss: 0.0170 - val_acc: 0.9945\n",
      "Epoch 19/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9914Epoch 00018: val_acc improved from 0.99449 to 0.99461, saving model to models/F9W-31L-18-0.99461_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0252 - acc: 0.9914 - val_loss: 0.0165 - val_acc: 0.9946\n",
      "Epoch 20/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9915Epoch 00019: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0251 - acc: 0.9915 - val_loss: 0.0171 - val_acc: 0.9945\n",
      "Epoch 21/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9916Epoch 00020: val_acc improved from 0.99461 to 0.99488, saving model to models/F9W-31L-20-0.99488_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0247 - acc: 0.9916 - val_loss: 0.0159 - val_acc: 0.9949\n",
      "Epoch 22/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9917Epoch 00021: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0244 - acc: 0.9917 - val_loss: 0.0160 - val_acc: 0.9948\n",
      "Epoch 23/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9917Epoch 00022: val_acc improved from 0.99488 to 0.99493, saving model to models/F9W-31L-22-0.99493_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0243 - acc: 0.9917 - val_loss: 0.0158 - val_acc: 0.9949\n",
      "Epoch 24/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9919Epoch 00023: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0238 - acc: 0.9919 - val_loss: 0.0156 - val_acc: 0.9949\n",
      "Epoch 25/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9919Epoch 00024: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0238 - acc: 0.9919 - val_loss: 0.0161 - val_acc: 0.9947\n",
      "Epoch 26/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9920Epoch 00025: val_acc improved from 0.99493 to 0.99495, saving model to models/F9W-31L-25-0.99495_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0236 - acc: 0.9920 - val_loss: 0.0159 - val_acc: 0.9949\n",
      "Epoch 27/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9922Epoch 00026: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0233 - acc: 0.9921 - val_loss: 0.0159 - val_acc: 0.9947\n",
      "Epoch 28/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9922Epoch 00027: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58356/58356 [==============================] - 75s - loss: 0.0229 - acc: 0.9922 - val_loss: 0.0155 - val_acc: 0.9949\n",
      "Epoch 29/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9923Epoch 00028: val_acc improved from 0.99495 to 0.99515, saving model to models/F9W-31L-28-0.99515_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0227 - acc: 0.9923 - val_loss: 0.0154 - val_acc: 0.9952\n",
      "Epoch 30/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9922Epoch 00029: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0229 - acc: 0.9922 - val_loss: 0.0154 - val_acc: 0.9949\n",
      "Epoch 31/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9923Epoch 00030: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0225 - acc: 0.9923 - val_loss: 0.0152 - val_acc: 0.9951\n",
      "Epoch 32/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9923Epoch 00031: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0226 - acc: 0.9923 - val_loss: 0.0153 - val_acc: 0.9950\n",
      "Epoch 33/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9924Epoch 00032: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0223 - acc: 0.9924 - val_loss: 0.0151 - val_acc: 0.9950\n",
      "Epoch 34/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9925Epoch 00033: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0220 - acc: 0.9925 - val_loss: 0.0148 - val_acc: 0.9951\n",
      "Epoch 35/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9925Epoch 00034: val_acc improved from 0.99515 to 0.99535, saving model to models/F9W-31L-34-0.99535_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0220 - acc: 0.9925 - val_loss: 0.0145 - val_acc: 0.9954\n",
      "Epoch 36/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9925Epoch 00035: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0220 - acc: 0.9925 - val_loss: 0.0151 - val_acc: 0.9952\n",
      "Epoch 37/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9926Epoch 00036: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0219 - acc: 0.9926 - val_loss: 0.0145 - val_acc: 0.9953\n",
      "Epoch 38/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9927Epoch 00037: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0215 - acc: 0.9927 - val_loss: 0.0145 - val_acc: 0.9953\n",
      "Epoch 39/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9927Epoch 00038: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0214 - acc: 0.9927 - val_loss: 0.0148 - val_acc: 0.9952\n",
      "Epoch 40/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9926Epoch 00039: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0216 - acc: 0.9926 - val_loss: 0.0149 - val_acc: 0.9952\n",
      "Epoch 41/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9927Epoch 00040: val_acc improved from 0.99535 to 0.99538, saving model to models/F9W-31L-40-0.99538_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0213 - acc: 0.9927 - val_loss: 0.0141 - val_acc: 0.9954\n",
      "Epoch 42/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9928Epoch 00041: val_acc improved from 0.99538 to 0.99542, saving model to models/F9W-31L-41-0.99542_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0211 - acc: 0.9928 - val_loss: 0.0143 - val_acc: 0.9954\n",
      "Epoch 43/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9929Epoch 00042: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0210 - acc: 0.9929 - val_loss: 0.0144 - val_acc: 0.9954\n",
      "Epoch 44/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9928Epoch 00043: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0210 - acc: 0.9928 - val_loss: 0.0142 - val_acc: 0.9953\n",
      "Epoch 45/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9928Epoch 00044: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0210 - acc: 0.9928 - val_loss: 0.0139 - val_acc: 0.9954\n",
      "Epoch 46/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9929Epoch 00045: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0208 - acc: 0.9929 - val_loss: 0.0141 - val_acc: 0.9953\n",
      "Epoch 47/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9930Epoch 00046: val_acc improved from 0.99542 to 0.99543, saving model to models/F9W-31L-46-0.99543_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0207 - acc: 0.9930 - val_loss: 0.0143 - val_acc: 0.9954\n",
      "Epoch 48/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9929Epoch 00047: val_acc improved from 0.99543 to 0.99557, saving model to models/F9W-31L-47-0.99557_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0207 - acc: 0.9929 - val_loss: 0.0137 - val_acc: 0.9956\n",
      "Epoch 49/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9931Epoch 00048: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0204 - acc: 0.9931 - val_loss: 0.0141 - val_acc: 0.9954\n",
      "Epoch 50/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9931Epoch 00049: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0203 - acc: 0.9931 - val_loss: 0.0143 - val_acc: 0.9954\n",
      "Epoch 51/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9930Epoch 00050: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0205 - acc: 0.9930 - val_loss: 0.0142 - val_acc: 0.9954\n",
      "Epoch 52/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9932Epoch 00051: val_acc improved from 0.99557 to 0.99557, saving model to models/F9W-31L-51-0.99557_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0202 - acc: 0.9932 - val_loss: 0.0141 - val_acc: 0.9956\n",
      "Epoch 53/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9932Epoch 00052: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0200 - acc: 0.9932 - val_loss: 0.0142 - val_acc: 0.9955\n",
      "Epoch 54/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9931Epoch 00053: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0202 - acc: 0.9931 - val_loss: 0.0140 - val_acc: 0.9954\n",
      "Epoch 55/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9933Epoch 00054: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0199 - acc: 0.9933 - val_loss: 0.0141 - val_acc: 0.9955\n",
      "Epoch 56/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9933Epoch 00055: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0197 - acc: 0.9933 - val_loss: 0.0140 - val_acc: 0.9955\n",
      "Epoch 57/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9933Epoch 00056: val_acc improved from 0.99557 to 0.99559, saving model to models/F9W-31L-56-0.99559_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0198 - acc: 0.9933 - val_loss: 0.0140 - val_acc: 0.9956\n",
      "Epoch 58/100\n",
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9932Epoch 00057: val_acc did not improve\n",
      "58356/58356 [==============================] - 75s - loss: 0.0199 - acc: 0.9932 - val_loss: 0.0138 - val_acc: 0.9955\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58304/58356 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9933Epoch 00058: val_acc improved from 0.99559 to 0.99562, saving model to models/F9W-31L-58-0.99562_.hdf5\n",
      "58356/58356 [==============================] - 75s - loss: 0.0197 - acc: 0.9933 - val_loss: 0.0138 - val_acc: 0.9956\n",
      "CPU times: user 53min 35s, sys: 10min 50s, total: 1h 4min 25s\n",
      "Wall time: 1h 14min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2abc775d5b00>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Fit the model\n",
    "model.fit(x_train, y_train, batch_size=64, validation_data=(x_valid, y_valid), \n",
    "          epochs=100, shuffle=True, verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     160\n",
       "1     193\n",
       "2     174\n",
       "3     174\n",
       "4     243\n",
       "5     261\n",
       "6     238\n",
       "7     225\n",
       "8     253\n",
       "9     172\n",
       "10    178\n",
       "11    240\n",
       "12    191\n",
       "13    241\n",
       "14    233\n",
       "15    246\n",
       "16    207\n",
       "17    233\n",
       "18    232\n",
       "19    224\n",
       "20    156\n",
       "21     16\n",
       "22    205\n",
       "23    258\n",
       "24    257\n",
       "25    189\n",
       "26    243\n",
       "27    215\n",
       "28    171\n",
       "29    228\n",
       "30    229\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_valid).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.save(os.path.join(model_path, 'cnn.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F9W-31L-58-0.99562_.hdf5\r\n",
      "F9W-31L-56-0.99559_.hdf5\r\n",
      "F9W-31L-51-0.99557_.hdf5\r\n",
      "F9W-31L-47-0.99557_.hdf5\r\n",
      "F9W-31L-46-0.99543_.hdf5\r\n",
      "F9W-31L-41-0.99542_.hdf5\r\n",
      "F9W-31L-40-0.99538_.hdf5\r\n",
      "F9W-31L-34-0.99535_.hdf5\r\n",
      "F9W-31L-28-0.99515_.hdf5\r\n",
      "F9W-31L-25-0.99495_.hdf5\r\n",
      "F9W-31L-22-0.99493_.hdf5\r\n",
      "F9W-31L-20-0.99488_.hdf5\r\n",
      "F9W-31L-18-0.99461_.hdf5\r\n",
      "F9W-31L-17-0.99449_.hdf5\r\n",
      "F9W-31L-15-0.99442_.hdf5\r\n",
      "F9W-31L-14-0.99432_.hdf5\r\n",
      "F9W-31L-13-0.99411_.hdf5\r\n",
      "F9W-31L-12-0.99409_.hdf5\r\n",
      "F9W-31L-09-0.99381_.hdf5\r\n",
      "F9W-31L-08-0.99336_.hdf5\r\n",
      "F9W-31L-07-0.99313_.hdf5\r\n",
      "F9W-31L-06-0.99301_.hdf5\r\n",
      "F9W-31L-05-0.99265_.hdf5\r\n",
      "F9W-31L-04-0.99230_.hdf5\r\n",
      "F9W-31L-03-0.99156_.hdf5\r\n",
      "F9W-31L-02-0.98928_.hdf5\r\n",
      "F9W-31L-01-0.98678_.hdf5\r\n",
      "F9W-31L-00-0.97945_.hdf5\r\n",
      "F9W-31-0.98714_.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "!ls models -t|grep 9W-31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Mname = 'models/F9W-31L-58-0.99562_.hdf5'\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model(Mname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_data_generator(batch=16):\n",
    "    fpaths = glob(os.path.join(test_data_path, '*wav'))\n",
    "    i = 0\n",
    "    for path in fpaths:\n",
    "        if i == 0:\n",
    "            imgs = []\n",
    "            fnames = []\n",
    "        i += 1\n",
    "        rate, samples = wavfile.read(path)\n",
    "        samples = pad_audio(samples)\n",
    "        resampled = signal.resample(samples, int(new_sample_rate / rate * samples.shape[0]))\n",
    "        _, _, specgram = log_specgram(resampled, sample_rate=new_sample_rate)\n",
    "        imgs.append(specgram)\n",
    "        fnames.append(path.split('\\\\')[-1])\n",
    "        if i == batch:\n",
    "            i = 0\n",
    "            imgs = np.array(imgs)\n",
    "            imgs = imgs.reshape(tuple(list(imgs.shape) + [1]))\n",
    "            yield fnames, imgs\n",
    "    if i < batch:\n",
    "        imgs = np.array(imgs)\n",
    "        imgs = imgs.reshape(tuple(list(imgs.shape) + [1]))\n",
    "        yield fnames, imgs\n",
    "    raise StopIteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used: 14.74 s :640 used: 12.26 s :1280 used: 13.66 s :1920 used: 11.52 s :2560 used: 11.85 s :3200 used: 12.34 s :3840 used: 12.26 s :4480 used: 12.07 s :5120 used: 12.32 s :5760 used: 13.20 s :6400 used: 13.33 s :7040 used: 13.78 s :7680 used: 12.97 s :8320 used: 12.85 s :8960 used: 13.40 s :9600 used: 12.96 s :10240 used: 13.51 s :10880 used: 13.03 s :11520 used: 12.84 s :12160 used: 12.30 s :12800 used: 12.81 s :13440 used: 12.93 s :14080 used: 12.59 s :14720 used: 12.91 s :15360 used: 13.33 s :16000 used: 12.91 s :16640 used: 14.03 s :17280 used: 12.84 s :17920 used: 13.74 s :18560 used: 12.99 s :19200 used: 13.05 s :19840 used: 13.08 s :20480 used: 12.69 s :21120 used: 13.00 s :21760 used: 13.77 s :22400 used: 12.74 s :23040 used: 12.87 s :23680 used: 14.10 s :24320 used: 13.48 s :24960 used: 13.50 s :25600 used: 12.80 s :26240 used: 12.98 s :26880 used: 13.16 s :27520 used: 12.85 s :28160 used: 13.38 s :28800 used: 11.92 s :29440 used: 10.41 s :30080 used: 10.32 s :30720 used: 11.91 s :31360 used: 10.57 s :32000 used: 10.14 s :32640 used: 10.42 s :33280 used: 10.82 s :33920 used: 12.28 s :34560 used: 12.90 s :35200 used: 12.48 s :35840 used: 13.56 s :36480 used: 13.30 s :37120 used: 13.26 s :37760 used: 11.71 s :38400 used: 12.98 s :39040 used: 12.19 s :39680 used: 12.91 s :40320 used: 12.73 s :40960 used: 12.95 s :41600 used: 12.50 s :42240 used: 12.36 s :42880 used: 12.94 s :43520 used: 12.57 s :44160 used: 13.71 s :44800 used: 12.86 s :45440 used: 13.63 s :46080 used: 12.35 s :46720 used: 13.16 s :47360 used: 13.00 s :48000 used: 13.45 s :48640 used: 12.81 s :49280 used: 27.95 s :49920 used: 19.55 s :50560 used: 16.31 s :51200 used: 16.94 s :51840 used: 16.65 s :52480 used: 20.63 s :53120 used: 27.21 s :53760 used: 18.24 s :54400 used: 18.14 s :55040 used: 15.63 s :55680 used: 15.95 s :56320 used: 12.43 s :56960 used: 12.92 s :57600 used: 12.57 s :58240 used: 12.80 s :58880 used: 12.85 s :59520 used: 12.65 s :60160 used: 11.58 s :60800 used: 12.11 s :61440 used: 11.48 s :62080 used: 11.56 s :62720 used: 11.93 s :63360 used: 11.58 s :64000 used: 12.81 s :64640 used: 12.32 s :65280 used: 12.54 s :65920 used: 12.78 s :66560 used: 12.87 s :67200 used: 12.41 s :67840 used: 12.31 s :68480 used: 13.58 s :69120 used: 13.14 s :69760 used: 12.69 s :70400 used: 12.77 s :71040 used: 12.58 s :71680 used: 12.22 s :72320 used: 12.76 s :72960 used: 12.11 s :73600 used: 12.86 s :74240 used: 12.34 s :74880 used: 27.61 s :75520 used: 19.20 s :76160 used: 17.28 s :76800 used: 18.04 s :77440 used: 16.53 s :78080 used: 13.46 s :78720 used: 13.22 s :79360 used: 12.32 s :80000 used: 12.40 s :80640 used: 12.54 s :81280 used: 12.28 s :81920 used: 12.43 s :82560 used: 12.01 s :83200 used: 13.26 s :83840 used: 12.25 s :84480 used: 12.91 s :85120 used: 12.19 s :85760 used: 12.66 s :86400 used: 13.05 s :87040 used: 12.29 s :87680 used: 12.13 s :88320 used: 12.48 s :88960 used: 12.54 s :89600 used: 12.27 s :90240 used: 12.94 s :90880 used: 12.37 s :91520 used: 13.02 s :92160 used: 34.05 s :92800 used: 20.36 s :93440 used: 19.64 s :94080 used: 18.03 s :94720 used: 14.93 s :95360 used: 13.18 s :96000 used: 12.67 s :96640 used: 13.92 s :97280 used: 13.10 s :97920 used: 13.34 s :98560 used: 13.65 s :99200 used: 14.03 s :99840 used: 13.27 s :100480 used: 29.09 s :101120 used: 20.41 s :101760 used: 19.44 s :102400 used: 19.09 s :103040 used: 14.29 s :103680 used: 13.68 s :104320 used: 12.95 s :104960 used: 12.71 s :105600 used: 13.45 s :106240 used: 14.09 s :106880 used: 14.22 s :107520 used: 14.19 s :108160 used: 13.50 s :108800 used: 13.79 s :109440 used: 14.16 s :110080 used: 13.17 s :110720 used: 13.12 s :111360 used: 12.91 s :112000 used: 13.04 s :112640 used: 13.31 s :113280 used: 12.85 s :113920 used: 12.84 s :114560 used: 12.82 s :115200 used: 12.94 s :115840 used: 12.81 s :116480 used: 13.03 s :117120 used: 12.63 s :117760 used: 12.89 s :118400 used: 12.85 s :119040 used: 12.77 s :119680 used: 13.18 s :120320 used: 13.03 s :120960 used: 12.78 s :121600 used: 12.77 s :122240 used: 13.04 s :122880 used: 13.26 s :123520 used: 12.79 s :124160 used: 12.82 s :124800 used: 13.51 s :125440 used: 13.22 s :126080 used: 12.72 s :126720 used: 13.35 s :127360 used: 13.00 s :128000 used: 12.94 s :128640 used: 12.65 s :129280 used: 13.13 s :129920 used: 13.62 s :130560 used: 15.03 s :131200 used: 32.51 s :131840 used: 19.52 s :132480 used: 18.34 s :133120 used: 17.66 s :133760 used: 13.48 s :134400 used: 13.01 s :135040 used: 12.86 s :135680 used: 13.07 s :136320 used: 12.96 s :136960 used: 13.15 s :137600 used: 13.09 s :138240 used: 12.96 s :138880 used: 12.93 s :139520 used: 13.13 s :140160 used: 13.40 s :140800 used: 13.78 s :141440 used: 13.09 s :142080 used: 13.14 s :142720 used: 13.18 s :143360 used: 13.07 s :144000 used: 12.80 s :144640 used: 13.59 s :145280 used: 13.21 s :145920 used: 13.20 s :146560 used: 12.77 s :147200 used: 13.16 s :147840 used: 13.25 s :148480 used: 13.01 s :149120 used: 12.96 s :149760 used: 13.03 s :150400 used: 13.08 s :151040 used: 12.83 s :151680 used: 12.78 s :152320 used: 12.81 s :152960 used: 12.88 s :153600 used: 13.01 s :154240 used: 12.93 s :154880 used: 13.52 s :155520 used: 13.74 s :156160 used: 13.26 s :156800 used: 12.86 s :157440 used: 12.92 s :158080 CPU times: user 4min 59s, sys: 19.3 s, total: 5min 18s\n",
      "Wall time: 56min 50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shj16110/anaconda2/envs/3.6.1/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: generator 'test_data_generator' raised StopIteration\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch = 64\n",
    "start = time()\n",
    "\n",
    "\n",
    "#exit() #delete this\n",
    "#del x_train, y_train\n",
    "gc.collect()\n",
    "\n",
    "index = []\n",
    "results = []\n",
    "N=0\n",
    "for fnames, imgs in test_data_generator(batch=batch):\n",
    "    N+=1\n",
    "    if N%10==0:\n",
    "        print ('used: {:.2f} s'.format(time()-start), end=' :{} '.format(N*batch))\n",
    "        start = time()\n",
    "    predicts = model.predict(imgs)\n",
    "    predicts = np.argmax(predicts, axis=1)\n",
    "    predicts = [label_index[p] for p in predicts]\n",
    "    index.extend(fnames)\n",
    "    results.extend(predicts)\n",
    "\n",
    "df = pd.DataFrame(columns=['fname', 'label'])\n",
    "df['fname'] = index\n",
    "df['label'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "on         18143\n",
       "four       10379\n",
       "up          9081\n",
       "off         6945\n",
       "no          6919\n",
       "zero        6885\n",
       "one         6824\n",
       "five        6727\n",
       "yes         6688\n",
       "eight       6275\n",
       "nine        6241\n",
       "left        6142\n",
       "two         6088\n",
       "six         5969\n",
       "stop        5645\n",
       "seven       5414\n",
       "right       4740\n",
       "three       4691\n",
       "go          4573\n",
       "down        4522\n",
       "bed         2717\n",
       "silence     2714\n",
       "sheila      2233\n",
       "marvin      2063\n",
       "wow         1984\n",
       "dog         1659\n",
       "cat         1531\n",
       "bird        1477\n",
       "happy       1191\n",
       "house       1040\n",
       "tree        1038\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "legal_label = np.array(['down', 'go', 'left', 'no', 'off', 'on', 'right',\n",
    "                        'silence', 'stop', 'up', 'yes']).astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknow     82426\n",
       "on         18143\n",
       "up          9081\n",
       "off         6945\n",
       "no          6919\n",
       "yes         6688\n",
       "left        6142\n",
       "stop        5645\n",
       "right       4740\n",
       "go          4573\n",
       "down        4522\n",
       "silence     2714\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].apply(lambda x: 'unknow' if x not in legal_label else x).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['label'] = df['label'].apply(lambda x: 'unknow' if x not in legal_label else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158538, 2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['fname'] = df['fname'].apply(lambda x:x.split('audio/')[-1])\n",
    "df.to_csv(os.path.join(out_path, Mname.split('/')[-1]+'_submission.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU3",
   "language": "python",
   "name": "gpu3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
