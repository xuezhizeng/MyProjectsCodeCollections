{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from scrapy.selector import Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Selector xpath=None data=u'<html>\\n\\t<head>\\n\\t\\t<meta charset=\"utf-8\">\\n'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = requests.get('http://www.soyoung.com/dpg5764886')\n",
    "r = Selector(text = c.text)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://img2.soyoung.com/tieba/ios/20171111/7/20171111132824469.jpg\n",
      "http://img2.soyoung.com/tieba/ios/20171111/2/20171111132819902.jpg\n",
      "http://img2.soyoung.com/tieba/ios/20171111/3/20171111132813333.jpg\n",
      "http://y.soyoung.com/d584\n",
      "http://y.soyoung.com/al79\n",
      "上海华美医疗美容医院\n",
      "http://y.soyoung.com/cp29\n",
      "谢卫国\n",
      "/u14908231\n",
      "摇曳在风中\n",
      "【假体隆胸】华美特贝茨丰胸【大咖名医亲诊@谢卫国、李健】美国进口曼托 舒适变美，无需按摩拆线\n"
     ]
    }
   ],
   "source": [
    "item={}\n",
    "dinfo = r.css('div.diary-info a')\n",
    "# item['diary_link']= response.url\n",
    "try:\n",
    "    user=dinfo[1]\n",
    "    hos=dinfo[2]\n",
    "    doc=dinfo[3]\n",
    "    prod=dinfo[4]\n",
    "    img1=dinfo[5]\n",
    "    img2=dinfo[6]\n",
    "    img3=dinfo[7]\n",
    "except:\n",
    "    print 'X'\n",
    "    \n",
    "try:\n",
    "    item['user_name'] = user.css('::text').extract()[0].strip()\n",
    "    item['user_link'] = user.css('::attr(href)').extract()[0].strip()\n",
    "    item['hospital'] = hos.css('::text').extract()[0].strip()\n",
    "    item['hospital_link'] = hos.css('::attr(href)').extract()[0].strip()    \n",
    "    item['doctor_name'] = doc.css('::text').extract()[0].strip()\n",
    "    item['doctor_link'] = doc.css('::attr(href)').extract()[0].strip()\n",
    "    item['product_name'] = prod.css('::text').extract()[0].strip()\n",
    "    item['product_link'] = prod.css('::attr(href)').extract()[0].strip()\n",
    "    item['pre_surg_pic1'] = img1.css('::attr(href)').extract()[0].strip()    \n",
    "    item['pre_surg_pic2'] = img2.css('::attr(href)').extract()[0].strip()    \n",
    "    item['pre_surg_pic3'] = img3.css('::attr(href)').extract()[0].strip()    \n",
    "    \n",
    "except:\n",
    "    print 'X'\n",
    "    \n",
    "for i in item.values():print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a={}\n",
    "a[0]=1\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]=2\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response=r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "19\n",
      "27\n",
      "21\n",
      "19\n",
      "24\n",
      "19\n",
      "19\n",
      "24\n",
      "25\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "lll=[]\n",
    "item={}\n",
    "dinfo = response.css('div.diary-info a')\n",
    "# item['diary_link']= response.url\n",
    "try:\n",
    "    user=dinfo[1]\n",
    "    hos=dinfo[2]\n",
    "    doc=dinfo[3]\n",
    "    prod=dinfo[4]\n",
    "    pre_img=dinfo[5:]\n",
    "    \n",
    "except Exception as e:\n",
    "    print e\n",
    "    \n",
    "\n",
    "    \n",
    "print len(item)\n",
    "\n",
    "for i in response.css('div.diary-list > ul > li.diary-item'):\n",
    "    item={}\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        item['user_name'] = user.css('::text').extract()[0].strip()\n",
    "        item['user_link'] = user.css('::attr(href)').extract()[0].strip()\n",
    "        item['hospital'] = hos.css('::text').extract()[0].strip()\n",
    "        item['hospital_link'] = hos.css('::attr(href)').extract()[0].strip()    \n",
    "        item['doctor_name'] = doc.css('::text').extract()[0].strip()\n",
    "        item['doctor_link'] = doc.css('::attr(href)').extract()[0].strip()\n",
    "        item['product_name'] = prod.css('::text').extract()[0].strip()\n",
    "        item['product_link'] = prod.css('::attr(href)').extract()[0].strip()\n",
    "        \n",
    "        m=0\n",
    "        for img in pre_img:\n",
    "            m+=1\n",
    "            item['pre_surg_pic'+str(m)] = img.css('::attr(href)').extract()[0].strip()    \n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print e    \n",
    "    \n",
    "    \n",
    "    \n",
    "    item['post_title'] = i.css('span.day::text').extract()[0]\n",
    "    item['post_link'] = i.css('p.describe > a::attr(href)').extract()[0]\n",
    "    item['post_text'] = i.css('p.describe > a::text').extract()[0]\n",
    "    \n",
    "    n=0\n",
    "    for p in i.css('ul.photo-list > li > a > img::attr(data-img)').extract():\n",
    "        n+=1\n",
    "        item['post_image'+str(n)] = p\n",
    "    tp='photo-diary'\n",
    "    \n",
    "    vid = i.css('div.video-poster > a > img::attr(data-img)').extract()\n",
    "    if len(vid)>0:\n",
    "        tp='video-diary'\n",
    "        item['video_image'] = vid[0]\n",
    "        \n",
    "    item['post_type'] = tp\n",
    "    \n",
    "    coll = i.css('div.other-box a::text').extract()\n",
    "    item['views']= coll[0]\n",
    "    item['comments']= coll[1]\n",
    "    item['favor']= coll[2]\n",
    "    \n",
    "    print len(item)\n",
    "    lll.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comments': u'38',\n",
       " 'doctor_link': u'http://y.soyoung.com/d584',\n",
       " 'doctor_name': u'\\u8c22\\u536b\\u56fd',\n",
       " 'favor': u'30',\n",
       " 'hospital': u'\\u4e0a\\u6d77\\u534e\\u7f8e\\u533b\\u7597\\u7f8e\\u5bb9\\u533b\\u9662',\n",
       " 'hospital_link': u'http://y.soyoung.com/al79',\n",
       " 'post_image1': u'http://img2.soyoung.com/tieba/web/20170926/6/20170926143141631_301_301.jpg',\n",
       " 'post_image2': u'http://img2.soyoung.com/tieba/web/20170926/9/20170926143506913_301_301.jpg',\n",
       " 'post_image3': u'http://img2.soyoung.com/tieba/web/20170926/1/20170926143515201_301_301.jpg',\n",
       " 'post_link': u'/p14697181?group_id=5764886',\n",
       " 'post_text': u'\\u3010\\u5047\\u4f53\\u9686\\u80f8\\u7b2c145\\u5929\\u3011\\u6211\\u73b0\\u5728\\u8fd8\\u662f\\u6709\\u70b9\\u4e0d\\u592a\\u4e60\\u60ef\\u5176\\u5b9e\\uff0c\\u4f46\\u662f\\u4f9d\\u7136\\u8d85\\u7ea7\\u5174\\u594b\\u3002\\u867d\\u7136\\u73b0\\u5728\\u5df2\\u7ecf\\u4e00\\u767e\\u591a\\u5929\\uff0c\\u5feb\\u534a\\u5e74\\u8fc7\\u53bb\\u4e86\\uff0c\\u4f46\\u4eca\\u5929\\u5c45\\u7136\\u8fd8\\u63a5\\u5230\\u4e86\\u534e\\u7f8e\\u7684\\u7535\\u8bdd\\uff0c\\u8be2\\u95ee\\u6211\\u7684\\u60c5\\u51b5\\uff0c\\u670d\\u52a1\\u771f\\u7684\\u6ca1\\u8c01\\u4e86\\u3002\\u80f8\\u7684\\u60c5\\u51b5\\u5176\\u5b9e\\u4e5f\\u6ca1\\u5565\\u597d\\u8bf4\\u7684\\u4e86\\uff0c\\u5c24\\u5176\\u6062\\u590d\\u540e\\u671f\\uff0c\\u56e0\\u4e3a\\u6bcf\\u5929\\u6ca1\\u4ec0\\u4e48\\u53d8',\n",
       " 'post_title': u'\\u672f\\u540e\\u7b2c145\\u5929',\n",
       " 'post_type': 'photo-diary',\n",
       " 'pre_surg_pic1': u'http://img2.soyoung.com/tieba/ios/20171111/3/20171111132813333.jpg',\n",
       " 'pre_surg_pic2': u'http://img2.soyoung.com/tieba/ios/20171111/2/20171111132819902.jpg',\n",
       " 'pre_surg_pic3': u'http://img2.soyoung.com/tieba/ios/20171111/7/20171111132824469.jpg',\n",
       " 'product_link': u'http://y.soyoung.com/cp29',\n",
       " 'product_name': u'\\u3010\\u5047\\u4f53\\u9686\\u80f8\\u3011\\u534e\\u7f8e\\u7279\\u8d1d\\u8328\\u4e30\\u80f8\\u3010\\u5927\\u5496\\u540d\\u533b\\u4eb2\\u8bca@\\u8c22\\u536b\\u56fd\\u3001\\u674e\\u5065\\u3011\\u7f8e\\u56fd\\u8fdb\\u53e3\\u66fc\\u6258 \\u8212\\u9002\\u53d8\\u7f8e\\uff0c\\u65e0\\u9700\\u6309\\u6469\\u62c6\\u7ebf',\n",
       " 'user_link': u'/u14908231',\n",
       " 'user_name': u'\\u6447\\u66f3\\u5728\\u98ce\\u4e2d',\n",
       " 'views': u'1538'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lll[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "class DiaryItem(scrapy.Item):\n",
    "    # define the fields for your item here like:\n",
    "    # name = scrapy.Field()\n",
    "    \n",
    "    diary_link=scrapy.Field()    \n",
    "    user_name=scrapy.Field()\n",
    "    user_link=scrapy.Field()\n",
    "    \n",
    "    diary_name=scrapy.Field()\n",
    "    diary_date=scrapy.Field()\n",
    "    project_name=scrapy.Field()\n",
    "    \n",
    "    hospital=scrapy.Field()\n",
    "    hospital_link=scrapy.Field()\n",
    "    \n",
    "    doctor_name=scrapy.Field()\n",
    "    doctor_link=scrapy.Field()\n",
    "    \n",
    "    product_name=scrapy.Field()\n",
    "    product_link=scrapy.Field()\n",
    "    \n",
    "    price=scrapy.Field()\n",
    "    \n",
    "    pre_surg_pic1=scrapy.Field()\n",
    "    pre_surg_pic2=scrapy.Field()\n",
    "    pre_surg_pic3=scrapy.Field()\n",
    "    \n",
    "    post_title=scrapy.Field()\n",
    "    post_link=scrapy.Field()\n",
    "    post_text=scrapy.Field()\n",
    "    post_image1=scrapy.Field()\n",
    "    post_image2=scrapy.Field()\n",
    "    post_image3=scrapy.Field()\n",
    "    post_image4=scrapy.Field()\n",
    "    post_image5=scrapy.Field()\n",
    "    post_image6=scrapy.Field()\n",
    "    post_image7=scrapy.Field()\n",
    "    post_image8=scrapy.Field()\n",
    "    post_image9=scrapy.Field()\n",
    "    \n",
    "    post_type=scrapy.Field()\n",
    "    video_image=scrapy.Field()\n",
    "    \n",
    "    posts_time=scrapy.Field()\n",
    "    views=scrapy.Field()\n",
    "    comments=scrapy.Field()\n",
    "    favor=scrapy.Field()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.soyoung.com/dpg6713991"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200 http://www.soyoung.com/dpg6713991>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = requests.get('http://www.soyoung.com/dpg6713991')\n",
    "from scrapy.http import TextResponse\n",
    "response = TextResponse(c.url, body=c.text, encoding='utf-8')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(response):\n",
    "    \n",
    "    if response.url == 'http://www.soyoung.com/dp':\n",
    "        return\n",
    "\n",
    "\n",
    "    basic={}\n",
    "\n",
    "\n",
    "    basic['diary_link']= response.url\n",
    "    basic['diary_name'] = response.css('div.diary-info > h2::text').extract()[0]\n",
    "\n",
    "    user = response.css('div.diary-info > div.avatar-box > p > a')\n",
    "    basic['user_name'] = user.css('::text').extract()[0].strip()\n",
    "    basic['user_link'] = user.css('::attr(href)').extract()[0].strip()\n",
    "\n",
    "    dinfo = response.css('div.diary-info > div.info-box > div.row')\n",
    "\n",
    "    try:\n",
    "        proj, dtime, hos, doc, prod, price, pre_img = dinfo\n",
    "    except Exception as e:\n",
    "        print 'X1',e\n",
    "\n",
    "    try:\n",
    "        basic['project_name'] = proj.css('div.value.tag::text').extract()[0].strip()\n",
    "    except Exception as e:\n",
    "        print 'pj',e        \n",
    "\n",
    "\n",
    "    try:\n",
    "        basic['diary_date'] = dtime.css('div.value.date::text').extract()[0].strip()\n",
    "    except Exception as e:\n",
    "        print 'pt',e        \n",
    "\n",
    "\n",
    "    try:\n",
    "        basic['hospital'] = hos.css('a::text').extract()[0].strip()\n",
    "        basic['hospital_link'] = hos.css('a::attr(href)').extract()[0].strip()    \n",
    "    except Exception as e:\n",
    "        print 'hp',e       \n",
    "\n",
    "    try:    \n",
    "        dx = doc.css('a::text').extract()\n",
    "        dy = doc.css('a::attr(href)').extract()\n",
    "\n",
    "        if len(dx)>0 and len(dy>0):\n",
    "            basic['doctor_name'] = dx[0].strip()\n",
    "            basic['doctor_link'] = dy[0].strip()\n",
    "    except Exception as e:\n",
    "        print 'dc',e     \n",
    "\n",
    "    try:    \n",
    "        basic['product_name'] = prod.css('a::text').extract()[0].strip()\n",
    "        basic['product_link'] = prod.css('a::attr(href)').extract()[0].strip()\n",
    "    except Exception as e:\n",
    "        print 'pd',e   \n",
    "\n",
    "    try:    \n",
    "        basic['price'] = price.css('div.value.price::text').extract()[0].strip()\n",
    "    except Exception as e:\n",
    "        print 'pc',e       \n",
    "\n",
    "\n",
    "    try:    \n",
    "        m=0\n",
    "        for img in pre_img.css('div.before-photos > a'):\n",
    "            m+=1\n",
    "            basic['pre_surg_pic'+str(m)] = img.css('::attr(href)').extract()[0].strip()    \n",
    "\n",
    "    except Exception as e:\n",
    "        print 'pi',e    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for i in response.css('div.diary-list > ul > li.diary-item'):\n",
    "        item=DiaryItem(basic)\n",
    "\n",
    "\n",
    "        item['post_title'] = i.css('span.day::text').extract()[0]\n",
    "        item['post_link'] = i.css('p.describe > a::attr(href)').extract()[0]\n",
    "        item['post_text'] = i.css('p.describe > a::text').extract()[0]\n",
    "\n",
    "        n=0\n",
    "        for p in i.css('ul.photo-list > li > a > img::attr(data-img)').extract():\n",
    "            n+=1\n",
    "            item['post_image'+str(n)] = p\n",
    "        tp='photo-diary'\n",
    "\n",
    "        vid = i.css('div.video-poster > a > img::attr(data-img)').extract()\n",
    "        if len(vid)>0:\n",
    "            tp='video-diary'\n",
    "            item['video_image'] = vid[0]\n",
    "\n",
    "        item['post_type'] = tp\n",
    "\n",
    "        coll = i.css('div.other-box a::text').extract()\n",
    "        item['views']= coll[0]\n",
    "        item['comments']= coll[1]\n",
    "        item['favor']= coll[2]\n",
    "\n",
    "        print item\n",
    "        #lll.append(item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'40', u'0', u'0'] 2017-11-11 10:52:45\n",
      "[u'39', u'1', u'0'] 2017-10-07 12:26:51\n",
      "[u'55', u'2', u'0'] 2017-10-04 09:30:48\n",
      "[u'34', u'1', u'0'] 2017-09-30 18:28:04\n"
     ]
    }
   ],
   "source": [
    "for i in response.css('div.diary-list > ul > li.diary-item'):\n",
    "    a = i.css('div.date::text').extract()[0]\n",
    "    coll = i.css('div.other-box a::text').extract()\n",
    "    print coll, a\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
