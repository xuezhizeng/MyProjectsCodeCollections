{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3931704774632626396\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5586538496\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 8866864628620453005\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Image dimensions\n",
    "img_width, img_height = 150, 150 \n",
    " \n",
    "\"\"\"\n",
    "    Creates a CNN model\n",
    "    p: Dropout rate\n",
    "    input_shape: Shape of input \n",
    "\"\"\"\n",
    "def create_model(p, input_shape=(32, 32, 3)):\n",
    "    # Initialising the CNN\n",
    "    model = Sequential()\n",
    "    # Convolution + Pooling Layer \n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Convolution + Pooling Layer \n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Convolution + Pooling Layer \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Convolution + Pooling Layer \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Flattening\n",
    "    model.add(Flatten())\n",
    "    # Fully connection\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(p))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(p/2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compiling the CNN\n",
    "    optimizer = Adam(lr=1e-3)\n",
    "    metrics=['accuracy']\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metrics)\n",
    "    \n",
    "    print (model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Fitting the CNN to the images.\n",
    "\"\"\"\n",
    "def run_training(bs=32, epochs=10):\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(rescale = 1./255, \n",
    "                                       shear_range = 0.2, \n",
    "                                       zoom_range = 0.2, \n",
    "                                       horizontal_flip = True)\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    " \n",
    "    training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (img_width, img_height),\n",
    "                                                 batch_size = bs,\n",
    "                                                 class_mode = 'binary')\n",
    "                                                 \n",
    "    test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (img_width, img_height),\n",
    "                                            batch_size = bs,\n",
    "                                            class_mode = 'binary')\n",
    "                                            \n",
    "    model = create_model(p=0.6, input_shape=(img_width, img_height, 3))      \n",
    "    \n",
    "    model.fit_generator(training_set,\n",
    "                         steps_per_epoch=8000/bs,\n",
    "                         epochs = epochs,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000/bs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 150, 150, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 18, 18, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                331840    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 405,793\n",
      "Trainable params: 405,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - 43s - loss: 0.6947 - acc: 0.5081 - val_loss: 0.6905 - val_acc: 0.5780\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 42s - loss: 0.6900 - acc: 0.5166 - val_loss: 0.6932 - val_acc: 0.5010\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 41s - loss: 0.6934 - acc: 0.4981 - val_loss: 0.6932 - val_acc: 0.5020\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 41s - loss: 0.6933 - acc: 0.4949 - val_loss: 0.6935 - val_acc: 0.5040\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 41s - loss: 0.6934 - acc: 0.5020 - val_loss: 0.6931 - val_acc: 0.5045\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 41s - loss: 0.6933 - acc: 0.4976 - val_loss: 0.6932 - val_acc: 0.4890\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 41s - loss: 0.6933 - acc: 0.4931 - val_loss: 0.6931 - val_acc: 0.5115\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 41s - loss: 0.6933 - acc: 0.4925 - val_loss: 0.6931 - val_acc: 0.4970\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 42s - loss: 0.6933 - acc: 0.4900 - val_loss: 0.6932 - val_acc: 0.4875\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 41s - loss: 0.6933 - acc: 0.5005 - val_loss: 0.6933 - val_acc: 0.4895\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 41s - loss: 0.6933 - acc: 0.4854 - val_loss: 0.6932 - val_acc: 0.4970\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 41s - loss: 0.6932 - acc: 0.4972 - val_loss: 0.6931 - val_acc: 0.5040\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 42s - loss: 0.6932 - acc: 0.5010 - val_loss: 0.6932 - val_acc: 0.4895\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 42s - loss: 0.6932 - acc: 0.4961 - val_loss: 0.6931 - val_acc: 0.5100\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 41s - loss: 0.6932 - acc: 0.4988 - val_loss: 0.6930 - val_acc: 0.4970\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 41s - loss: 0.6927 - acc: 0.5049 - val_loss: 0.6931 - val_acc: 0.5045\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 41s - loss: 0.6934 - acc: 0.4996 - val_loss: 0.6931 - val_acc: 0.5100\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 42s - loss: 0.6933 - acc: 0.4985 - val_loss: 0.6932 - val_acc: 0.4910\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 42s - loss: 0.6933 - acc: 0.4910 - val_loss: 0.6931 - val_acc: 0.5095\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 42s - loss: 0.6931 - acc: 0.5074 - val_loss: 0.6932 - val_acc: 0.4820\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 41s - loss: 0.6933 - acc: 0.4925 - val_loss: 0.6932 - val_acc: 0.4950\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 40s - loss: 0.6932 - acc: 0.4965 - val_loss: 0.6932 - val_acc: 0.4990\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 40s - loss: 0.6932 - acc: 0.5001 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 40s - loss: 0.6933 - acc: 0.4884 - val_loss: 0.6931 - val_acc: 0.5035\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 40s - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6931 - val_acc: 0.4930\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 40s - loss: 0.6932 - acc: 0.5041 - val_loss: 0.6932 - val_acc: 0.4950\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 40s - loss: 0.6932 - acc: 0.4964 - val_loss: 0.6931 - val_acc: 0.5075\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 40s - loss: 0.6932 - acc: 0.5022 - val_loss: 0.6931 - val_acc: 0.5060\n",
      "Epoch 29/100\n",
      " 87/250 [=========>....................] - ETA: 22s - loss: 0.6932 - acc: 0.4989"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    classifier = run_training(bs=32, epochs=100)\n",
    "    return classifier\n",
    " \n",
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    classifier = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_backup_path = os.path.join(script_dir, 'dataset/cat_or_dogs_model.h5')\n",
    "classifier.save(model_backup_path)\n",
    "\n",
    "print(\"Model saved to\", model_backup_path)\n",
    " \n",
    " \n",
    "print(\"The model class indices are:\", training_set.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
